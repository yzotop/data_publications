---
tags:
  - data
author: Davydov
data_type:
  - Analytics
---


# 1. ОСНОВЫ СТАТИСТИКИ

### Метрики генеральной совокупности и выборок

1.  **Среднее** **значение** (mean) - это сумма всех значений в генеральной совокупности, разделенная на ее размерность. Среднее значение представляет собой типичное значение генеральной совокупности.
2.  **Медиана** (median) - это значение, которое разделяет генеральную совокупность на две равные половины, когда значения упорядочены по возрастанию или убыванию.
3.  **Мода** (mode) - это значение, которое наиболее часто встречается в генеральной совокупности.
4.  **Дисперсия** (variance) - это мера разброса значений в генеральной совокупности относительно их среднего значения.    
5.  **Стандартное отклонение** (standard deviation) - это квадратный корень из дисперсии и используется для измерения степени изменчивости значений в генеральной совокупности.   
6.  **Квантили** (quantiles) - это значения, которые разделяют генеральную совокупность на равные доли. 
7. **Интерквартильный размах** (interquartile range) - это разница между 75-перцентилью и 25-перцентилем и используется для измерения разброса значений в генеральной совокупности.

### Критерии для выборок

Случайность
Репрезентативность
Размер выборки
Объективность
Прозрачность

###  Стандартизация

Стандартизация (также называемая Z-преобразованием) - это процесс преобразования данных в стандартизированные единицы, чтобы сравнивать их относительно друг друга. Стандартизация полезна в статистике, когда требуется сравнение различных наборов данных, которые имеют различную шкалу измерения.

Стандартизация основана на идее вычисления разности между каждым значением и средним значением выборки, а затем деления этой разности на стандартное отклонение выборки. В результате стандартизации каждое значение данных конвертируется в "Z-оценку", которая показывает, на сколько стандартных отклонений это значение отклоняется от среднего значения выборки.

Стандартизация позволяет сравнивать значения данных, измеренных в разных единицах или имеющих различный масштаб, и сделать выводы о том, насколько каждое значение отклоняется от среднего значения в единицах стандартного отклонения. Стандартизация также полезна при работе с нормально распределенными данными, поскольку позволяет привести данные к стандартному нормальному распределению, где среднее значение равно нулю, а стандартное отклонение равно единице.

### ЦПТ

ЦПТ (центральная предельная теорема) — сумма или среднее большого числа независимых и одинаково распределенных случайных величин сходится к нормальному распределению при увеличении размера выборки. Другими словами, ЦПТ говорит о том, что если мы берем достаточно большую выборку из генеральной совокупности и находим среднее значение выборки, то оно будет иметь нормальное распределение, независимо от распределения исходной генеральной совокупности.

Согласно ЦПТ, при условии, что размер выборки достаточно большой (обычно больше 30), распределение средних значений выборки будет приближаться к нормальному распределению со средним значением, равным среднему значению генеральной совокупности, и стандартным отклонением, которое зависит от размера выборки.

Если мы многократно выбираем случайные выборки из генеральной совокупности, находим среднее значение каждой выборки и строим гистограмму распределения этих средних значений, то форма этой гистограммы будет напоминать нормальное распределение.

Форма распределения средних значений выборки также зависит от формы распределения генеральной совокупности. Если генеральная совокупность имеет нормальное распределение, то распределение средних значений выборки также будет нормальным. Если же генеральная совокупность имеет не нормальное распределение, то распределение средних значений выборки будет иметь форму, которая будет приближаться к нормальной форме при увеличении размера выборки.

ЦПТ позволяет использовать нормальное распределение для анализа большинства выборочных данных, что значительно упрощает статистический анализ.

## Ошибка первого рода

> [!tip] Мы делаем ложное предположение о наличии эффекта, когда на самом деле такого эффекта нет.
> Ошибка происходит, когда нулевая гипотеза отвергается, когда она на самом деле верна. 
> Уровень значимости (alpha) контролирует вероятность ошибки первого рода, то есть вероятность отклонения нулевой гипотезы, когда она верна.


## Уровень значимости или ошибки первого рода (альфа)

Уровень риска ошибки первого рода
<span style="background:#b1ffff">Вероятность того, что будет сделано неверное заключение о статистической значимости, когда на самом деле никаких статистически значимых различий или связей нет.</span>

Если значение p-value меньше или равно уровню значимости, то мы можем отвергнуть нулевую гипотезу (о том, что нет статистически значимых различий или связей) и сделать вывод о статистической значимости результатов. Если же значение p-value больше уровня значимости, то мы не можем отвергнуть нулевую гипотезу и делаем вывод о том, что статистически значимых различий или связей не обнаружено.

В контексте статистики и тестирования гипотез "альфа" обычно обозначает уровень значимости, который представляет собой вероятностную меру того, насколько сильным должно быть статистическое доказательство, чтобы отвергнуть нулевую гипотезу. Уровень значимости, обозначаемый символом α, определяет пороговое значение вероятности ошибки первого рода, которое исследователь готов принять.

Например, если уровень значимости α установлен на 0.05 (часто используемый стандартный порог), это означает, что исследователь готов допустить вероятность ошибки первого рода в 5%. То есть, если p-значение, полученное из статистического теста, меньше или равно α, нулевая гипотеза отвергается.

## Уровень доверия или доверительная вероятность

1 - α называется уровнем доверия или доверительной вероятностью в контексте статистического тестирования гипотез. 
<span style="background:#b1ffff">Уровень доверия отражает вероятность того, что результаты теста не будут ложноположительными. </span>Давайте рассмотрим это подробнее:

Высокий уровень доверия (например, 95% или 99%) означает, что мы с высокой вероятностью можем доверять результатам теста, избегая ложных положительных выводов. Однако увеличение уровня доверия (уменьшение альфа) требует большего объема данных и более строгих условий тестирования.

Это ключевая концепция в статистическом тестировании, позволяющая оценить надежность и достоверность полученных результатов. Выбор соответствующего уровня доверия зависит от конкретных требований и контекста теста.

## Ошибка второго рода

> [!tip] Мы делаем ложный вывод о том, что эффект отсутствует, когда на самом деле такой эффект есть
> Ошибка происходит, когда нулевая гипотеза не отвергается, когда она на самом деле неверна. 
> Вероятность ошибки второго рода зависит от размера выборки, уровня значимости и эффекта, который мы хотим обнаружить.

## Уровень ошибки второго рода (бета)

Бета-ошибка, или ошибка второго рода, возникает в статистических тестах, когда нулевая гипотеза неверно принята, хотя она должна была быть отвергнута. 
<span style="background:#b1ffff">В контексте анализа данных это означает, что тест не обнаружил статистически значимых различий между группами или переменными, хотя эти различия существуют в генеральной совокупности.</span>

Например, в A/B-тестировании бета-ошибка возникает, когда тест не обнаруживает значимых различий между контрольной и тестовой группами, хотя эти различия на самом деле существуют. Это может привести к неправильному выводу о том, что изменение не оказывает значимого влияния, когда на самом деле оно может быть значимым.

Уменьшение бета-ошибки обычно достигается увеличением размера выборки или повышением мощности статистического теста. Однако это может привести к увеличению вероятности совершения другой ошибки - альфа-ошибки (ошибки первого рода).
## Мощность (1 - бета)


Мощность теста -  это вероятность того, что статистический тест правильно отвергнет нулевую гипотезу, когда альтернативная гипотеза верна. 
Мощность теста обозначается как 1 - β, где β — это вероятность ошибки второго рода. 

<span style="background:#b1ffff">Высокая мощность теста означает, что тест с большой вероятностью обнаружит реальный эффект, если он существует.</span>

Факторы, Влияющие на Мощность Теста:
1. **Размер эффекта (Effect Size)**: Чем больше размер эффекта, тем выше мощность теста. Размер эффекта — это величина различий между контрольной и экспериментальной группами.
2. **Размер выборки (Sample Size)**: Увеличение размера выборки повышает мощность теста. Большие выборки обеспечивают более точные оценки и снижают вероятность случайных ошибок.
3. **Уровень значимости (Alpha Level)**: Уровень значимости (α) — это вероятность ошибки первого рода. Снижение α снижает мощность теста, так как требуется больше данных для достижения статистической значимости.
4. **Вариативность данных (Data Variability)**: Меньшая вариативность в данных (например, меньшее стандартное отклонение) повышает мощность теста, так как различия между группами становятся более отчетливыми.

## Уровень статистической значимости (P-value)

<span style="background:#b1ffff">Уровень статистической значимости (p-value) - это вероятность получить результаты, как минимум, столь же экстремальные, как наблюдаемые, при условии, что нулевая гипотеза верна.</span>

Если p-value очень маленькое (обычно меньше заранее заданного уровня значимости), то мы можем отвергнуть нулевую гипотезу и сделать вывод, что есть статистически значимые различия или связь между изучаемыми переменными. Если же p-value большое, то мы не можем отвергнуть нулевую гипотезу и не можем сделать вывод о наличии статистически значимых различий или связи.

Уровень статистической значимости позволяет оценить вероятность того, что полученные результаты случайны, а также определить, насколько надежными и интерпретируемыми являются результаты исследования.

## MDE

<span style="background:#b1ffff">MDE (Minimum Detectable Effect) определяется как минимальный размер эффекта, который эксперимент может обнаружить с заданной статистической значимостью и мощностью.</span>

Расчет MDE включает несколько шагов:

1. **Выбор статистической мощности**: Обычно выбирают уровень мощности, например, 80% или 90%. Мощность связана с вероятностью обнаружить реальный эффект, если он существует.
2. **Определение уровня статистической значимости (альфа)**: Обычно выбирают уровень значимости 0,05 или 0,01. Это уровень, при котором результаты считаются статистически значимыми.
3. **Оценка стандартного отклонения (σ)**: Оценивается стандартное отклонение показателя в выборке.
4. **Выбор метода анализа**: В зависимости от типа данных и дизайна эксперимента выбирается соответствующий метод анализа (например, t-тест для сравнения средних значений или χ²-тест для сравнения долей).
5. **Расчет MDE**: Используя выбранную мощность, уровень значимости, стандартное отклонение и метод анализа, рассчитывается минимальный размер эффекта, который эксперимент может обнаружить.
    
Например, для теста сравнения средних значений двух групп MDE может быть рассчитан как разница между средними значениями, которая является статистически значимой при выбранной мощности и уровне значимости.

# 2. ПРОВЕРКА ГИПОТЕЗ

Узнаем, как появилась идея проверять гипотезы. Создадим собственный критерий принятия решений. Рассмотрим популярные критерии для типичных метрик и поговорим об их ограничениях.

Основная идея статистической проверки гипотез заключается в том, чтобы использовать статистические методы для определения того, насколько вероятно, что некоторое наблюдаемое явление или различие между двумя выборками является результатом случайной вариации или действительно является статистически значимым.

Для этого используется процесс, включающий формулирование нулевой гипотезы, которая утверждает, что никакого статистически значимого эффекта нет, а также альтернативной гипотезы, которая утверждает, что есть статистически значимый эффект. Затем используются статистические тесты, чтобы определить вероятность того, что нулевая гипотеза может быть отвергнута на основе данных выборки.

Если вероятность отвержения нулевой гипотезы достаточно высока, то это может указывать на то, что наблюдаемый эффект является реальным и не случайным. Если вероятность низкая, то мы не можем отвергнуть нулевую гипотезу и делаем вывод, что наблюдаемое различие между выборками может быть случайным и не имеет статистической значимости.


# 3. ДИЗАЙН ЭКСПЕРИМЕНТА

Научимся подбирать оптимальные параметры для запуска эксперимента. Определять продолжительность, размер выборки и минимальный эффект, который возможно обнаружить.

## Размер выборки

1.  Определите минимально значимый эффект (MDE), то есть минимальную разницу между двумя группами, которая будет иметь для вас практический смысл и которую вы хотите обнаружить с помощью теста. MDE зависит от бизнес-цели вашего теста.
2.  Определите уровень значимости (alpha), который показывает вероятность ложно положительных результатов, то есть того, что вы обнаружите статистически значимые различия между группами при отсутствии реальных различий.
3.  Определите мощность (power), которая показывает вероятность обнаружения статистически значимых различий между группами при наличии реальных различий.
4.  Оцените стандартное отклонение (standard deviation) величины, которую вы хотите измерить. Это может быть, например, конверсия на сайте или время, проведенное на странице.

## Проверка нормальности распределения данных

Тест Шапиро-Уилка - это статистический тест на нормальность распределения. Он используется для проверки гипотезы о том, что наблюдаемая выборка имеет нормальное распределение вероятностей.
Идея теста заключается в том, чтобы сравнить эмпирическую функцию распределения (ECDF) выборки с теоретической функцией распределения нормальной случайной величины. Критерием сравнения служит мера отклонения между двумя функциями - коэффициент Шапиро-Уилка (W).

Основные особенности теста Шапиро-Уилка:
1.  Параметрический тест: тест Шапиро-Уилка является параметрическим, то есть требует предположения о распределении выборки.
2.  Чувствительность: тест Шапиро-Уилка достаточно чувствителен к малым отличиям от нормального распределения

## Проверка выборок на равенство дисперсий

Тест Бартлетта для проверки равенства дисперсий в группах A и B.

## Виды распределений 

### Нормальное распределение (распределение Гаусса)
Нормальное распределение является одним из самых распространенных распределений в статистике. Оно имеет симметричную колоколообразную форму и характеризуется средним значением и стандартным отклонением. Многие естественные и социальные явления могут быть приближены нормальным распределением.

![[Pasted image 20230608105536.png]]
![[Pasted image 20230608110444.png]]

### Равномерное распределение

Равномерное распределение предполагает равномерное распределение вероятностей в заданном интервале. Все значения в этом интервале имеют одинаковую вероятность.

![[Pasted image 20230608105702.png]]

### Биномиальное распределение

Биномиальное распределение используется для моделирования ситуаций, где есть два возможных исхода (например, успех или неудача) и фиксированное число испытаний. Оно характеризуется параметрами, такими как вероятность успеха и количество испытаний.

![[Pasted image 20230608105925.png]]

### Распределение Бернулли

это простейшее дискретное вероятностное распределение, которое моделирует случайный эксперимент с двумя возможными исходами: успехом (событие с вероятностью p) и неудачей (событие с вероятностью 1-p). Оно названо в честь швейцарского математика Жака Бернулли.

В распределении Бернулли есть один параметр, называемый вероятностью успеха (p). Этот параметр указывает на вероятность успеха в каждом испытании. Вероятность неудачи (q) равна (1 - p).
Вероятность того, что случайная величина X примет значение 1 (успех) обозначается как P(X=1) = p, а вероятность принятия значения 0 (неудача) обозначается как P(X=0) = 1-p.
Распределение Бернулли имеет следующие особенности:
-   Значения случайной величины X принимают только два возможных значения: 0 и 1.
-   Математическое ожидание распределения Бернулли равно p, а дисперсия равна p(1-p).

![[Pasted image 20230608110247.png]]

Распределение Бернулли широко используется для моделирования бинарных случайных событий, таких как монетные броски (где успех может быть выпадение орла, а неудача - выпадение решки), или события успеха/неудачи в экспериментах Бернулли, где проводится одно испытание с двумя возможными исходами.

### Экспоненциальное распределение
Экспоненциальное распределение описывает время между последовательными событиями, которые происходят независимо друг от друга. Оно имеет положительную скошенную форму и характеризуется параметром интенсивности.

![[Pasted image 20230608110223.png]]
    
### Хи-квадрат распределение (распределение Пирсона)
Хи-квадрат распределение часто используется в статистических тестах и моделях, связанных с категориальными данными. Оно возникает при суммировании квадратов независимых стандартных нормально распределенных случайных величин.

![[Pasted image 20230608110331.png]]

### Стьюдента распределение
Стьюдента распределение используется в t-тесте и других статистических процедурах для проверки статистической значимости различий между выборками. Оно имеет колоколообразную форму, но более тяжелые хвосты, чем нормальное распределение.

![[Pasted image 20230608110354.png]]

# 4. ТЕСТИРОВАНИЕ ДИЗАЙНА

Разберёмся как проверять корректность дизайна. Узнаем, зачем нужно проводить синтетические A/A и A/B эксперименты на исторических данных.

## Синтетические тесты 

В статистике термин "синтетические тесты" может относиться к тестам, в которых данные генерируются программно, чтобы имитировать определенные распределения или сценарии, которые могут возникнуть в реальных данных.

Такие тесты используются для оценки статистических методов или алгоритмов на их способность обрабатывать различные типы данных. Они могут помочь проверить работоспособность метода в экстремальных условиях или на необычных наборах данных.

Синтетические тесты могут быть полезны для улучшения статистических методов и алгоритмов, путем выявления и исправления проблем в их работе на ранней стадии. Однако, как и с любым тестированием, результаты синтетических тестов могут отличаться от реальных данных, поэтому они должны использоваться в сочетании с тестированием на реальных данных.

## A/A-тест

A/A-тест - это эксперимент, в котором две идентичные группы случайным образом разделяются на две подгруппы, каждая из которых получает один и тот же вариант контрольной версии. Этот тест используется для проверки точности и надежности системы тестирования.

A/A-тест может быть полезен для проверки надежности системы тестирования, прежде чем запускать более сложные A/B-тесты, которые требуют значительных ресурсов и времени. Он также может использоваться для проверки, насколько хорошо случайное разделение на группы работает и насколько точно система может измерять результаты тестирования.

В A/A-тесте не должно быть значимых различий между двумя подгруппами, так как они получают одинаковый контрольный вариант. Если в результате тестирования будет обнаружено статистически значимое различие между двумя подгруппами, это может указывать на проблемы с системой тестирования, например, на ошибки при разделении на подгруппы или недостаточную мощность теста.

Однако, как и в любом статистическом тесте, возможны ложноположительные результаты, т.е. статистически значимые различия между подгруппами, когда на самом деле различий нет. Обычно устанавливают уровень значимости (alpha), который определяет вероятность получения ложноположительных результатов. Обычно уровень значимости устанавливают на уровне 0,05 или 0,01, что означает, что вероятность получить ложноположительный результат не должна превышать 5% или 1%.

Таким образом, процент различий между группами A/A-теста должен быть меньше уровня значимости, установленного для теста, чтобы считать тест успешным. Если различия между группами превышают уровень значимости, это может указывать на проблемы с тестированием и требовать дополнительных проверок и корректировок.


# 5. ДОВЕРИТЕЛЬНЫЕ ИНТЕРВАЛЫ

Познакомимся с методом бутстрэп. Научимся строить доверительные интервалы для произвольных метрик и узнаем, как принимать решения на основе доверительных интервалов.


# 6. ПОВЫШЕНИЕ ЧУВСТВИТЕЛЬНОСТИ ТЕСТОВ

Рассмотрим актуальные способы повышения чувствительности A/B-тестов и применим их на практике. 
Научимся сокращать размер выборки, необходимый для проведения эксперимента.

## Сокращение выборки

1.  Определите минимально значимый эффект. Минимально значимый эффект (MDE) - это минимальная разница между группами, которая вам нужна, чтобы считать эксперимент успешным. Определение MDE позволяет определить необходимый размер выборки для достижения статистической значимости при данном уровне мощности. Чем меньше MDE, тем меньше необходимый размер выборки.
2.  Уменьшите уровень значимости (alpha). Уменьшение уровня значимости, например, с 5% до 1%, может сократить необходимый размер выборки. Однако это также может увеличить вероятность ложноположительных результатов.
3.  Используйте более точные методы анализа данных. Использование более точных методов анализа данных, например, байесовских методов, может помочь сократить размер выборки.
4.  Определите более узкую целевую аудиторию. Если вы можете определить более узкую целевую аудиторию, то вам может потребоваться меньший размер выборки для достижения статистической значимости.
5.  Используйте более эффективные методы выборки. Использование более эффективных методов выборки, например, стратифицированной случайной выборки или кластеризованной выборки, может помочь сократить размер выборки.

## Способы ускорения тестов

1.  Увеличьте размер выборки. Больший размер выборки увеличивает мощность теста и позволяет лучше обнаруживать различия между группами.
2.  Уменьшите уровень значимости (alpha). Уменьшение уровня значимости, например, с 5% до 1%, увеличит чувствительность теста, но может увеличить вероятность ложноположительных результатов.
3.  Измените соотношение групп. Если вы предполагаете, что одна группа будет более отзывчивой, чем другая, вы можете изменить соотношение групп. Например, вы можете сделать 70% тестируемой группы и 30% контрольной группы.
4.  Используйте более чувствительные метрики. Использование более чувствительных метрик, например, увеличение доли кликов вместо увеличения количества кликов, может помочь обнаружить более мелкие различия между группами.
5.  Проводите тест на более длительный период времени. Увеличение длительности теста может помочь обнаружить более маленькие различия между группами. Однако это может привести к увеличению времени, необходимому для завершения теста.

## Продвинутые методы ускорения тестов

1.  Сегментация аудитории: эта техника заключается в том, чтобы разбить аудиторию на более мелкие группы в зависимости от их характеристик или поведения. Это может помочь выявить различия между группами и определить, какие факторы могут влиять на результаты тестирования.
2.  Платные просмотры: этот метод заключается в том, чтобы заплатить за просмотры тестовой версии сайта или приложения, чтобы получить больше трафика и данные для тестирования. Это может помочь собрать больше данных и сократить время, необходимое для проведения тестирования.
3.  Байесовский подход: это подход, основанный на теории вероятностей, который позволяет учитывать предыдущие знания или опыт при анализе данных и сделать более точные выводы о результате тестирования.
4.  Анализ временных рядов: это метод, который позволяет анализировать изменения в метриках во времени и определить, какие изменения связаны с изменениями в тестовой версии сайта или приложения.
5.  Мультирукие бандиты: это метод многоруких бандитов, который позволяет оптимизировать выбор варианта в зависимости от характеристик пользователя и прошлых результатов тестирования.
6.  Статистические методы: включают в себя методы, такие как анализ дисперсии, критерий Крускала-Уоллиса, тест Фишера и другие, которые позволяют более точно анализировать данные и делать выводы о результате тестирования.

## Байесовский подход

В AB-тестировании Байесовский подход используется для оценки вероятностей относительных различий между вариантами теста.

Когда мы проводим AB-тест, мы сравниваем результаты двух групп - контрольной и тестовой. Для этого мы сравниваем метрики, такие как конверсия или средний чек, и проверяем, есть ли статистически значимые различия между группами.

В Байесовском AB-тестировании мы используем априорное распределение, чтобы определить начальную вероятность различий между группами, а затем обновляем ее с учетом новых данных, полученных во время теста, чтобы получить постериорное распределение вероятности.

Это позволяет нам получить более точную оценку относительных различий между группами, а также позволяет нам принимать решения на основе вероятности, что различия между группами настоящие и стоят дальнейшего исследования, или же что различия случайны и не нуждаются в дополнительном исследовании.

## Multi-armed bandits

Мультирукие бандиты - это метод многоруких бандитов, который используется для оптимизации выбора варианта в A/B-тестировании. Он используется для оптимизации выбора варианта, который будет показан пользователю в зависимости от его характеристик.

В традиционном A/B-тестировании мы выбираем один вариант и сравниваем его с контрольной группой, чтобы увидеть, какой вариант лучше работает. Метод многоруких бандитов позволяет выбирать между несколькими вариантами одновременно, в зависимости от того, какие характеристики у пользователя.

В процессе тестирования каждый вариант получает свою "руку", которая может быть нажата пользователем. Каждый раз, когда пользователь посещает страницу, алгоритм выбирает, какой вариант показать пользователю, чтобы максимизировать вероятность того, что он совершит целевое действие (например, сделает покупку).

Мультирукие бандиты используются для оптимизации выбора варианта, основываясь на статистических моделях, которые учитывают прошлые результаты каждого варианта и его текущую производительность. Это позволяет оптимизировать выбор варианта, чтобы максимизировать эффект от тестирования и получить максимальное количество целевых действий.

# 7. СТАТИСТИЧЕСКИЕ КРИТЕРИИ

1.  T-критерий Стьюдента (Student's t-test) - используется для проверки гипотезы о том, что две выборки (обычно экспериментальная и контрольная) имеют одинаковые средние значения. T-критерий Стьюдента может быть применен, если выборки имеют нормальное распределение и равные дисперсии.
2.  Z-критерий (Z-test) - аналогичен t-критерию Стьюдента, но может быть использован, когда размер выборки достаточно большой, чтобы можно было считать, что выборочное среднее имеет нормальное распределение.
3.  Критерий АНОВА (ANOVA) - используется для сравнения средних значений трех и более выборок. Он позволяет определить, есть ли статистически значимые различия между группами.
4.  Критерий хи-квадрат (χ2) - используется для анализа категориальных данных. Он позволяет определить, есть ли статистически значимые различия между наблюдаемыми и ожидаемыми частотами в таблице сопряженности.
5.  Критерий Манна-Уитни (Mann-Whitney U test) - аналогичен t-критерию Стьюдента, но может быть использован для несвязанных выборок и/или когда распределение не является нормальным.
6.  Критерий Крускала-Уоллиса (Kruskal-Wallis test) - аналогичен критерию АНОВА, но может быть использован для несвязанных выборок и/или когда распределение не является нормальным.

## T-критерий Стьюдента

T-критерий применяется, когда **неизвестны параметры генеральной совокупности, и их нужно оценить на основе данных выборки.** T-критерий используется в случаях, когда размер выборки маленький или неизвестно стандартное отклонение генеральной совокупности. T-критерий более устойчив к отклонениям от нормальности и дает более консервативные результаты при малых размерах выборки.

1.  Зависимость от размера выборки: t-критерий Стьюдента чувствителен к размеру выборки. С увеличением размера выборки t-значение уменьшается и при достаточно большой выборке (обычно более 30 наблюдений в каждой группе) различия между группами становятся статистически значимыми даже при небольших различиях между средними значениями.
2.  Нормальность распределения: t-критерий Стьюдента предполагает, что данные в каждой группе имеют нормальное распределение. Если распределение не является нормальным, то результаты теста могут быть неточными.
3.  Однородность дисперсий: t-критерий Стьюдента также предполагает, что дисперсии данных в каждой группе совпадают. Если дисперсии различаются, то результаты теста могут быть неверными.
4.  Независимость выборок: t-критерий Стьюдента применяется только для независимых выборок. Если выборки зависимы, то следует использовать парный t-критерий Стьюдента.
5.  Опасность множественных сравнений: при сравнении более двух выборок t-критерий Стьюдента может давать ложно положительные результаты. При использовании нескольких t-тестов следует применять поправку на множественные сравнения, например, метод Бонферрони.

## U-критерий манна-уитни

1.  Независимость выборок: U-критерий Манна-Уитни применяется только для независимых выборок.
    
2.  Ранги: вместо исходных значений данных используются ранги, то есть каждое значение заменяется его порядковым номером в упорядоченном ряду. Это делается для того, чтобы избежать предположений о распределении данных и учитывать только порядок значений.
    
3.  Нет требований к нормальности распределения: U-критерий Манна-Уитни не предполагает нормальность распределения данных. Это делает его более устойчивым к выбросам и искаженным данным.
    
4.  Равенство выборочных размеров: U-критерий Манна-Уитни требует, чтобы выборочные размеры были примерно равными. Если размеры выборок значительно отличаются, то могут возникнуть проблемы с оценкой значимости различий между группами.
    
5.  Сложность интерпретации: интерпретация результатов U-критерия Манна-Уитни может быть сложной, так как это не просто сравнение средних значений, а сравнение ранговых сумм выборок.


## Z-критерий

Z-критерий основан на нормальном распределении данных и применяется, когда **известны параметры генеральной совокупности, такие как среднее и стандартное отклонение**. Он широко используется, когда размер выборки достаточно велик (обычно более 30 наблюдений). Z-критерий позволяет проверить гипотезы о различиях между выборкой и генеральной совокупностью.

T-критерий, с другой стороны, применяется, когда **неизвестны параметры генеральной совокупности, и их нужно оценить на основе данных выборки.** T-критерий используется в случаях, когда размер выборки маленький или неизвестно стандартное отклонение генеральной совокупности. T-критерий более устойчив к отклонениям от нормальности и дает более консервативные результаты при малых размерах выборки.

## BOOTSTRAP

1.  Не требует предположений о распределении: метод Bootstrap не предполагает какое-либо определенное распределение данных, поэтому он может быть использован для оценки статистических характеристик любых данных.
    
2.  Хорошая точность: метод Bootstrap позволяет получить точные оценки статистических характеристик даже в том случае, если выборка имеет малый размер или распределение данных неизвестно.
    
3.  Может использоваться для различных статистик: Bootstrap можно использовать для оценки различных статистик, включая среднее значение, медиану, стандартное отклонение, коэффициент корреляции и другие.
    
4.  Используется для оценки доверительных интервалов: одной из основных целей применения Bootstrap является оценка доверительных интервалов для различных статистик.
    
5.  Ресемплинг с возвращением: при выборке наблюдений из исходной выборки в Bootstrap используется ресемплинг с возвращением, что позволяет использовать каждое наблюдение несколько раз, увеличивая точность оценки.

# 8-9. CUPED И СТРАТИФИКАЦИЯ

Научимся применять CUPED и стратификацию — продвинутые методы повышения чувствительности A/B-тестов, основанные на использовании дополнительной информации.

## CUPED

CUPED - это метод, который позволяет снизить разброс (variance) между группами в A/B-тесте, учитывая не только переменную, которую вы тестируете, но и другие факторы, которые могут влиять на результаты теста. CUPED основан на разделении выборки на блоки (partitions) и корректировке средних значений в каждом блоке на основе средних значений других переменных, которые могут влиять на результаты теста. Этот метод позволяет уменьшить ошибку измерения и повысить чувствительность теста.

## Стратификация

  
Стратификация - это метод разделения генеральной совокупности на подгруппы или страты в зависимости от определенных характеристик, таких как возраст, пол, географическое расположение и т. д. Этот метод может уменьшить дисперсию данных внутри каждой страты по сравнению с дисперсией данных в генеральной совокупности.

В основе этого метода лежит идея, что данные внутри каждой страты более однородны, чем данные в генеральной совокупности в целом. Поскольку внутри страт данные более схожи между собой, это уменьшает дисперсию внутри страты. Затем, при анализе результатов, усредненные значения из каждой страты могут быть взвешены по размеру страты, что позволяет получить более точные оценки параметров генеральной совокупности.

Таким образом, стратификация помогает уменьшить дисперсию путем увеличения однородности данных внутри каждой страты, что делает оценку параметров более точной и надежной.

# 10. МНОЖЕСТВЕННОЕ ТЕСТИРОВАНИЕ

Иногда для решения одной проблемы выдвигается сразу несколько гипотез, одновременная проверка которых влияет на дизайн эксперимента. Познакомимся с техниками множественного тестирования и параллельным проведением большого числа экспериментов.

# 11. СПЛИТИЛКА ТРАФИКА

Гипотез становится всё больше, и нам не хватает наблюдений, чтобы проверять их все одновременно. Обсудим, когда можно использовать пользователей одновременно в нескольких экспериментах и как это делать.

# 12. АНАЛИЗ МЕТРИК ОТНОШЕНИЯ

Z-критерий используется часто для метрик отношений (например, конверсии), потому что эти метрики имеют биномиальное распределение, которое может быть приближено нормальным распределением при достаточно больших размерах выборки. В частности, когда количество успехов и неудач в каждой группе достаточно большое (обычно, когда количество успехов и неудач в каждой группе больше 5), то можно использовать нормальное распределение для аппроксимации распределения выборочной доли успехов и расчета статистической значимости различий между группами с помощью Z-критерия.

Таким образом, использование Z-критерия для метрик отношений удобно и практично, так как он не требует знания исходного распределения, а только выборочных средних и стандартных отклонений, что делает его простым в использовании и интерпретации результатов. Однако, важно помнить, что при малых размерах выборки следует использовать более точные методы, такие как точный тест Фишера.

# 13-14. ПОЛНЫЙ ПАЙПЛАЙН A/B-ТЕСТИРОВАНИЯ

