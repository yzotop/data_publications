---
tags:
  - data
link: https://habr.com/ru/articles/829336/
source: habr
data_type:
  - AB tests
---
## Введение

**Бутстрап** — это вычислительный статистический метод, который позволяет оценить распределение выборочной статистики (например: медиана, эксцесс, куртозис, среднее значение) путем многократной генерации выборок методом Монте-Карло на основе уже имеющейся выборки.

> Проще говоря, бутстрап позволяет «притворяться» генеральной совокупностью, многократно создавая «псевдовыборки» из исходной выборки с возвращением

**Бутстрап-выборка** — это псевдовыборка с повторениями, извлеченная из исходной выборки, то есть в бутстрап-выборке может попасться несколько раз одно и то же наблюдение из исходной выборки. Более того, бутстрап-выборка должна быть равной по объему исходной выборке.

---

Фактически, когда мы используем бутстрап, мы хотим по имеющейся выборке сделать выводы об определенной статистике в генеральной совокупности. Мы много раз извлекаем из исходной выборки бутстрап-выборки, считаем по ним статистику, строим ее распределение, считаем доверительный интервал и делаем выводы относительно него. Ну или можем просто взять, например, среднее или медианное значение, чтобы получить точечную оценку.

Обычно бутстрап применяется в следующих случаях:

- теоретическое распределение данных неизвестно;
    
- объем выборки мал для прямой статистической оценки;
    
- нет параметрических или непараметрических аналогов;
    
- необходима оценка сложных статистик, для которых сложно получить аналитические формулы.
    

Ключевое преимущество бутстрапа заключается в том, что его можно применять в широком спектре задач, даже тогда, когда все остальные методы, как параметрические, так и непараметрические, бессильны.

Данный метод **не требует предположений о распределении** данных от исследователя. Единственное условие, которое необходимо выполнить — репрезентативность выборки.

## Применение

Теперь давайте немного подробнее остановимся на том, где на практике применяется бутстрапирование. Бутстрап очень распространен в Data Science, а именно в машинном обучении, он позволяет оценивать качество моделей, неопределенность предсказаний и многое другое.

- **Оценка качества модели**
    
    Бутстрап используется для получения более точных оценок метрик качества модели, таких как точность, полнота, F1-мера и т.д. Из исходного набора данных многократно формируются бутстрап-выборки путем случайного отбора с повторением. Затем на каждой выборке обучается и тестируется модель, после чего метрики усредняются. Это позволяет снизить смещение оценок и получить доверительные интервалы.
    
- **Оценка неопределенности предсказаний**
    
    В нейронных сетях бутстрап применяется для оценки неопределенности (uncertainty) предсказаний модели. Для этого создаются несколько моделей на разных бутстрап-выборках и делаются предсказания каждой из них. Разброс предсказаний характеризует неопределенность. Это важно, например, для задач с высокой ценой ошибки, где нужно знать, насколько модель уверена в своем ответе.
    
- **Интерпретация и анализ признаков**
    
    Обучая модели на бутстрап-выборках, можно оценить важность признаков по частоте их использования в деревьях (для случайного леса) или по разбросу весов (для нейросетей). Это дает понимание, какие признаки вносят наибольший вклад в предсказания модели.
    
- **Активное обучение**
    
    Бутстрап используется в активном обучении (active learning) — подходе, где модель сама выбирает наиболее информативные примеры для разметки и дообучения. Одна из стратегий — запрашивать разметку для примеров, где предсказания моделей, обученных на разных бутстрап-выборках, сильнее всего различаются между собой.
    
- **Ансамблевые методы**
    
    Бутстрап лежит в основе некоторых ансамблевых алгоритмов, таких как бэггинг (bagging) и случайный лес (random forest). Эти методы строят множество базовых моделей на различных бутстрап-выборках из обучающих данных. Затем предсказания базовых моделей объединяются, что чаще всего дает более точный и стабильный результат по сравнению с одиночной моделью.
    

Таким образом, бутстрап позволяет улучшить качество, надежность и интерпретируемость моделей машинного обучения и применяется в достаточно широком спектре задач. Он особенно полезен при ограниченном размере обучающей выборки, помогая максимально эффективно использовать доступные данные.

## Ограничения

У бутстрапа есть несколько ограничений. Сперва рассмотрим те, что **влияют на точность результатов**, это:

- количество сгенерированных бутстрап-выборок (псеводвыборок);
    
- размер исходной выборки.
    

Чем больше количество наблюдений в исходной выборке и бутстрап-выборок, тем точнее получится результат, и наоборот. Количество сгенерированных бутстрап-выборок имеет здесь большее значение.

В любом случае, данные факторы не являются блокирующими, то есть можно работать и с маленькими выборками, и с относительно небольшим количеством бутстрап-выборок. В таком случае, просто нужно правильно интерпретировать результат и понимать последствия, о которых будет сказано в разделе проблем.

---

Также бутстрап **может быть ресурсоемким**, особенно при работе с большими объемами данных и большим количеством итераций, так как нам приходится извлекать много бутстрап-выборок из исходной выборки.

Как нам известно из комбинаторики, количество таких уникальных выборок ![n^n](https://habrastorage.org/getpro/habr/upload_files/3b5/a89/287/3b5a892875a4a9aa57dc3cdb5858ad18.svg), то есть алгоритмически бутстрапирование будет нам обходиться в ![O(n^n)](https://habrastorage.org/getpro/habr/upload_files/dbf/65a/327/dbf65a327370caf58f513be6416dbf2e.svg), что очень грустно.

На самом деле, никто так не делает, все ориентируются на собственные вычислительные мощности, поэтому никогда не извлекаются все уникальные бутстрап-выборки, а просто каждый раз берется случайная псевдовыборка ![N](https://habrastorage.org/getpro/habr/upload_files/98c/242/a51/98c242a5153a2edaf13f910961e705ce.svg)-ое количество раз. Такие выборки маловероятно, но могут быть неуникальными, и, даже так, фактически, для нас это не имеет значения. То есть для бутстрапирования используется симуляция методом Монте-Карло.

Подытоживая, точность результата бутстрапирования, как уже было сказано, определяется количеством псевдовыборок, но, с другой стороны, это очень дорого обходится по вычислительным мощностям.

Таким образом, необходимо приходить к компромиссу между точностью и ресурсоемкостью бутстрапирования, что достигается использованием метода Монте-Карло (в частности, управлением количеством псевдовыборок ![N](https://habrastorage.org/getpro/habr/upload_files/141/10b/558/14110b55857bae573e0561097096e8ec.svg)).

---

Последний, но очень важный нюанс заключается в предназначении бутстрапа. Бутстрап является замечательным методом для работы в средиземье, однако **в крайнеземье бутстрап показывает себя заметно хуже**. Это происходит по той причине, что в бутстрап-выборки приходит лишь небольшое число наблюдений из хвостов исходной выборки.

То есть с помощью бутстрапа мы можем анализировать и строить выводы о средних тенденциях, но не о крайних. Например, мы можем построить доверительный интервал для медианы, но доверительный интервал для 99% процентиля будет крайне неточным.

## Схема бутстрапа

### Эфронов доверительный интервал

Итак, давайте перейдем к рассмотрению схемы бутстрапа. Изначально, у нас имеется выборка, которая является частью генеральной совокупности. Мы хотим изучить какую-нибудь статистику и сделать относительно нее выводы по генеральной совокупности. Именно в этом ключе мы будем рассматривать исходную выборку.

Далее, мы определяем сколько бутстрап-выборок (размера как исходная выборка) наши вычислительные мощности позволяют извлечь из исходной выборки. Извлекаем ![N](https://habrastorage.org/getpro/habr/upload_files/ecd/630/dcb/ecd630dcb1acdb9ea0ed9d08940220b4.svg)-ое количество псевдовыборок с повторениями.

По каждой полученной бутстрап-выборке считаем статистику, относительно которой хотим оценить генеральную совокупность.

Когда мы подсчитали все статистики, мы строим распределение данной статистики и подсчитываем 2.5% и 97.5% квантили.

Так и выглядит алгоритм. Теперь давайте опишем его математически.

**Обозначения**:

- ![\theta](https://habrastorage.org/getpro/habr/upload_files/32d/0f4/344/32d0f4344b5b8e7456d7f07cdd9fada8.svg) — статистика по генеральной совокупности;
    
- ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/02f/80a/4da/02f80a4da53877d124e86df4daeb7458.svg) — выборочная статистика;
    
- ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/520/f84/b92/520f84b924f92329e2b401530565aa0e.svg) — статистика по бутстрап-выборке;
    
- ![N](https://habrastorage.org/getpro/habr/upload_files/767/1b7/d0c/7671b7d0ce4bc68bb0a551697c58fccb.svg) — количество бутстрап-выборок;
    
- ![n](https://habrastorage.org/getpro/habr/upload_files/1c8/62c/e36/1c862ce360db4babb4f46d3988391603.svg) — объем исходной выборки (то есть и каждой бутстрап-выборки);
    
- ![\alpha](https://habrastorage.org/getpro/habr/upload_files/c49/7aa/dac/c497aadacbdf1c3a29e78251c1426599.svg) — уровень значимости.
    

**Алгоритм**:

1. Выборка представляет собой часть большей генеральной совокупности, которую вы хотите изучить, и является репрезентативной.
    
2. Из исходной выборки случайным образом с повторением (один и тот же элемент может быть выбран несколько раз) выбирается ![n](https://habrastorage.org/getpro/habr/upload_files/b4f/455/208/b4f455208392622bf10fbd7c75925671.svg) элементов, формируя бутстрап-выборку.
    
3. По сформированной бутстрап-выборке считается ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/535/971/314/5359713143cc00f91b16f9eb6f562381.svg) статистика.
    
4. Повторяем шаги 2 и 3 ![N](https://habrastorage.org/getpro/habr/upload_files/f0b/851/150/f0b8511509804aa69ab12aae394ea68e.svg) раз (например, 10000, 100000 или 1000000 раз).
    
5. Находим Эфронов доверительный интервал, то есть значения, меньше которых 2.5% и 97.5% значений (по необходимости % значений вне границ можно выбрать самостоятельно, например, 1%, 0.1% и т.д.). Сам же доверительный интервал имеет следующий вид:
    

![CI = [ \hat \theta^{*}_{ \frac { \alpha }{ 2 }}; \hat\theta^*_{1 - \frac{\alpha}{2}}]](https://habrastorage.org/getpro/habr/upload_files/d0c/cc8/088/d0ccc8088506ac16bcc4bdc54666f24b.svg)

Итак, схема, о которой было рассказано, является классической. И построенный по этой схеме доверительный интервал называется **Эфронов доверительный интервал**.

Помимо Эфронова доверительного интервала существуют **доверительный интервал Холла** и **t-процентильный доверительный интервал**. Преимущество последних двух заключается в том, что они дают несмещенную оценку выборочной статистики, так как при их расчете происходит центрирование.

> Эфронов доверительный интервал дает **смещенную оценку**, а t-процентильный и Холла — **несмещенную**.

Смещение оценки может произойти если в исходной выборке очень мало наблюдений, или распределение имеет тяжелые хвосты, или же распределение выборочной статистики перекошено, мультимодально, или по другим причинам, связанным с видом распределения сильно отличающимся от традиционных.

В частности, говоря о t-процентильном доверительном интервале, он несколько шире Эфронова и Холла, что приближает его к аналитическим аналогам, по сравнению с другими двумя, которые заметно уже, то есть в меньшей степени учитывают вариативность статистики.

### Доверительный интервал Холла

Итак, как уже было сказано, алгоритм построения доверительного интервала Холла **дает несмещенную оценку**. Достигается это **при помощи центрирования**, которое заключается в том, что из каждой полученной статистики по бутстрап-выборке вычитается статистика по исходной выборке.

Помимо центрирования и небольшой корректировки формулы расчета доверительного интервала данная схема ничем больше не отличается. Рассмотрим схему по пунктам, вспомнив обозначения:

**Обозначения**:

- ![\theta](https://habrastorage.org/getpro/habr/upload_files/74a/d0b/6b9/74ad0b6b97248679f99ef6311c28fc78.svg) — статистика по генеральной совокупности;
    
- ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/02f/80a/4da/02f80a4da53877d124e86df4daeb7458.svg) — выборочная статистика;
    
- ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/520/f84/b92/520f84b924f92329e2b401530565aa0e.svg) — статистика по бутстрап-выборке;
    
- ![N](https://habrastorage.org/getpro/habr/upload_files/767/1b7/d0c/7671b7d0ce4bc68bb0a551697c58fccb.svg) — количество бутстрап-выборок;
    
- ![n](https://habrastorage.org/getpro/habr/upload_files/1c8/62c/e36/1c862ce360db4babb4f46d3988391603.svg) — объем исходной выборки (то есть и каждой бутстрап-выборки);
    
- ![\alpha](https://habrastorage.org/getpro/habr/upload_files/c49/7aa/dac/c497aadacbdf1c3a29e78251c1426599.svg) — уровень значимости.
    

**Алгоритм**:

1. Выборка представляет собой часть большей генеральной совокупности, которую вы хотите изучить, и является репрезентативной.
    
2. По исходной выборке считается ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/6ee/a8a/5e8/6eea8a5e8b7b63672312704738df5c39.svg) статистика.
    
3. Из исходной выборки случайным образом с повторением выбирается ![n](https://habrastorage.org/getpro/habr/upload_files/090/851/fdf/090851fdf8d16de08586a5cf4cff98af.svg) элементов, формируя бутстрап-выборку.
    
4. По сформированной бутстрап-выборке считается ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/dbc/224/d6b/dbc224d6b3094bbd5f1bcdefbc9c68d3.svg) статистика.
    
5. Из полученной по бутстрап-выборке статистики ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/1b5/dfa/0cc/1b5dfa0ccc11abf5a64637410c0d32e8.svg) _вычитается_ ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/32d/4e7/58a/32d4e758a3b07a146ecf811b949086d6.svg) _и получаем_ ![\hat q^*_i](https://habrastorage.org/getpro/habr/upload_files/e08/c08/2dc/e08c082dcb0772a243924f5954f775c7.svg).
    
6. Повторяем шаги 3, 4 и 5 ![N](https://habrastorage.org/getpro/habr/upload_files/f2a/9b4/751/f2a9b4751d1f2d6b35a004d68bdd1b7d.svg) раз (например, 10000, 100000 или 1000000 раз).
    
7. Находим доверительный интервал Холла, который имеет следующую формулу:
    

![CI = [\hat\theta - \hat q^*_{1 - \frac{\alpha}{2}}\ ;\ \hat\theta - \hat q^*_{\frac{\alpha}{2}}]](https://habrastorage.org/getpro/habr/upload_files/426/62a/aa4/42662aaa415c051c02580325818123fe.svg)

Таким образом и получается несмещенная оценка.

### t-процентильный доверительный интервал

t-процентильный доверительный интервал является еще одной схемой построения бутстраповского доверительного интервала. Так же, как и доверительный интервал Холла, t-процентильный использует центрирование. Однако в данном случае, мы еще и делим полученную разность между статистиками по бутстрап-выборке и исходной на стандартную ошибку.

> Такой доверительный интервал получается несколько **шире** Эфронова и Холла, что компенсирует недооценивание разброса статистики, но не полностью. Также t-процентильный доверительный интервал **обладает лучшей асимптотической сходимостью**.

Итак, давайте перейдем к обсуждению алгоритма:

**Обозначения**:

- ![\theta](https://habrastorage.org/getpro/habr/upload_files/c6a/ad3/75e/c6aad375e9b1bd466e8f898cff14d7b0.svg) — статистика по генеральной совокупности;
    
- ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/a27/144/aaf/a27144aaf08645e341547a5254e7617c.svg)— выборочная статистика;
    
- ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/6bd/5db/cb6/6bd5dbcb687258124eec9f54c0efbfe1.svg) — статистика по бутстрап-выборке;
    
- ![N](https://habrastorage.org/getpro/habr/upload_files/f6b/b21/811/f6bb218119399cbcd5636abbd0a17082.svg) — количество бутстрап-выборок;
    
- ![n](https://habrastorage.org/getpro/habr/upload_files/fce/0d7/dc5/fce0d7dc57811b9da358250716630b0d.svg) — объем исходной выборки (то есть и каждой бутстрап-выборки);
    
- ![\alpha](https://habrastorage.org/getpro/habr/upload_files/e67/eb2/109/e67eb21092c13a68bdd2607696d14969.svg) — уровень значимости;
    
- ![se(\hat\theta^*_i)](https://habrastorage.org/getpro/habr/upload_files/eb6/42a/537/eb642a5374f4b55db82e733ef8dd5143.svg) — стандартная ошибка бутстрап-выборки;
    
- ![se(\hat\theta)](https://habrastorage.org/getpro/habr/upload_files/f33/efd/cfc/f33efdcfca0ff4a80a80cb28c0e0e2ed.svg) — стандартная ошибка исходной выборки.
    

**Алгоритм**:

1. Выборка представляет собой часть большей генеральной совокупности, которую вы хотите изучить, и является репрезентативной.
    
2. По исходной выборке считается ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/29c/dec/2f3/29cdec2f3041800b59830e9b21e756d9.svg) статистика и ![se(\hat\theta)](https://habrastorage.org/getpro/habr/upload_files/d73/1b3/a39/d731b3a39b363fadd7577744fd1da98c.svg).
    
3. Из исходной выборки случайным образом с повторением выбирается ![n](https://habrastorage.org/getpro/habr/upload_files/baa/1ad/0b0/baa1ad0b0e834523570b0e6cac5299c7.svg) элементов, формируя бутстрап-выборку.
    
4. По сформированной бутстрап-выборке считается ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/740/e67/e3b/740e67e3b1b0e1f6bb86cf290bdbbc7b.svg) _статистика и_ ![se(\hat\theta^*_i)](https://habrastorage.org/getpro/habr/upload_files/ab2/835/5b5/ab28355b5e61bc940dd65443cf8dfe16.svg).
    
5. Из полученной по бутстрап-выборке статистики ![\hat\theta^*_i](https://habrastorage.org/getpro/habr/upload_files/269/c4a/f2b/269c4af2bec550f3d5399513f17f647f.svg) _вычитается_ ![\hat\theta](https://habrastorage.org/getpro/habr/upload_files/41a/230/aeb/41a230aeb9cec4ebee4d98ca031e0028.svg) _и результат делится на_ ![se(\hat\theta^*_i)](https://habrastorage.org/getpro/habr/upload_files/48f/d1c/cd8/48fd1ccd89aa322b0d1654bfacd02e76.svg), итоговое значение будет обозначаться как ![t^*_i](https://habrastorage.org/getpro/habr/upload_files/66e/99d/df4/66e99ddf47cf1a9271b6a72c4dfb0edd.svg).
    

![t^*_i = \cfrac{(\hat\theta^*_i - \hat\theta)}{se(\hat\theta^*_i)}](https://habrastorage.org/getpro/habr/upload_files/49e/13c/905/49e13c90584cc1934b9bb89f997d4245.svg)

6. Повторяем шаги 3, 4 и 5 ![N](https://habrastorage.org/getpro/habr/upload_files/5b5/43b/496/5b543b4963383ddafa08afde5c792901.svg) раз (например, 10000, 100000 или 1000000 раз).
    
7. Находим t-процентильный доверительный интервал, который имеет следующую формулу:
    

![CI = [\hat\theta - t^*_{1 - \frac{\alpha}{2}} \cdot se(\hat\theta)\ ;\ \hat\theta - t^*_{\frac{\alpha}{2}} \cdot se(\hat\theta)]](https://habrastorage.org/getpro/habr/upload_files/f13/38d/53e/f1338d53e3acb271061df537dd61cfd8.svg)

## Реализация на Python

Наконец, давайте рассмотрим реализацию бутстрапа на Python. Напишем достаточно простую функцию, которая будет предоставлять возможность воспользоваться разными схемами бутстрапирования и иметь возможность принимать функцию, которая заданным образом считает необходимую статистику. Стоит отметить, что для упрощения, полагается, что эта функция будет содержаться в `numpy` и иметь параметр `axis`. Данному требованию удовлетворяют, например, `mean()`, `median()` и `var()`.

```
import numpy as npfrom typing import Callable, Literaldef get_bootstrap_ci(        X: np.ndarray, func: Callable, N: int = 10**3,        kind: Literal['Efron', 'Hall', 't-percentile'] = 't-percentile',        alpha: float = 0.05) -> tuple[float, float]:    n = X.size    bootstrap_samples = np.random.choice(X, (N, n), replace=True)    theta_hat_star = func(bootstrap_samples, axis=1)    if kind == 't-percentile':        theta_hat = func(X)        se_theta_hat = np.std(X) / np.sqrt(n)        se_theta_hat_star = np.std(bootstrap_samples, axis=1) / np.sqrt(n)        theta_hat_star = (theta_hat_star - theta_hat) / se_theta_hat_star        left, right = np.quantile(theta_hat_star, (1 - alpha / 2, alpha / 2))        ci = (theta_hat - se_theta_hat * left, theta_hat - se_theta_hat * right)    elif kind == 'Hall':        theta_hat = func(X)        theta_hat_star -= theta_hat        left, right = np.quantile(theta_hat_star, (1 - alpha / 2, alpha / 2))        ci = (theta_hat - left, theta_hat - right)    elif kind == 'Efron':        left, right = np.quantile(theta_hat_star, (alpha / 2, 1 - alpha / 2))        ci = (left, right)    else:        raise ValueError('Unknown method')            return ci
```

А теперь давайте посмотрим на эту функцию в действии. Допустим, что у нас есть выборка из 52334 наблюдений, в которых находится возраст респондентов. Тогда, грубо, но ради иллюстрации, мы можем предположить, что имеющиеся наблюдения и есть генеральная совокупность, а затем извлечь выборку и по ней постараемся рассчитать доверительный интервал для среднего возраста методом бутстрапирования.

Для начала импортируем необходимые библиотеки:

```
import numpy as npimport pandas as pdimport seaborn as sns
```

загрузим данные (примечание 1):

```
df = pd.read_excel('analysis/data/data_msk.xlsx')
```

а теперь посмотрим как они распределены:

```
sns.displot(df.age, aspect=1.8, bins=df.age.nunique())
```

![Распределение возраста респондентов](https://habrastorage.org/r/w1560/getpro/habr/upload_files/be5/6c6/069/be56c606956aae584e57f33db55ceb38.png "Распределение возраста респондентов")

Распределение возраста респондентов

Видим, что распределение имеет коэффициент асимметрии больше нуля и оно бимодально, но не сильно выражено, что не должно сильно помешать нам в эксперименте.

Далее, чтобы эксперимент можно было воспроизвести, настроим состояние:

```
np.random.seed(34)
```

Теперь посчитаем среднее по “генеральной совокупности”, создадим выборку и посчитаем среднее по ней:

```
sample = df.age.sample(500)print(f'Среднее по "генеральной совокупности": {np.mean(df.age)}')print(f'Среднее по выборке: {np.mean(sample)}')
```

вывод:

```
Среднее по "генеральной совокупности": 68.54052814613827Среднее по выборке: 67.768
```

Видим, что среднее в выборке сильно отличается от среднего в генеральной совокупности. Я специально подобрал такой пример, чтобы показать, что даже в таких случаях бутстрап будет работать корректно.

Итак, теперь давайте посмотрим на результаты разных схем по очереди:

1. Эфронов доверительный интервал:
    
    ```
    ci = get_bootstrap_ci(sample , np.mean, alpha=0.01, kind='Efron')print(ci)print(f'Ширина интервала составила: {ci[1] - ci[0]}')
    ```
    
    вывод:
    
    ```
    (66.99199, 68.53201)Ширина интервала составила: 1.5400199999999984
    ```
    
2. Доверительный интервал Холла:
    
    ```
    ci = get_bootstrap_ci(sample , np.mean, alpha=0.01, kind='Hall')print(ci)print(f'Ширина интервала составила: {ci[1] - ci[0]}')
    ```
    
    вывод:
    
    ```
    (67.00399, 68.54401)Ширина интервала составила: 1.5400199999999984
    ```
    
3. t-процентильный доверительный интервал:
    
    ```
    ci = get_bootstrap_ci(sample , np.mean, alpha=0.01)print(ci)print(f'Ширина интервала составила: {ci[1] - ci[0]}')
    ```
    
    вывод:
    
    ```
    (67.0257231115649, 68.56861294427233)Ширина интервала составила: 1.5428898327074307
    ```
    

> **Важное примечание!** Для того, чтобы воспроизвести эксперимент, необходимо каждый раз перед получением доверительного интервала определенным методом запускать строки с установкой `seed` и генерацией выборки. Это позволит работать с одинаковыми бутстраповскими выборками, которые генерируются функцией `choice()` в `get_bootstrap_ci()`.

В данном случае, среднее по генеральной совокупности на уровне значимости 1% лежит **за пределами Эфронова доверительного интервала**, но **внутри t-процентильного и Холла**. Важно отметить, что в данном примере **проявилось смещение**, которое заложено в Эфронов доверительный интервал. Именно поэтому среднее в генеральной совокупности входит в доверительный интервал Холла, а в Эфронов нет, при том, что они не отличаются по ширине.

Также, из примечательного, t-процентильный доверительный интервал оказался самым широким из всех, а интервалы Холла и Эфрона, как было сказано, равны, но уже t-процентильного, что вполне закономерно.

## Проблемы

1. По сравнению с аналитическими доверительными интервалами, доверительные интервалы, полученные с помощью бутстрапирования (не имеет значения какая выбрана схема), несколько уже, если исходная выборка мала. Это является недостатком, так как мы по сути **недооцениваем разброс выборочной статистики** при небольшом количестве наблюдений в исходной выборке.
    
2. С помощью бутстрапирования мы охватываем асимптотически только 63% наблюдений из исходной выборки, а **37% наблюдений не попадают ни в одну бутстрап-выборку**. Этот факт является следствием того, что мы берем выборки с повторениями.
    
3. Исходя из предыдущего факта следует, что бутстрап является отличной техникой для работы в средиземье, но не в крайнеземье. А когда у распределения исходной выборки **тяжелые хвосты** (то есть много выбросов), бутстрап может начать плохо себя показывать даже в средиземье.
    
4. При наличии **структуры в данных** (регрессия, временные ряды) бутстрап схему необходимо устроить таким образом, чтобы она учитывала эту структуру (Примечание 2).
    

## Примечания

**Примечание 1**. Данные можно скачать [по ссылке](https://docs.google.com/spreadsheets/d/19HgDEoYpO71HVjeAA09oUmn0639fqIhSqwGpFXDdKlo/edit?usp=sharing).

**Примечание 2**. Наличие структуры в данных является большой проблемой при бутстрапировании. Таким образом, необходимо учитывать имеющуюся структуру, что позволяет создать более продвинутые методы, смоделированные на основе классического бутстрапирования, или воспользоваться имеющимися. С конкретными методами бутстрапирования регрессий и временных рядов можно ознакомиться [по ссылке](https://www.hse.ru/mirror/pubs/share/200205069).