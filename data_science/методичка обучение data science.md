---
tags:
  - data
author: Davydov
data_type:
  - DS
---


# 1. Виды машинного обучения

Машинное обучение (Machine Learning, ML) является подразделом искусственного интеллекта (Artificial Intelligence, AI), который фокусируется на разработке алгоритмов и моделей, которые компьютеры могут использовать для выполнения задач без явного программирования. Иными словами, машинное обучение дает возможность компьютерам учиться на основе данных.

Машинное обучение может быть классифицировано по различным критериям, но наиболее распространенная классификация включает следующие типы: обучение с учителем (supervised learning), обучение без учителя (unsupervised learning), обучение с подкреплением (reinforcement learning) и полу-обученное обучение (semi-supervised learning).

## **Обучение с учителем** 

является наиболее распространенным типом машинного обучения. В этом случае, алгоритм учится на основе набора данных, где известны и входные параметры (features), и целевые значения (labels). Задача алгоритма - вывести обобщающую функцию, которая будет предсказывать целевые значения для новых, ранее не встречавшихся примеров. Это могут быть задачи классификации (когда целевая переменная является категорией) или регрессии (когда целевая переменная - непрерывное значение).

## **Обучение без учителя**
отличается от обучения с учителем тем, что в этом случае алгоритму предоставляются только входные параметры, и его задача - найти в данных некую структуру без заранее заданных целевых значений. Примерами такого обучения могут быть задачи кластеризации (группировка данных на основе их схожести) и снижения размерности (уменьшение количества входных параметров, сохраняя при этом наиболее важную информацию).

## **Обучение с подкреплением**
является неким компромиссом между обучением с учителем и без учителя. В этом случае агент (алгоритм) взаимодействует с окружающей средой, получая положительное или отрицательное подкрепление (reward) за свои действия, и стремится максимизировать получаемое подкрепление.

## **Полу-обученное обучение**
используется в ситуациях, когда набор данных включает как размеченные, так и неразмеченные примеры. Алгоритм использует как размеченные примеры для обучения, так и неразмеченные примеры для улучшения обобщающей способности модели.

# Процесс обучения

Процесс обучения в машинном обучении - это последовательность шагов и операций, которые модель проходит для извлечения информации из данных и настройки своих параметров для выполнения задачи, таких как классификация, регрессия или кластеризация. Процесс обучения состоит из следующих основных этапов:

1.  Подготовка данных: Этот этап включает сбор и предварительную обработку данных, такую как очистка от выбросов, заполнение пропущенных значений, нормализация и шкалирование. Данные должны быть готовы к использованию в модели обучения.
    
2.  Выбор модели: Это важный шаг, который включает выбор типа модели, которую вы будете использовать для решения вашей задачи машинного обучения. Это может быть линейная регрессия, дерево решений, нейронная сеть или другая модель, которая лучше всего подходит для вашей задачи.
    
3.  Определение функции потерь: Функция потерь (loss function) определяет, как модель оценивает свои предсказания по сравнению с фактическими значениями. Выбор правильной функции потерь зависит от типа задачи и данных.
    
4.  Определение оптимизатора: Оптимизатор (optimizer) определяет алгоритм, используемый для обновления параметров модели и минимизации функции потерь. Оптимизаторы, такие как стохастический градиентный спуск (SGD) или Adam, используются для настройки параметров модели на основе градиентов функции потерь.
    
5.  Обучение модели: В этом этапе модель подстраивается под данные путем настройки своих параметров для минимизации функции потерь. Это происходит путем подачи тренировочных данных на модель и корректировки параметров с помощью выбранного оптимизатора.
    
6.  Оценка модели: После завершения обучения модели производится оценка ее производительности на отложенных данных (валидационный набор) или на тестовых данных. Оценка может включать вычисление метрик качества, таких как точность, средняя абсолютная ошибка или F1-мера, для оценки производительности модели.
    
7.  Настройка и повторное обучение: Если модель не дает достаточно хороших результатов, возможно потребуется настроить гиперпараметры модели или провести дополнительное обучение для улучшения результатов.
    

Процесс обучения в машинном обучении является итеративным, и его цель состоит в том, чтобы найти оптимальные параметры модели, которые лучше всего соответствуют данным и позволяют достичь требуемых результатов.



# Компоненты процесса машинного обучения

1.  **Набор данных (Data Set)**: это сырьё для машинного обучения. Данные могут быть разнообразными: числовыми, категориальными, текстовыми, изображениями и т.д.
    
2.  **Модель (Model)**: это математическая формулировка или алгоритм, который используется для обучения и предсказания. Модели могут варьироваться от простых линейных регрессий до сложных нейронных сетей.
    
3.  **Функция потерь (Loss Function)**: это мера того, насколько хорошо модель предсказывает целевые значения. Цель обучения - минимизировать функцию потерь.
    
4.  **Оптимизатор (Optimizer)**: это алгоритм, который используется для обновления параметров модели с целью минимизации функции потерь.
    
5.  **Процесс обучения (Training Process)**: это итеративный процесс, в котором модель обновляет свои параметры, чтобы минимизировать функцию потерь.
    
6.  **Оценка (Evaluation)**: после того как модель обучена, она должна быть оценена на новых данных (тестовый набор), чтобы увидеть, насколько хорошо она обобщает свои знания.
    

Важным аспектом машинного обучения является также **валидация модели (Model Validation)**, которая помогает проверить качество модели и её способность к обобщению на новых данных, что позволяет избегать переобучения.

# Основные термины

## Модель 

В машинном обучении, модель представляет собой алгоритм или математическую функцию, которая используется для предсказания или прогнозирования на основе входных данных. Она представляет собой абстракцию, которая устанавливает отношение между входными данными и целевыми значениями или выходами.

Модель в машинном обучении может принимать различные формы и зависит от типа задачи. Вот несколько примеров типов моделей:

1.  Линейная регрессия: модель, которая устанавливает линейную зависимость между входными признаками и выходными значениями. Она предсказывает непрерывные значения, такие как цены, расстояния и другие.
    
2.  Логистическая регрессия: модель, используемая для задач бинарной классификации, где выходные значения ограничены двумя классами. Она использует логистическую функцию для предсказания вероятности принадлежности к одному из классов.
    
3.  Решающие деревья: модели, представляющие собой иерархическую структуру решений в виде дерева. Они используются для классификации и регрессии и могут принимать решения, основываясь на значении различных признаков.
    
4.  Нейронные сети: модели, которые имитируют работу нейронной системы и используют многослойную структуру для извлечения и обработки информации. Они применяются в различных задачах, включая классификацию, регрессию, сегментацию и другие.
    
5.  Метод опорных векторов: модель, которая строит гиперплоскость для разделения данных разных классов в пространстве признаков. Она применяется в задачах классификации.
    

Кроме того, существуют и другие типы моделей, включая ансамбли моделей, кластерные модели, сверточные нейронные сети, рекуррентные нейронные сети и многое другое. Выбор конкретной модели зависит от характеристик данных, типа задачи и целей машинного обучения.

## Оптимизатор

В машинном обучении оптимизатор (optimizer) представляет собой алгоритм или метод, который используется для настройки параметров модели с целью минимизации функции потерь и достижения наилучших результатов. Оптимизатор является ключевым компонентом в процессе обучения модели.

При обучении модели в машинном обучении, мы сталкиваемся с задачей оптимизации, где требуется найти набор оптимальных параметров модели, которые минимизируют функцию потерь на тренировочных данных. Оптимизатор отвечает за нахождение этих оптимальных параметров, путем обновления их значений на каждой итерации обучения.

Оптимизатор использует градиентные методы для определения направления движения в пространстве параметров модели. Он вычисляет градиент функции потерь по отношению к параметрам модели и использует эту информацию для обновления параметров в направлении, которое минимизирует функцию потерь. Некоторые из распространенных оптимизаторов включают в себя:

1.  Стохастический градиентный спуск (Stochastic Gradient Descent, SGD): простой и широко используемый оптимизатор, который обновляет параметры модели с использованием градиента функции потерь на каждом обучающем примере или небольшой группе примеров.
    
2.  Адаптивный градиентный спуск (Adagrad): оптимизатор, который адаптивно изменяет скорость обучения для каждого параметра на основе истории градиентов. Он позволяет большим шагам для параметров с меньшей обновляемостью и меньшим шагам для параметров с большой обновляемостью.
    
3.  Адаптивный момент (Adam): популярный оптимизатор, который комбинирует идеи из стохастического градиентного спуска и адаптивного градиентного спуска. Он адаптивно настраивает скорость обучения и момент для каждого параметра, что обеспечивает более эффективную оптимизацию.
    
4.  RMSprop: оптимизатор, который также адаптивно настраивает скорость обучения на основе истории градиентов, но использует экспоненциальное сглаживание для вычисления среднеквадратичного градиента.
    
5.  Adamax: вариация оптимизатора Adam, который использует бесконечную норму градиентов вместо среднеквадратичного.
    

Оптимизаторы имеют различные свойства и подходят для разных задач и типов моделей. Выбор оптимизатора зависит от особенностей данных и требуемых свойств оптимизации, таких как скорость сходимости, устойчивость и т. д.

### Градиентный спуск

Градиентный спуск (Gradient Descent) является одним из ключевых алгоритмов в области машинного обучения и оптимизации. Он используется для минимизации функций потерь и нахождения оптимальных параметров моделей. Вот подробное объяснение о градиентном спуске и его роли в машинном обучении:

Градиентный спуск является итерационным методом оптимизации, который позволяет найти минимум или максимум целевой функции. В контексте машинного обучения, целевая функция обычно представляет собой функцию потерь (loss function), которую нужно минимизировать. Например, в задаче линейной регрессии целевая функция может быть среднеквадратичной ошибкой (Mean Squared Error).

Градиентный спуск основан на использовании градиента функции потерь, который представляет собой вектор частных производных функции по каждому из параметров модели. Градиент указывает направление наискорейшего возрастания функции, поэтому мы можем использовать его для нахождения направления наискорейшего убывания функции потерь.

Алгоритм градиентного спуска начинает с некоторого начального значения параметров модели и последовательно обновляет их, двигаясь в направлении антиградиента функции потерь. Это делается путем вычисления градиента функции потерь по параметрам и умножения его на некоторый коэффициент, называемый скоростью обучения (learning rate). Скорость обучения определяет шаг, с которым мы двигаемся в направлении антиградиента.

Процесс обновления параметров продолжается до тех пор, пока не будет достигнуто условие остановки, например, заданное количество итераций или достижение требуемой точности. В итоге, градиентный спуск позволяет найти оптимальные значения параметров модели, при которых функция потерь достигает минимума.

Градиентный спуск является основным алгоритмом обучения во многих моделях машинного обучения, включая линейную регрессию, логистическую регрессию, нейронные сети и многое другое. Он позволяет модели адаптироваться к данным и находить оптимальные параметры, чтобы достичь лучшей производительности.

## Функция потерь

Функция потерь (loss function) в машинном обучении является математическим выражением, которое измеряет разницу между предсказанными значениями модели и фактическими значениями целевой переменной. Она играет ключевую роль в оптимизации модели, так как позволяет оценить, насколько хорошо модель работает на конкретных данных.

Цель функции потерь заключается в минимизации ошибки модели и нахождении оптимальных параметров, которые приводят к наилучшему предсказанию. При обучении модели, функция потерь используется для оценки, насколько хорошо модель соответствует тренировочным данным и какие корректировки необходимо внести в параметры модели для улучшения результатов.

В зависимости от типа задачи машинного обучения (например, регрессия или классификация), функции потерь могут различаться. Некоторые из наиболее распространенных функций потерь включают:

1.  Среднеквадратичная ошибка (Mean Squared Error, MSE): используется в задачах регрессии и измеряет среднеквадратичное отклонение между предсказанными и фактическими значениями.
    
2.  Средняя абсолютная ошибка (Mean Absolute Error, MAE): также используется в задачах регрессии и измеряет среднюю абсолютную разницу между предсказанными и фактическими значениями.
    
3.  Кросс-энтропийная ошибка (Cross-Entropy Loss): часто применяется в задачах классификации и измеряет разницу между вероятностными распределениями предсказанных и фактических классов.
    
4.  Логарифмическая функция потерь (Log Loss): также используется в задачах бинарной или многоклассовой классификации для измерения точности вероятностных предсказаний модели.
    

Функции потерь выбираются в зависимости от характеристик задачи и требуемых свойств модели. Цель состоит в том, чтобы найти такие параметры модели, которые минимизируют значение функции потерь. Для достижения этой цели применяются различные методы оптимизации, такие как градиентный спуск, стохастический градиентный спуск и другие.

# Виды моделей 

В машинном обучении существует множество моделей, каждая из которых имеет свои особенности и применяется в различных задачах. Вот некоторые из основных моделей в машинном обучении:

## Линейная регрессия (Linear Regression)

Модель, которая устанавливает линейную зависимость между входными признаками и выходными значениями. Она используется для задач регрессии, где требуется предсказать непрерывные значения.

Линейная регрессия — один из основных инструментов машинного обучения. Это статистический метод, используемый для предсказания количественных переменных. В основе линейной регрессии лежит предположение о том, что существует линейная связь между зависимой переменной (то, что мы хотим предсказать) и одной или несколькими независимыми переменными (также называемыми признаками).

Основная цель линейной регрессии — определить линию, которая наилучшим образом описывает данные. В случае одной независимой переменной это просто прямая линия, задаваемая уравнением `y = mx + b`, где `y` — это зависимая переменная, `x` — независимая переменная, `m` — коэффициент наклона линии (или "вес"), а `b` — точка пересечения линии с осью Y (или "сдвиг").

Метод наименьших квадратов — это общепринятый подход к определению коэффициентов линейной регрессии. Задача состоит в том, чтобы минимизировать сумму квадратов расстояний между наблюдаемыми значениями и значениями, предсказанными моделью.

В многомерной линейной регрессии, где у нас есть несколько независимых переменных, уравнение становится `y = b + m1*x1 + m2*x2 + ... + mn*xn`. Здесь `x1, x2, ..., xn` — это независимые переменные, а `m1, m2, ..., mn` — коэффициенты этих переменных.


## Логистическая регрессия (Logistic Regression)

модель, используемая для задач бинарной классификации, где требуется предсказать вероятность принадлежности к одному из двух классов. Она основана на логистической функции, которая преобразует линейную комбинацию входных признаков в вероятности классов.

Логистическая регрессия - это статистический метод, используемый для прогнозирования бинарного или категориального результата на основе набора независимых переменных. Она является одним из основных алгоритмов в машинном обучении и широко применяется в задачах классификации.

Основная идея логистической регрессии заключается в том, чтобы оценить вероятность принадлежности наблюдения к определенному классу. Для этого используется логистическая функция, также известная как сигмоида, которая преобразует линейную комбинацию независимых переменных в вероятность.

В логистической регрессии оптимизируется функция потерь, такая как логарифмическая функция потерь или кросс-энтропия, чтобы найти оптимальные коэффициенты модели. Эти коэффициенты представляют веса, которые отображают важность каждой независимой переменной в предсказании целевой переменной.

## Решающие деревья (Decision Trees)

Решающие деревья - это алгоритмы машинного обучения, которые используются для задач классификации и регрессии. Они представляют собой древовидную структуру, где каждый узел представляет тестовое условие на одном из признаков данных, а каждая ветвь от узла соответствует возможному результату этого теста.

Процесс построения решающего дерева начинается с корневого узла, который содержит весь набор данных. Затем происходит разделение данных на основе тестового условия в узле, что приводит к созданию дочерних узлов. Этот процесс рекурсивно повторяется для каждого дочернего узла до достижения определенного условия остановки, например, достижения максимальной глубины дерева или достижения минимального количества образцов в узле.

Каждый листовой узел (также называемый терминальным узлом) решающего дерева представляет прогноз или классификацию для нового наблюдения, основываясь на преобладающем классе в образцах, попавших в этот узел.

Решающие деревья имеют несколько преимуществ, включая простоту интерпретации, возможность обработки числовых и категориальных признаков, а также способность обрабатывать большие объемы данных. Они также могут обнаруживать важные взаимодействия между признаками.

Однако, решающие деревья могут быть склонны к переобучению, особенно если дерево имеет большую глубину и слишком хорошо подстраивается под обучающие данные. Для улучшения обобщающей способности деревьев применяются различные методы, такие как обрезка дерева, прунинг, ансамблирование деревьев (например, случайный лес) и др.    

## Случайные леса (Random Forests)

Случайный лес (Random Forest) - это алгоритм машинного обучения, который использует ансамбль решающих деревьев для решения задач классификации и регрессии. Он получил свое название благодаря использованию случайности при построении и обучении деревьев.

Основная идея случайного леса заключается в создании множества решающих деревьев, каждое из которых обучается на случайной подвыборке данных с возможностью повторения (bootstrap sample), а также на случайном подмножестве признаков. Затем, при прогнозировании новых наблюдений, каждое дерево в ансамбле выдает прогноз, и итоговый прогноз случайного леса определяется путем усреднения или голосования по прогнозам всех деревьев.

Случайные леса имеют несколько преимуществ. Они обладают хорошей способностью к обобщению и могут обрабатывать большие объемы данных. Также они устойчивы к переобучению и способны обнаруживать важные взаимодействия между признаками. Кроме того, случайные леса могут работать как с категориальными, так и с числовыми признаками.

Одно из ключевых преимуществ случайного леса заключается в возможности оценки важности признаков. По этой оценке можно определить, какие признаки вносят наибольший вклад в прогнозирование и какие являются наиболее информативными.

Случайные леса также могут применяться для решения задач регрессии, обнаружения аномалий и других задач машинного обучения.
    
## Метод опорных векторов (Support Vector Machines, SVM)

Метод опорных векторов (Support Vector Machines, SVM) - это алгоритм машинного обучения, используемый для задач классификации и регрессии. Он основан на идее поиска оптимальной разделяющей гиперплоскости между двумя классами данных.

Основная цель SVM - найти гиперплоскость в многомерном пространстве, которая максимально разделяет данные разных классов. Гиперплоскость строится таким образом, чтобы максимизировать расстояние (зазор) до ближайших точек каждого класса, называемых опорными векторами.

Метод опорных векторов имеет несколько преимуществ. Во-первых, он способен работать с линейно разделимыми и неразделимыми данными. Для неразделимых данных используется концепция "мягкого отступа" (soft margin), которая позволяет допускать некоторые ошибки классификации. Во-вторых, SVM может эффективно работать в пространствах большой размерности и с высокой размерностью признаков. Кроме того, метод опорных векторов позволяет использовать различные ядерные функции, которые могут преобразовывать данные в более сложные пространства, повышая точность классификации.

Одним из ключевых преимуществ SVM является его устойчивость к переобучению и способность обобщать данные на новые, ранее не виданные примеры. Однако SVM также может быть чувствителен к выбору ядра и гиперпараметров, и требует аккуратной настройки для достижения оптимальных результатов.

## Кластерный анализ (Clustering)

Кластерный анализ - это метод машинного обучения, который используется для группировки объектов или данных в наборы, называемые кластерами, на основе их схожести или близости друг к другу. Он помогает выявить скрытые структуры и паттерны в данных и сегментировать их на более управляемые группы.

Цель кластерного анализа заключается в создании кластеров, внутри которых объекты подобны друг другу и отличаются от объектов в других кластерах. Кластеры могут быть определены на основе различных метрик сходства, таких как евклидово расстояние, косинусное расстояние или другие меры сходства, в зависимости от характеристик данных и конкретной задачи.

Кластерный анализ находит применение в различных областях, таких как анализ данных, маркетинг, биоинформатика, обработка изображений и другие. Он может использоваться для группировки пользователей, сегментации рынка, обнаружения аномалий, классификации объектов и многих других приложений.

В результате кластерного анализа получается набор кластеров, каждый из которых содержит объекты схожие друг с другом внутри кластера. Это позволяет исследователям и аналитикам делать выводы о структуре данных, проводить дальнейший анализ внутри каждого кластера и принимать соответствующие решения на основе полученных результатов.

## Градиентный бустинг (Gradient Boosting)

Градиентный бустинг (Gradient Boosting) - это алгоритм машинного обучения, который используется для решения задач классификации и регрессии. Он относится к семейству ансамблевых методов, где несколько слабых моделей комбинируются для создания более мощной модели.

Принцип работы градиентного бустинга заключается в последовательном построении моделей, называемых "слабыми учениками" (weak learners), и объединении их в одну "сильную" модель. Каждый слабый ученик обучается на остатках предыдущей модели с целью минимизировать функцию потерь.

Алгоритм градиентного бустинга использует градиентный спуск для минимизации функции потерь. Он итеративно добавляет слабых учеников, каждый из которых направлен на улучшение предсказания в районе остатков предыдущих моделей. Таким образом, каждый слабый ученик исправляет ошибки предыдущих моделей, постепенно улучшая точность предсказания.

Преимущества градиентного бустинга включают:

-   Высокая точность предсказания: Градиентный бустинг является мощным алгоритмом, способным достичь высокой точности предсказания.
-   Устойчивость к выбросам: Градиентный бустинг хорошо справляется с выбросами в данных благодаря своей способности фокусироваться на ошибочных примерах.
-   Автоматическая обработка пропущенных значений: Алгоритм способен обрабатывать пропущенные значения в данных без необходимости дополнительной предобработки.

Однако, градиентный бустинг также имеет некоторые недостатки:

-   Большая вычислительная сложность: Итеративный процесс обучения может быть вычислительно затратным, особенно при большом количестве слабых учеников.
-   Потребность в настройке гиперпараметров: Градиентный бустинг имеет несколько гиперпараметров, которые требуют тщательной настройки для достижения оптимальной производительности.

## Нейронные сети (Neural Networks)

модели, которые имитируют работу нейронной системы и используют многослойную структуру для извлечения и обработки информации. Они применяются в различных задачах, включая классификацию, регрессию, сегментацию и другие.
  

# 4. Обобщающая способность модели: метод отложенной выборки. Кросс-Валидация

Обобщающая способность модели: метод отложенной выборки

(Cross-validation) - это метод оценки производительности модели машинного обучения, который позволяет более надежно оценить ее способность к обобщению на новые данные. Он представляет собой процедуру разделения доступных данных на несколько подмножеств (фолдов) для обучения и оценки модели.

Процесс кросс-валидации обычно состоит из следующих шагов:

1.  Разделение данных: Доступные данные разбиваются на K подмножеств (фолдов), обычно равного размера. Каждый фолд выступает в роли тестового набора данных, а оставшиеся фолды используются для обучения модели.
    
2.  Обучение и оценка: Модель обучается на K-1 фолдах и оценивается на оставшемся фолде. Это повторяется K раз, чтобы каждый фолд стал тестовым набором данных. Для каждого запуска модель обучается заново, и метрики оценки производительности (например, точность, средняя абсолютная ошибка и т. д.) собираются.
    
3.  Усреднение результатов: В конце каждой итерации кросс-валидации собираются метрики производительности модели на тестовых фолдах. Обычно используется усреднение этих метрик для получения единой оценки производительности модели.
    

Преимущества кросс-валидации:

-   Позволяет более надежно оценить производительность модели, так как каждый фолд выполняет роль тестового набора данных.
-   Позволяет оценить стабильность модели, проверяя, насколько результаты варьируются в разных наборах данных.
-   Позволяет эффективно использовать доступные данные, особенно при ограниченном объеме данных.
-   Помогает выявить проблемы с переобучением или недообучением модели.

Наиболее распространенными методами кросс-валидации являются K-fold Cross-Validation, Stratified K-fold Cross-Validation и Leave-One-Out Cross-Validation. Кросс-валидация является важным инструментом в выборе модели, настройке гиперпараметров и оценке ее производительности на реальных данных.




# 5. Мультиколлинеарность, регуляризация и масштабирование признаков

Узнаем, что такое ЛЗ векторов, научимся бороться с ней с помощью регуляции. Потренируем новые навыки на старом датасете, выясним, действительно ли регуляция помогает выбрасывать плохие признаки.





# 6. Методы отбора признаков

Разберемся с типами подсчёта корреляций и вычислением p-value.





# 7. Полезные приемы при работе с данными.

Поработаем с выбросами и пропущенными значениями. Узнаем дополнительные способы кодировки категориальных фичей.





# 8. Практика: Housing Market

Закрепим полученные знания и навыки на реальном бизнес-кейсе — научимся гридсерчиться на большом количестве признаков и регуляризаторах.





# 9. Линейная классификация: оценка вероятности

Поработаем с фичами на примере датасета, запустим логрег из коробки. Формально опишем задачу классификации.




# 10. Матрица ошибок и основные метрики классификации

Обсудим базовые методы оценки качества классификации: accuracy, precision, recall, F-меру. Посчитаем матрицу ошибок для выбранного ранее датасета, научимся влиять на метрики через threshold.





# 11. ROC, PR-кривые. AUC-ROC, AUC-PR. Калибровка.

Формально введём определения ROC-AUC, PR-AUC, обсудим калибровку вероятностей. Научимся строить ROC, PR кривые, посчитаем метрики.





# 12. Метод опорных векторов.

Узнаем, чем знаменит SVM, в каких задачах его стоит применять. Запустим SVM из коробки.





# 13. Многоклассовая классификая: one vs rest, one vs one

Введём новую задачу многоклассовой классификации, изучив два подхода к ней. Запустим из коробки и сравним различия в качестве оценки при использовании разных подходов.





# 14. Понижение размерности признакового пространства

Научимся рисовать и экономить ресурсы бизнесу. Будем использовать PCA и t- SNE для работы с нашим датасетом и обученной моделью.





# 15. Метод K ближайших соседей: обоснование нелинейности, гиперпараметры и подбор метрики близости объектов

Займёмся подбором метрик близости, научимся смотреть на смысл фичей. Запустим KNN на примере, научимся выбирать гипер параметры для модели.





# 16. Решающее дерево: постановка задачи регрессии/классификации и гиперпараметры модели и проблемы с обобщающей способностью и подбор гиперпараметров

Узнаем, как построить дерево с лучшим качеством оценки таргетов, почему деревья легко недообучить и переобучить. Запустим два дерева на датасете: для решения задач регрессии и классификации.




# 17. Композиции алгоритмов. Случайный лес

Изучим основные методы ансамблирования — стекинг, бустинг и другие. Рассмотрим случайный лес, бустрап и метод случайных подпространств. Обучим случайный лес и увидим связь между изменением гиперпараметров базового дерева и качеством модели.





# 18. Градиентный бустинг. Bias-variance trade-off

Обсудим идею и интуицию градиентного бустинга. Обучим случайный лес, проведём градиентный бустинг из коробки.





# 19. Кластеризация

Начнём разбирать задачу обучения без учителя, рассмотрим k-means и dbscan для кластеризации. Попробуем визуализацию обученных кластеров.





# 20. Рекомендательные системы

Рассмотрим задачу построения рекомендательный системы и коллаборативную фильтрацию.





# 21. Машинное обучение: классические задачи и алгоритмы 

Разбор задач на линейные модели классификации, регрессии и ансамбли.