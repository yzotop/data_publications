---
tags:
  - data
data_type:
  - AB tests
link: https://colab.research.google.com/drive/1_CY_8DJRLm70gl9RjTz1vmPoLMwCeT0u?usp=sharing
author: expf
company: expf
---
# Предисловие

Привет!

Меня зовут Илья, в свободное время от работы я пишу про аналитику. Если тебе интересно получать больше полезных материалов, то можешь подписаться на ресуры ниже:

- телеграм-канал (Дневник Стьюдента) - [https://t.me/t_diary](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Ft.me%2Ft_diary)
- linkedin - [https://www.linkedin.com/in/ilya-loladze/](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fwww.linkedin.com%2Fin%2Filya-loladze%2F)

В этом файле содержится вся основная теория по А/Б-экспериментам. Конспект был построен на основе 20 часов лекций курса по экспериментам от консалтинговой и образовательной компании EXPF. Выкладка этого конспекта в общий доступ была согласована с лекторами курса.

Если конспект будет пользоваться спросом, то я подготовлю 2-ую версию, дополнив каждый блок элементами кода, чтобы для наглядности увидеть всю теорию на практике :)

Приятного чтения!

# 1. Об экспериментах и основы статистики

---

Если у нас по каким-то причинам мало данных, то есть и другие способы проверки гипотез помимо A/B-экспериментов:

1) Глубинное интервью
2) Опросы
3) Юзабилити-тестирования

Решения в экспериментах бывают

- Ложноотрицательные (решили, что нет положительных изменений, когда они на самом деле есть - ошибка 2-го рода)
- Ложноположительные (наоборот, решили, что есть положительные изменения, когда их на самом деле нет - ошибка 1-го рода)

Типы экспериментов:

1) A/B
2) A/A
3) A/B/C
4) TDI (team draft interleaving) - изменения в ранжированных списках. Чаще в поиске и рекомендациях. Один юзер видит оба варианта. Например, два алгоритма поисковой выдачи, пополам разделяющие выдачу

В экспериментах используем метрики, верхнеуровневая классификация: 1) Goal metric / North Star metric (NSM) - главная метрика (-и), чаще Выручка, GMV и прочие

2) Driver / Proxy metric - производные метрики от Goal metric Популярный "пиратский" фреймворк с примером декомпозиции метрик: AARRR: Acquisition -> Activation -> Retention -> Referral -> Revenue

3) Debig metric / Diagnostic - самый низкий уровень, объясняют причину изменения driver-метрик

4) Guardrail metric - "охраняющие" метрики, часто технические: время загрузки сайта, баланс веток

Полезные материалы по построению дерева метрик:

1) Беспалтный крутой гайд от консультанта Маккинзи (фреймворк MECE) [https://www.craftingcases.com/issue-tree-guide/](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fwww.craftingcases.com%2Fissue-tree-guide%2F)

2) Анна Саакян (дерево решений, консалтинговый подход)

3) STEDII - фрейморк по построению правильных метрик от microsoft

4) Ваши A/B-тесты сломаны: [https://habr.com/ru/companies/jugru/articles/358104/](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fhabr.com%2Fru%2Fcompanies%2Fjugru%2Farticles%2F358104%2F)

Почему важно не зацикливаться на одной метрике?

"Эффект кобры" - чтобы избавиться от размножившихся кобр в колониальной Индии правительство запустило программу - за пойманную кобру выплачивался бонус. Но только их стало еще больше, так как местные начали разводить кобр для награды.

Закон Кэмпбелла (экономика): ~Чем чаще мы будем смотреть на один и тот же показатель, тем хуже мы будем понимать среду, которую он описывать и больше заводить себя в заблуждение (оригинальная цитата про социальные индикаторы и коррупцию)

OEC - overall estimation critetion критерий успешности эксперимента, который нацелен на долгосрочный положительный эффект

По сути просто концепция о здравом смысле в продолжении 2-х принципов выше

Из чего состоит метрика

1) Тип: доля, непрерывная, дискретная, отношение

2) Параметры: направленность, чувствительность, единица рандомизации

3) Компоненты: числитель, знаменатель

Большие эксперты по A/B-экспериментам:

- Рон Кохави
- Александр Фабиджан
- Павел Дмитриев
- Лукас Вермеер
- Джианнан Лу

Быстрое введение в математическую статистику

Основные показатели:

- математическое ожидание (среднее)
- дисперсия*, выборочная-несмещенная дисперсия (n-1)
- стандартное отклонение
- коэффициент вариации (cv = sd / m, переводим стандартное отклонение в проценты с помощью мат-го ожидания)

*fun fact - если не возводить разницы в квадрат при расчете дисперсии, то мы получим 0

Основные концепции:

- правило 3-х сигм (68-95-99,7%)
- центральная предельная теорема (при увеличении кол-ва выборочных средних -> нормальное респределение выборочных средних, стремление среднего средних к математическому ожиданию генеральной совокупности, уменьшение стандартной ошибки)

Можно использовать ЦПТ, чтобы оценить среднее значение генеральной совокупности по выборке (похоже на бутстрап):

1) Берем n выборок одинакового размера, считаем среднее для каждой из них

2) Считаем среднее средних и их стандартное отклонение (стандратная ошибка среднего)

3) Считаем доверительный интервал x_mean +- se * 2 (95,4%) - границы, где скорее всего находится среднее генеральной совокупности

Способ выше хоть и рабочий, но на практике им не пользуются. А делают вот что: считаем выборочное стандартное отклонение и делим его на корень из размера выборки - это будет показателем погрешности

x_mean +- sd / square(N) * 2

[https://seeing-theory.brown.edu/compound-probability/index.html#section1](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Fseeing-theory.brown.edu%2Fcompound-probability%2Findex.html%23section1) - супер сайт, чтобы наглядно посмотреть концепции выше и другие из теории вероятности и математической статистики

---



# 2. Статистические критерии и гипотезы

---

t-значение = сигнал / шум

x1 - x2 / sqrt(s1^2/n1 + s2^2/n2)

H0: u1 = u2 H1: u1 != u2

Доли - в отличие от t-теста не нужно проверять выборку, так как это распределение Бернулли по определению.

Z-тест для долей = p1 - p2 / sqrt(p1_(1-p1)/n1 + p2_(1-p2)/n2) = разница долей / стандартная ошибка

Помимо статистики можно считать доверительный интервал разницы метрик - это не будет отличаться от p-value.

например, p1 +/- p2 * 1,96 * стандартная ошибка

! надо смотреть ДИ разницы, а не ДИ метрик, так как в последнем случается уменьшается мощность

Непараметрические критерии

Есть ли структурные отличия в распределениях (выручка)?

Для этого используем u-критерий Манна-Уитни, его алгоритм:

1) Объединяем метрики в обеих группах и присваиваем каждой порядкой номер (1 - самое маленькое значение, 2 - чуть больше и тд)

2) Для повторящихся значений ранги заменить на их среднее (например, 0 - 1 ранг, 0 - 2 ранг -> 0 - (1+2)/2=1,5 ранг, 0 - 1,5 ранг)

3) Суммируем ранги для каждой группы - R1 и R2 соответственно, из которых получаем U-статистику:

U1 = n1_n2+n1_(n1+1)/2-R1

U2 = n2_n1+n2_(n2+1)/2-R2

4) sd = sqrt((n1+n2+1)/12_n1_n2)

5) z = (AverageRank - max(U1, U2)) / sd,

где AverageRank = 0,5 + n1*n2/2

Комментарий: U-тест - это непараметрический критерий, и он не проверяет равенство медиан, так как медиана - параметр! -> это легко проверить, сгенерировав данные, где суммы рангов равны, а медианы отличаются кратно

Что проверяет U-тест:

H0: Распределение F = Распределение G H1: G(x) = F(x+q), где q!=0

Или примерно формулируя на человеческом языке - u-тест сравнивает каждое наблюдение xi в первой выборке с каждым наблюдением yj во второй выборке

Условия для применения Манна-Уитни:

- схожесть форм распределений
- не любит повторящиеся дискретные значения

Аналогичный критерий Краскелла-Уоллиса для случаев от 2-х групп и больше

---

_keyboard_arrow_down_

# 3. Способы выбора объема выборки для А/Б. Мощность эксперимента

---

Есть 2 основных подхода для определения времени остановки эксперимента:

1) Fixed Horizon

- простая реализация
- высокая ошибка ранней остановки

2) Sequental testing

- оптимизация "проблемы подглядывания"
- сложная реализация (границы остановки эксперимента рассчитываются real-time)

N - собираем, опираясь на мощность (TP), уровень значимости (TN) и MDE (minimum detectable effect)

Факторы, влияющие на время эксперимента:

- статистические (effect size, ошибки 1 и 2 рода, дисперсия)
- продуктовые (сезонность, окно закрытия)

Мощность (чувствительность) - обратное ошибке 2-го рода.

Lift - % изменения метрики = (x1 - x2) / x2

Effect size - стандартизированный эффект = (x1 - x2) / std, where std = (std1 + std2) / 2

MDE - это наименьший истинный эффект полученный от изменений, который с уверенностью сможет обнаружить статистический критерий

Формально - это наименьший истинный эффект полученный от изменений, который имеет определенный уровень статитстической мощности для определенного уровня статистической значимости, учитывая конкретный статистический тест

Формула для t-теста:

M * Y / S, где M = ta/2 + tb, S = sqrt(disp1 / n1 + disp2 / n2)

Прокрутить обратно фарш (считаем n)

n = 2 * (ta/2+tb)^2 * disp / effect_size^2

!Помним, что у эффекта есть доверительный интервал, и правильно называть его, а не просто среднее

Используем tt_ind_solve_power, чтобы рассчитать необходимое кол-во наблюдений: alpha, power, effect_size, nobs1 + ratio + equal_var для поправки Уэлша если False

-> функция возвращает один из 4-х параметров, который бюл пропущен

Разберем детальней множественную проверку гипотез, есть 2 подхода:

1) MVT-тестирование

каждый вариант сравнивается с каждым

2) A/B/N-тестирование

контроль сравнивается с каждым вариантом

Если проверять N гипотез, то вероятность сделать ошибку 1-го рода (FWER, family-wise error rate) значительно возрастает по формуле:

1-(1-a)^m, где m - кол-во проверяемых гипотез

Например, для 3-х гипотез при уровне значимости 95% уровень альфа будет 1-(1-0,05)^3=0,142

Кейс Марисы Майер с тестом 41 оттенка синего для рекламных ссылок в gmail

Поправки при множественных сравнениях:

1) Поправка Бонферрони - a/m, где m - кол-во проверяемых гипотез

при этом резко уменьшается мощность

2) Поправка Бенджамини-Хохберга

FDR (False Discovery Rate) = FP / (FP + TP). - контролируется, когда нам важнее сохранить истинно-положительные результаты. FDR - это доля ложных открытий.

- фиксируют FDR, обычно на уровне 10% - это уровень гамма y
- значения p сортируют в порядке возрастания и присваивают ранги
- находим p с наибольшим рангом такое, что pj <= y*(j/N)
- все тесты с рагнами j и меньше считаем значимыми
- аналогично можно для каждого отдельно посчитать q = y * (j/N)

FWER или FDR?

- FDR (обычно FDR < 0.1) - выше мощность и контроль ошибки 2-го рода
- FWER (обычно FWER < 0.05) - строгий контроль за вероятностью ошибок 1-го рода

FDR для продуктовых реалий эффективней и быстрорастущие сервисы выбирают его

Ошибка подглядывания и важность смотреть p-value в динамике

Кейсы:

- видим, что эффект отрицательный, но чтобы говорить о значимом понижении наблюдений пока не хватает. Можем заранее отключить тест, так как денбги терять не хотим, а по динамике видим, что положительного эффекта точно не будет
- Видим совсем небольшой положительный лифт на протяжении всего последнего времени, но p-value не опускается ниже нужного уровня. Можем посмотреть в прокси метрики, чтобы быстрее определить, есть ли на самом деле эффект

Holdout - какой-то % траффика не трогают весь квартал, а потом сравнивают его со всеми эффектами, принимая решение по всем экспериментам сразу

---

_keyboard_arrow_down_

# 4. Бутстрап: повторные выборки и децильные оценки А/Б тестов

---

Алгоритм бутстрапа:

1) Из выборки берем N элементов (получаем бутстрап выборку)

2) Повторяем несколько раз и считаем для каждой бутстрап выборки нужную статистику (например, медиану)

3) По этим статистикам строим доверительный интервал

Доверительный интервал можно построить разными способами:

- перцентильный метод: от 2,5 до 97,5 (для 95%)
- percentile CI
- normal CI
- basic CI
- BCA

Подробнее про другие способы построения ДИ: [https://arch.readthedocs.io/en/latest/bootstrap/confidence-intervals.html](https://colab.research.google.com/corgiredirector?site=https%3A%2F%2Farch.readthedocs.io%2Fen%2Flatest%2Fbootstrap%2Fconfidence-intervals.html)

Корреция смещения (bias-correction)

Если статистика не среднее, то она сильно подвержена смещению, которое необходимо корректировать

bias(Tn) = E(Tn) - T,

где T - выборочная оценка, Tn - оценка бутстрапом

Можно провести аналогию - коррекция при расчете выборочной дисперсии (n-1)

Порядок для коррекций:

1) Рассчитываем смещение в бутстрап-выборке -> bias(T^) = E(T^) - T для коррекции T^. T - статистика выборки.

2) Сдвигаем каждое значение по бутстрап-подвыборке -> T~ = T^ - bias(T^) если смещение вправо, T~ = T^ + bias(T^) если смещено влево

3) Используем скорректированное значение T~ (для проверки гипотез используем T~t - T~c)

Теперь проверка гипотез с помощью бутстрапа

1) По Эфрону (но так типо никто не делает)

- строим бутстрап-распределение А и Б
- считаем разницу между ними
- на каждой бутстрап итерации считаем T = (X - Y) / (s^2x/nx + s^2y/ny)
- считаем p-value P(T>=t)=1/B * SUM[1->B]1{Tb >= t}

2) Альтернатива в python

- строим бутстрап-распределение А и Б
- считаем среднее и стандартное отклонение (ско) бут-выборок
- считаем площадь под кривой кумулятивной функции распределения (cdf) с параметрами среднего и ско взятых по бут-распределению
- снова считаем площадь под cdf, но уже с отрицательным средним (для двухсторонней альтернативы)
- берем минимальное значение из 2-х и умножает на 2

!Важно - когда бутстрапируем, то делаем бутстрап-выборки такого же размера, как изначальная выборка

Бутстрап квантилей

Поиск очага структурных изменений в распределение

Если Манна-Уитни недостаточно, и хочется понять где именно произошли структурные изменения, то используется бутстрап квантилей

Но здесь появляется проблема множественных сравнений:

a_corrected = a / Neq, где

- a-1 - уровень значимости
- Neq - кол-во уникальных тестов
- Neq = N^2 / SUM[i,j=1->N]r(i,j)

Дециль - каждый 10 перцель распределения

ФИШКИ И ОПТИМИЗАЦИЯ

Применение бакетизации для ускорения бутстрапа

Распределение, отличающиеся от нормального, можно привести к нормальному с помощью техники бакетов:

- рандомно присваиваем группы от B1 до Bn
- аггрегируем по среднему или сумму
- из аггрегированных значений получаем распределение близкое к нормальному

Универсального кол-во бакетов нету, но чем больше бакетов, тем меньше bias между оригинальной дисперсией и бакетизированной

ПРОВЕРКА КАЧЕСТВА СПЛИТОВАНИЯ

Убедиться в корректности системы сплитования можно путем трех-этапной проверки:

- Sample Ratio Mismatch check - честное деление пользователей между группами
- Intersection check - проверка пересечения пользователей между сплитами
- False Positive Rate check - проверка ложноположительной вероятности с помощью бизнес-метрик

SRM - разбиваются ли в целом бзеры 50/50 и по разным стратам, можно проверять с помощью хи-квадрата Intersection - проверка пересечений между сплитами, а также А и Б в каждом сплите не должны пересекаться FPR - альфа не должен превышать заданный уровень, p-value должен быть распределен равномерно на А/А

По мере увеличения кол-ва экспериментов, у нас будет все больше пересечений групп, поэтому важно следить, чтобы пересечение пользователей было равномерно (в тесте 1 в группах А и Б должно быть ~одинаковый % пользователей, которые еще и в тест 2 попали)

Альтернатива проверка равномерности FPR визуальной оценке - критерий Андерсона-Дарлинга

Частые кейсы завышенного FPR: 1) Долгое ожидание сервера для присвоения id 2) Приоритет одной из групп 3) Не на всех страницах/кейсах реализован сплит-алгоритм 4) Банально "сломан" рандом

! Лайфхак - для проверки SRM можно, например, сгруппировать контроль и тест по RFM и посмотреть разницу этих групп между ними.

!Для проверки дисбалансов критерий Хи-Квадрат или критерий Кохрана-Мантеля-Ханзеля (CMH, для нескольких групп)

!Эксперименты не 50/50 могут снижать мощность

!Пост-симуляции А/А нужно делать без возвращений (replace=False)

!Интересный вариант - запускать эксперименты по группам A1/A2/B с распределением 25%/25%/50%, если между А1 и А2 нет различий, то объединяем их и провереям с B

---

_keyboard_arrow_down_

# 5. Ускорение A/B и ratio-метрики

---

## Ускорение А/Б

Один из способов - сокращение дисперсии:

1) Использовать меньшее кол-во наблюдений
2) Значимо наблюдать более низкие эффекты

На примере t-статистики посмотрим, что на нее влияет:

t = разница средних / стандартная ошибка = (x_mean1 - x_mean2) / sqrt(s1^2 / n1 + s2^2 / n2)

Как же сократить дисперсию?

- увеличивать кол-во наблюдений
- равномерное разделение вариантов А и Б (50/50)
- очистка выбросов (q>0.95, q>0.99), но меньшее способность экстраполяции выводов
- анализ exposured (вовлеченных) пользователей - на пример, при тестировании нового алгоритма поиска в группы а/б включаем только тех пользователей, которые им пользуются

Другой способ - стратификация

У него есть два варианта реализации: стратификация (stratified sample) и пост-стратификация (post-stratification)

В случае с обычной стратификацией все понятно - мы подбираем группы так, чтобы пропорции между стратами были такими же как в генеральной совокупности.

С пост-стратификацией сложнее:

- variance strat = 1/n * SUM[k=1;K] (pk*dispersion_k), где k - какая-то страта, pk = вероятность в нее попасть, dispersion_k - дисперсия этой страты
- среднее стратифицированной выборке будет равно среднему генеральной совокупности
- главная польза от пост-стратификации - при подсчете стратифицированной дисперсии мы избавляемся от межгрупповой дисперсии, которая учитывается при подсчете обычной дисперсии всей выборки*

*потому что обычная дисперсия выборки = межгрупповая дисперсия + внутригрупповая дисперсия, а стратифицированная дисперсия = внутригрупповая дисперсия, откуда получаем, что обычная дисперсия выборки >= стратифицированная дисперсия

важные моменты для стратификации:

1) страты должны быть стабильными и не меняться во времени

2) стратификацию можно использовать при проблеме с балансом выборок

3) некоторые исследования показывают, что стратификация может помочь сократить дисперсию от 1 до 40 %

CUPED (controlled-experiment using pre-existing data)

Y_cupedi = Yi - (Xi - mean) * COV(X,Y) / VAR(X), где

- Y - эксперементельная метрика
- Xi - ковариата, метрика влияющая на Y косвенно
- mean - метрика Xi до эксперимента
- var(Ycuoed) = var(Y)*(1 - p(x,y)^2), где p - корреляция x и y; что то же самое var(Ycuped) / var(Y) = 1 - p(x,y)^2
- для эксперимента эффект считается как X_cuped - Y_cuped
- есть разные способы еще, что использовать вместо X, некоторые подходы называются CUPAC, любой из выбранных нужно тестировать на симуляциях Монте-Карло

Алгоритм действий:

1) Рассчитываем COV(X,Y) по предэксперемнтальному X и эксперементальному Y

2) Рассчитываем VAR(X)

3) Рассчитывем X_mean по предэксперементальному периоду

4) Считаем коррекцию для каждого наблюдения Y_cuped_i = Y_i - (Xi - X_mean) * COV(X,Y) / VAR(X)

5) Применяем статистический критерий к распределению Y_cuped

Альтернативный способ:

1) Рассчитываем зависимость Y от X, оценив theta с помощью линейно регресии

2) Считаем Y_cuped = Y - theta * X

3) Считаем разницу Cuped метрик А и Б

Ограничения:

- считается только для разницы средних
- какой период до выбрать не очевидно
- иногда может трансформировать некорректно данные и привести к неправильным выводам

Способы трансформации метрики, сокращающие дисперсию:

- корень
- логарифм
- бокс-кокс
- ранжирование

Помимо увеличения чувствительности экспериментов важно следить за направленностью после применения разных техник. Например, при применении логарифма к X метрике часть значений около нуля станет отрицательной, и если большая часть выборки находилась там, то лифт будет отрицательным.

На симуляциях можно проверять, в скольких случаях метрика после транфсормации поменяла свою направленность и так оценивать валидность способа.

Для разных метрик подходят разные способы (CUPED / трансформации). Это можно проверять на симуляциях: по оси X - лифт, по оси Y - % значимых изменений. Для каждого лифта делать 10 000 симуляций и смотреть, при каком способе больший % нахождения стат значимых изменений.

---

## Ratio-метрики

Ratio-метрика - это отношение одной случайной величины к другой. Например, клики к просмотрам или клики к сессиям. Любую метрику можно свести к ratio-метрике

Особенности

- нужно учитывать дисперсию обеих величин
- не получит перевести в бинарную метрику (0 для метрики выручки?)
- учитывем историю по каждому пользователю*

*например, имеем 2-х пользователей с показателями по просмотру кликам: 10 / 1, 100 / 20.

CTR наивный = (0.1 + 0.2) / 2 = 0.15

CTR global = (1 + 20) / (10 + 100) = ~0.27

bias = 0.27 - 0.15 = 0.12

Способы работы с ratio-метрики:

1) Бутстрап

- делаем бутстрап выборку по пользователям сумма кликов / сумма просмотров
- полученные значения умножаем на веса для избегания смещения (в данном случае на занменатель - просмотры)
- в группе Б аналогично
- считаем разницу и получаем распределение разницы метрики отношение контроля и теста

2) Пуассоновский бутстрап

- распределение Пуассона с лямбдой = 1 приближено в биномиальному, метод позволяет ускорять вычисления

3) Линеаризация

- между числителем и знаменателем есть зависимость, чем больше знаменатель, тем больше числитель как правило в ratio-метриках
- поэтому можно посчитать регрессию X = k * Y, где X - числитель, Y - знаменатель
- для каждого пользователя считается метрика X - k * Y
- на трансформированную метрику можно использовать CUPED

4) Delta-метод

- с помощью этого метода получаем примерное значение дисперсии в метрике, в том числе ratio-метрике
- в упрощенном объяснении дельта-метод расширяет функцию случайной величины относительно ее среднего значения с помощью ряда Тейлора, а после берет дисперсию

---

# 6. Q&A

---

_keyboard_arrow_down_

# 7. Монте-Карло, направленность и поиск прокси метрик, автоматизация расчетом A/B, про ratio-метрики

---

## Монте-Карло симуляции

- многократное симулирование исходов каких-либо событий

Можем симулировать и проверять много разных гипотез, в том числе оценивать не только на А/А-тестах, но и А/Б, проверяя тем самым мощность теста = TRP (true positive rate) = чувствительность, домножая симулированную группу B на эффект X с нормальным распределением.

Еще одно преимущество симуляций - оценивать необходимое кол-во наблюдений для заданного MDE. Так как для непараметрических критериев формула расчета сложнее недели как у ttest_ind

При симуляциях для проверки метрик и критериев нужно валидировать по очереди:
1) FPR - в каком % случаев увидели прокрас на А/А-тестах
2) TPR - аналогично, только домножаем на лифт с шагами (например, от 1% до 10% с шагом 1%)

Некоторые детали при симулировании:
- для дискретных величин нет смысла домножать на лифт (0 * x = 0), поэтому лучше использовать генераторы биномиальных распределений с заданными уровнями вероятности успеха
- для остальных используем не просто x, а домножаем на нормальное распределение со средним x
- для ratio-метрик как правило меняем только числитель

Моделировать эффект разными способами:
- константа
- нормальное распределение
- равномерное распределение
- скошенные вправо / влево

Советы от expf:
- дискретные величины лучше не умножать, а генерировать эффект как дискретное распределение и прибавлять
- иногда нам важнее увидеть лифт у конкретной группы, тогда можно домнажать lyft в перцентилях

Некоторые дополнения:
- лучше менять не кол-во наблюдений, а фиксировать n и смотреть разные периоды длительности эксперимента. Помимо этого учитывать "окно" активации, так как метрика не меняется как правило в первый же день эксперимента
- для моделирования эффекта можно пробовать все возможные распределения или взять распределение из других экспериментов

---

## Направленность и поиск прокси метрик

- свойство отражает направленное изменение метрики в ту же сторону, что и у другой метрики

Для чего искать:

- нужно найти прокси-метрики, исследуя исторические экспериментов
- когда нужно подобрать оптимальный способ трансформации метрики для повышения ее чувсвительности

Существует 3 способа оценки направленности метрик, но для каждого из них нужен истоический корпус экспериментов:

1) Label Agreement
- помечаем эксперименты dummy переменными (-1 - плохое изменение, 1 - хорошее)
- считаем случаи, когда дельта (если отвергли H0) treatment - control была сонаправлена с dummy
- MAX(N+;N-) / N, где N+ - кол-во стат-значимых экспериментов и где дельта соответсвует вердикту (dummy), N- - аналогично, только дельта не соответсвует вердикту
- очень рекомендуется paper: "Pavel Dmitriev, Xian Wu. Measuring metrics. Appeared in CIKM 2016"

2) Корреляция метрик по стат значимым дельтам
- используется для поиска прокси метрик
- собираем данные в виде (метрики, лифт, p-value)
- смотрим до лифта и после лифта каждую метрику с каждой и проверяем, в каком % случаев метрики были сонаправлены (+ = +, 0 = 0 или - = -)

3) Корреляция метрик по t-статистике
- аналогично 2-му способу, только вместо абсолютных разниц метрик сравниваем значения t-статистик

Что делать, если нет истории экспериментов?
- начать ее вести :)
- провести обратные ухудшающие эксперименты A/B
- чувствительность трансформаций можно считать без исторических А/Б

---

## Автоматизация A/B

Для чего платформа?

- сфокусировать время аналитиков на более важных задачах
- унификация (если дать посчитать А/Б двум аналитикам, то результаты могут быть разными)

Основные этапы платформы экспериментов - планирование, запуск, проведение и анализ. Далее будет говориться только про часть анализа.

Нужно создать репозиторий метрик, где определено, по какой логике каждая метрика считается, чтобы логика расчетов на уровне компании у всех команд была одинаковой.

Пример (считается через jinjasql):

name: arpu

metric_type: continuous

numerator:

aggregation_function: sum

aggregation_field: revenue

level: client_id

estimator: t_test_delta_method

Метрики можно объединять в группы по смыслу (пресеты): экономические показатели, операционные и так далее

---

## Как придумать любую метрику с помощью числителей и знаменателей

Все метрики можно представлять в форме ratio-метрик. Это можно использовать для упрощения/ускорения подсчета аналитики

Для ratio-метрик используется один из 3 критериев: дельтаметод, линеаризация, бутстрап

---

_keyboard_arrow_down_

# 8. Оффлайн эксперименты

SUTVA - stable unit treatment value assumption - предположение о том, что юниты, на которых проводится эксперимент, не влияют друг на друга

Spillover effect - когда группы влияют друг на друга

Нарушением конистентности в expf называют, когда мы исследуем влияние какого-то фактора, но этот фактор отличается от юнита к юниту в тестовой группе (утрированный пример: как сильно влияет посещение дополнительных консультаций на успеваемость. но у разных учеников разные учителя будут на консультациях, которые сильно также влияют на успеваемость учеников)

Один из возможных вариантов решения при проблеме с соблюдением SUTVA - изменить единицу рандомизации (из магазинов в группы магазинов по округам, из пользователей в кассы)

Если проведение А/Б-эксперимента невозможно, то используют техники из Causal Inference, формально определить эти подходы можно так:

Outcome for treated - Outcome for untreated = [Outcome for treated - Outcome for treated if not treated] + [Outcome for treated if not treated - Outcome for untreated] = Impact of treatment on treated + selection bias

- В А/Б первый компонент это влияние нового изменения, а второй (selection bias) будет равен нулю
- В Causal Inference используют следующие методы: DiD, Causal Impact, прочие регресии
- Элементы, которые помимо выбранного фактора оказывают влияние и мешают соблюдению SUTVA еще называют confounders

Основные эксперименты в оффлайне:

- промо / цены в магазинах
- интерфейсы самообслуживания
- доступные меню блюд
- мотивация для водителей такси (или любых других) и тд

Проблемы оффлайна:

1) Confounder'ы в ретроспективном анализе

При прогнозировании контроля и сравнивании с тестом сложно избежать внешнего влияния - праздники, активности конкурентов, экономические-политические изменения

2) Сетевой эффект при сплите пользователей

Для теста с мотивацией таксистов одни водители могут отъедать заказы у других в теории, таким образом тест будет влиять на контроль. К рекомендации статья и выступление Артема Солоухина (Ситимобил) "Платформа switchback-экспериментов"

2.2) Network эффект в социальных сетях (еще один пример сетевого эффекта, но уже в онлайне)

Например, части пользователей выдаем стикеры, а другим нет. Но пользователи общаются друг с другом

Популярные решения:

1) Синтетический контроль

Раскатка на 100% и сравнение с синтетическим контролем (SCM, BSTS (prophet / causal impact)). Полноценное обучние модели машинного обучения и ее валидация для применения

2) Изоляция / зонирование групп

Изоляция по гео-хрону (switchback на регионах в разное время с переключениями). Тут помимо логики переключение контроля/теста важно правильно выделить зоны, с которыми алгоритм sqitchback будет работать. Выделить зоны нужно так, чтобы они друг на друга не влияли.

В социальных сетях популярна техника изолирования на графах (по кластерам насколько одни юзеры общаются с дргуими). Нужно соблюдать баланс (trade-off) между кол-вом и размером кластеров. Отдельные пользователи могут сильно влиять на большую часть других юзеров (например, популярные блогеры).

3) Матчинг

Сопоставление по схожести. У нас появляется 4 группы: unmatched treatment, unmatched control, matched treatment, matched control. Последние 2 мы и сравниваем между собой для расчета эффекта

---

#### Sampling bias

Рассмотрим несколько смещений, которые мы хотим избегать при проведении экспериментов

Selection Bias - ошибка, которая допускается при отборе наблюдений для исследования. При ее допущении результаты теста нельзя экстраполировать на генеральную совокупность

Перечень допущений, при которых Selection Bias'а нет:
- выборка отражает ГС (высокая внешняя валидность) = репрезентативность
- выборка не подвержена другим факторам воздействия, кроме treatment'а (высокая внутренняя валидность)

User learning: Novelty & Primacy effects

Novelty effect - эффект новизны, когда к новому функционалу относятся с особым интересом, но со временем перестают пользоваться

Primacy effect - рост активности по взаимодействию с каким-то функционам в течение долгого времени (эффект принятия, обратное эффекту новизны)

Для понимания, какой из эффектов мы наблюдаем, можно отображать метрику "использования" изменения не просто по дням, а кумулятивно для каждого отдельного пользователя: 1-й день после использования, 2-й и так далее (запустили тест 12 декабря, но это не значит, что все юзеры 12-го зашли в приложение и увидели изменение)

Инструменты для обнаружения primacy и novelty эффектов:
1) Более долгое проведение эксперимента
2) Корреляция моделей (linkedin)
3) Difference in Differences
4) Jacknife estimator Допустим, эксперимент длится 14 дней. Считаем средний лифт за 13 дней, исключая 1-й. Потом еще один средний лифт за 13 дней, исключая уже 2-й день и так далее. От всех этих оценок берем среднее - это и есть jacknife оценка, которую далее сравниваем с общим средним лифтом за 14 дней.

Sampling Bias: Heavy and Light users - нарушение внешней валидности

Для упрощения пример с соцаильной сетью. Часть пользователей активничают каждый день, а другая - раз в неделю. На эксперименте можем "зацепить" эффект от активных пользователей, но ничего не понять по неактивным.
Простое решение: можно смотреть по задействованным пользователям в эксперименте в какой пропорции они разбиваются и считать эксперимент валидным, когда их соотношение приблизиться к соотношению в генеральной совокупности

---
#### Propensity Score Matching

-- метод Causal Inference, который позволяет сформировать похожие группы по заданным признакам, чтобы их отличие по ключевой для нас метрики было идеально. Сразу минус метода в том, что не для каждого элемента из ГС найдется "близнец", поэтому его прийдется исключить их эксперимента.

Помимо подбора контрольной и тестовой групп для оффлайн эксперимента PSM может быть полезен и в онлайне в случае, когда А/А-тесты красятся. Для таких групп А/А можно провести PSM и проанализировать пользователей, к которым "близнецы" и не нашлись и тем самым найти причину прокраса.

PSM можно применять как до, так и после эксперимента.

Предположим, мы разбили оффлайн-магазины на группы А и Б. Теперь для каждого магазина из контроля мы хотим найти соответствующего близнеца и теста по всем основным метрикам, которые мы выбрали.

Считается логистическая регрессия, которая определяет вероятность определения в тестовую (treatment) группу:

Pr(Treatment = 1 | X1, X2, ... , Xk), где Xk - независимая переменная

Сравниваем каждый элемента из контроля с каждым из теста и считаем дельту их ps_scores. Пары с минимально дельтой фиксируем как близнецов. PSM можно настроить, чтобы он подбирал близнецов 1 к 1, а не многие ко многим (чтобы для нескольких магазинов из теста не был один близнес из контроля).
