---
tags:
  - data
data_type:
  - AB tests
link: https://habr.com/ru/companies/glowbyte/articles/696540/
company: Glowbyte
source: habr
author: Glowbyte
---
Хабр, привет! 

Меня зовут Полина Окунева, я работаю ведущим аналитиком в компании GlowByte в команде Advanced Analytics, а также автор [курса по A/B тестам](https://clck.ru/32bZhu). Сегодня в статье я предлагаю интересующимся небольшой гайд по A/B-тестам.

Когда я начала погружаться в тему A/B-тестирования пару лет назад, меня кидало из стороны в сторону: то перечитывала фундаментальные учебники по статистике, то переключалась на статьи о конкретных методиках. Но во всем этом многообразии материалов для меня на тот момент был огромный недостаток — я не могла собрать все в кучу и разобраться, а как же проводить-то этот A/B-тест? Я знала, что есть разные виды тестов, множественное тестирование и поправки, полезный и популярный Bootstrap… Но как все это соединить было не очевидно. Хотелось понять, какие этапы есть у A/B-тестирования и на каком этапе на что обращать внимание. Хотя бы какие термины гуглить и когда.

Сегодня я представляю вашему вниманию пазл, который сложился в моей голове по итогу плотной работы в этой теме. Я не претендую на истину в последней инстанции — шаги могут и должны(!) быть адаптированы конкретно под вашу задачу. Но если вы только начинаете входить в сферу A/B-тестирования, надеюсь, статья будет очень полезна. Я не буду подробно останавливаться на каждом понятии. Моя цель — обозначить технические этапы и показать новичкам модельную картину A/B-тестирования.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/7c7/fd0/c9f/7c7fd0c9ff5e413565de00552e28dd3e.jpeg)

Классически, можно начать с обсуждения, а зачем нужно A/B-тестирование. Но я рассчитываю, что те хабровчане, кто заглянул в статью, понимают его цель. Если нет, то можно посмотреть эти материалы:

- [A/B Тестирование: Основы / Хабр](https://habr.com/ru/company/otus/blog/546168/)
    
- R. Kohavi, Trustworthy Online Controlled Experiments
    

В начале статьи я дам основной роадмэп эксперимента. Внутри каждого этапа мы будем разбирать более подробно понятия, относящиеся к этому этапу.

### Роадмэп A/B-теста крупными мазками 

Весь процесс эксперимента можно разделить на 4 этапа:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/33a/443/494/33a44349421d8647971854f6c5c7303d.png)

**Планирование эксперимента:**

1. выбираем и фиксируем метрики;
    
2. формулируем гипотезу H0, альтернативную и выбираем MDE;
    
3. выбираем способ подведения итогов;
    
4. определяем alpha и beta, размер выборки и MDE;
    
5. оптимизируем размер выборки.
    

**Подготовка групп:**

1. разбиваем клиентов на группы;
    
2. проводим стратификацию, если она возможна;
    
3. замораживаем клиентов, участвующих в кампании (контрольная и тестовая группы).
    

**Запуск эксперимента:**

1. проверяем статус факта воздействия;
    
2. проверяем, что объекты из контрольной группы были без воздействия;
    
3. контролируем заморозку клиентов;
    
4. уточняем, как замораживается глобальная контрольная группа (если планируется ее учет в анализе).
    

**Анализ результатов:**

1. подготавливаем данные;
    
2. анализируем результаты эксперимента.
    

### Планирование эксперимента

1. Выбираем и фиксируем метрики
    

На начальном этапе важно определиться с метрикой, за которой будем наблюдать. Кажется, что это не так сложно — берем «деньги» и все. Ведь в конечном итоге цель бизнеса — растить прибыль. Но не все так однозначно. Начиная с того, что деньги бывают разные — средний чек, или сумма трат в неделю, или средняя маржа. Заканчивая тем, что на текущем этапе важнее могут быть другие метрики: CTR (click-through-rate), конверсия в покупку или удовлетворенность пользователей сервисом. К выбору метрики нельзя относиться снисходительно и необходимо определить, на какие параметры ваш эксперимент должен оказать влияние.

В целом, метрики можно разделить на три типа:

- целевая;
    
- прокси (опережающая);
    
- guardrail (барьерная).
    

На основе _целевой метрики_ принимается решение об успешности эксперимента. Это основная метрика, за которой наблюдаем.

Не всегда есть возможность ждать результатов по целевой метрике. Например, интересует результат в деньгах, но чтобы увидеть статистически значимый эффект необходимо собирать данные три месяца. Долго. Поэтому, как один из вариантов, можно рассмотреть _прокси-метрику_ «конверсия», для получения результатов по которой необходимо только две недели.

Прокси-метрика подбирается по историческим данным. Одна должна быть сонаправлена с целевой, т.е. меняться в ту же сторону при внешнем воздействии, что и целевая. Еще один принципиальный момент — бизнес должен быть согласен с прокси-метрикой в качестве целевой.

_Guardrail-метрика_ — общая для всей компании барьерная метрика, которую нельзя «ронять». При запуске теста нужно удостовериться, что барьерных метрик нет или они есть, но изменение в тесте на них не влияет или влияет положительно. В качестве примера такой метрики может выступать маржа.

2. Формулируем гипотезу H0, альтернативную и выбираем MDE
    

Этот топик один из самых интересных и, в то же время, контринтуитивных.

При планировании эксперимента необходимо задать две гипотезы.

_Гипотеза H0_: при внесении каких-то изменений или запуске кампании ничего не поменяется. Это нежелательная ситуация, поэтому ее мы хотим отвергнуть. Сделать это можно только в пользу другой гипотезы, альтернативной.

_Альтернативная гипотеза H1_: после внесения изменений будет получен минимальный эффект (minimum detectable effect, MDE).

_MDE_ — это граничное значение эффекта, ради которого имеет смысл вводить какие-то изменения. Если влияние изменений будет меньше заданного, то его невозможно зафиксировать в эксперименте, и практического смысла в столь маленьком эффекте нет. Если эффект будет больше — здорово, повезло, его тоже отметим.

Как задать MDE — вопрос хороший. Можно опираться на исторические запуски похожих изменений, учесть издержки на время/деньги/скидки, которыми придется пожертвовать.

Не стоит относиться к формальности гипотез снисходительно. Если отвергнуть гипотезу Н0 не получилось, то это не значит, что она верна. С точки зрения математической логики, суждения «Н0 не опровергнута» и «Н0 верна» не тождественны друг другу.

Кроме того, если вы отвергли гипотезу Н0 в пользу альтернативной, это значит, что полученный в эксперименте эффект может оказаться и больше, чем мы закладывали как MDE.

А еще существуют ошибки при принятии решения. О них чуть далее.

3. Выбираем метод тестирования
    

Тесты бывают непараметрические и параметрические.

В _непараметрических_ тестах анализируются распределения, которые не параметризуются при анализе — ни средним, ни стандартным отклонением, ни какими-либо другими параметрами. Эти методы в статье я не буду рассматривать, а обращу ваше внимание на два других вида тестов.

В _параметрических_ тестах необходимо оценивать среднее и стандартное отклонение. Если обратиться к формулам, то везде в них фигурирует разность средних. Такие тесты помогают оценить, произошел ли сдвиг в среднем значении определенной метрики — именно этот вопрос и интересен в большинстве случаев.

Примеры параметрических тестов: 

- Ztest;
    
- Ttest Student;
    
- Ttest Welch;
    
- ANOVA /ANCOVA.
    

Распространенное заблуждение, что Ttest применим исключительно к нормальным распределениям. Информацию о Ttest можно найти [здесь](https://habr.com/ru/company/glowbyte/blog/594183/) и [здесь](https://koch-kir.medium.com/%D0%B8%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F-%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BE%D0%B1%D0%BC%D0%B0%D0%BD%D0%B0-%D0%B8%D0%BB%D0%B8-%D1%82%D1%80%D0%B5%D0%B1%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BA-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8E-%D0%B2-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85-%D1%82%D0%B5%D1%81%D1%82%D0%B0%D1%85-55139a5558d). Огромное преимущество Ttest — он быстрый. Очень.

Если вам надо сравнить не просто среднее двух распределений, а что-то более специфичное, например, моду или определенный персентиль, обратите внимание на метод Bootstrap. Принцип его работы: 

1. из выборок A и B собираем подвыборки с повторением;
    
2. на каждой из подвыборок считаем интересующую нас метрику;
    
3. рассчитываем разность полученных метрик.
    

Повторяем такую операцию много раз и в итоге получаем набор разностей метрик — распределение разностей.

Теперь необходимо оценить, где находится число 0 в этом распределении. Если тестировалась гипотеза, что «новое» распределение будет сдвинуто вправо (эффект положительный) относительно «старого» распределения, то распределение разностей метрик тоже должно быть сдвинуто вправо относительно 0.

![Площадь под графиком влево от 0 показывает, какая доля разностей имеет значение меньшее 0. Если их меньше 5%, то эффект действительно статистически значимый.](https://habrastorage.org/r/w1560/getpro/habr/upload_files/968/76b/ee9/96876bee9f3ac3ea9a5f590577d2e736.png "Площадь под графиком влево от 0 показывает, какая доля разностей имеет значение меньшее 0. Если их меньше 5%, то эффект действительно статистически значимый.")

Площадь под графиком влево от 0 показывает, какая доля разностей имеет значение меньшее 0. Если их меньше 5%, то эффект действительно статистически значимый.

Недостатком Bootstrap может быть длительное время работы. Но есть решение: гуглите термины бакетирование и пуассоновский Bootstrap.

Комментарий: я допускаю, что у коллег из других компаний могут быть другие советы по выбору теста, основанные на их личном опыте. И это нормально! Выбор теста сильно зависит от постановки вашей задачи и требований. Поэтому любые абстрактные советы надо пропускать через призму здравого смысла и конкретно вашей ситуации.

4. Определяем alpha и beta, размер выборки, MDE
    

Ну какой рассказ про A/B-тесты без обсуждения ошибок 1 и 2 рода, или alpha и beta? 

_Ошибка 1 рода_ (alpha, ![\alpha](https://habrastorage.org/getpro/habr/upload_files/9cf/02b/749/9cf02b7492516953909c5aa784687164.svg)) определяет вероятность того, что будет принято ложно-положительное решение. Это значит, что по итогу эксперимента будет отвергнута базовая гипотеза H0 в пользу альтернативной, что неверно.

_Ошибка 2 рода (beta, ![\beta](https://habrastorage.org/getpro/habr/upload_files/749/aa0/6f1/749aa06f165ba8d75cc0f6a14441941e.svg))_ указывает на вероятность того, что эффект, который действительно есть, не был выявлен. Так случается, когда подвыборки по итогу эксперимента, не демонстрируют эффект, который в действительности, на генеральной совокупности, присутствует.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6cb/b66/a1b/6cbb66a1b3bba2a7fdeb97f0d5300487.png)

Почему-то ошибка 1 рода более известна. Но важность ошибок зависит от ситуации. Например, если проводится тест на тему заболевания у человека, то здесь ошибка 2 рода может играть более важную роль.

В индустрии принято устанавливать ошибку 1 рода на уровне 0,05 (или 5%), а ошибку 2 рода — на уровне 0,2 (или 20%). Но эти уровни обязательно нужно адаптировать под каждую конкретную ситуацию.

Отмечу еще такое понятие как _мощность_ (или _power_) — вероятность принять альтернативную гипотезу, когда она действительно корректная. Математически выражается как ![1 - \beta](https://habrastorage.org/getpro/habr/upload_files/885/24c/c9d/88524cc9dbd1cc96ab06cb27d8eed5c0.svg).

На этот моменте стоит остановиться и обсудить множественное тестирование и как оно связано с ошибками. Множественным тестированием называют ситуацию, когда за один эксперимент планируется оценить сразу несколько гипотез. Например, 10 вариантов оттенка синего.

При таком варианте теста резко возрастает процент ложно-положительных срабатываний, т.е. эффект заметен там, где его в действительности нет. Это происходит из-за того, что вероятность ложно-положительных срабатываний зависит от числа экспериментов степенным образом: ![1 - (1 - \alpha)^n](https://habrastorage.org/getpro/habr/upload_files/765/2b4/ee6/7652b4ee688d8a1af87c389bab7bb7f2.svg), где n — количество экспериментов.

Чтобы этого избежать, нужно вводить поправки на ошибку 1 рода, например:

1. поправка Бонферони;
    
2. поправка Бенджамини-Хохберга;
    
3. поправка Холма.
    

Такие поправки позволяют вручную скорректировать ситуацию при множественном тестировании путем уменьшения ошибки 1 рода. Однако, даже при наличии поправок, настоятельно рекомендую не проверять за раз больше трех гипотез.

Теперь переходим к практическому вопросу — как рассчитать размер выборки для получения статистически значимого результата. Для этого аналитику нужно найти компромисс между четырьмя переменными:

- ошибка 1 рода;
    
- ошибка 2 рода;
    
- MDE;
    
- размер выборки.
    

Рассчитать размер выборки можно через онлайн-калькуляторы, например, [Sample Size Calculator (Evan’s Awesome A/B Tools)](https://www.evanmiller.org/ab-testing/sample-size.html) — для конверсии.

У таких калькуляторов есть недостаток: внутри них расчеты базируются на параметрических тестах (обычно Ttest, Ztest или chi2), где анализируется разница между средними значениями. Поэтому если необходимо проанализировать, как сдвинулся 5-й персентиль, то лучше использовать Bootstrap-имитацию. Она позволяет наглядно рассчитать, какое количестве сэмплов необходимо собрать для получения статистически значимого результата, вне зависимости от формы распределения, его особенностей и метрики.

![Модельный вариант Bootstrap-имитации.](https://habrastorage.org/r/w1560/getpro/habr/upload_files/448/e90/0fe/448e900fe3a35b9afe6710ec78f9ff98.jpg "Модельный вариант Bootstrap-имитации.")

Модельный вариант Bootstrap-имитации.

Пытливый читатель увидит в этой схеме неточность — в пункте 1 фиксируется beta, а в конце цикла считается мощность. Но противоречия здесь нет.

Сначала аналитик примерно определяет уровень мощности через ошибку 2 рода, но до момента проведения множества Bootstrap-имитаций это значение нигде не используется. И только когда уже есть все имитационные эксперименты для фиксированного sample_size и по каждой паре подвыборок принято решение об отвержении нулевой гипотезы, можно рассчитать реальную мощность на реальных данных.

Мощность — это доля тех пар подвыборок, на которых было принято верное решение отвергнуть нулевую гипотезу (на уровне alpha). И это число может быть 76% или 84%… И эта вариативность в зависимости от сэмпла дает еще одну степень свободы при выборе размера групп. Стоит ли дополнительно набирать 500 сэмплов, чтобы увеличить мощность на 1%? 

Помимо цикла по sample_size я советую проводить цикл по эффекту. Это дает дополнительную степень свободы при выборе оптимального сочетания ошибок 1 и 2 рода, MDE и размера выборки. Результат представлен в таблице ниже:

![Определение мощности при предполагаемом эффекте и количестве наблюдений в группе.](https://habrastorage.org/r/w1560/getpro/habr/upload_files/f58/6ef/49d/f586ef49dacb349fd88d6f989f3b5dd3.png "Определение мощности при предполагаемом эффекте и количестве наблюдений в группе.")

Определение мощности при предполагаемом эффекте и количестве наблюдений в группе.

Более подробно Bootstrap-имитацию мы рассматриваем в курсе.

5. Оптимизируем размер выборки
    

Стандартное пожелание бизнеса — протестировать все получше и побыстрее. И на этапе оптимизации мы можем этому поспособствовать.

Сократить длительность теста и повысить его точность можно с помощью уменьшения ошибок 1 и 2 рода. Это можно сделать, в основном, следующими способами:

- удаление выбросов;
    
- функциональное преобразование;
    
- уменьшение дисперсии.
    

Рассмотрим каждый подпункт немного подробнее.

_Удаление выбросов_ — хороший метод, который позволяет не только сократить дисперсию, но и освободиться от шумовых данных. Но убирать нужно минимально, я рекомендую до 1% данных. Например, только технические ошибки или сегмент, с которым мы не работаем на тесте.

_Функциональное преобразование_ полезно тогда, когда исходное распределение сильно скошено. Такое распределение можно преобразовать в нормальное путем применения определенной функции, например, логарифмированием. Я бы не возлагала серьезные надежды на этот способ, но попробовать стоит.

_Уменьшение дисперсии_ можно выполнять методами CUPED и CUPAC.

CUPED (Controlled-experiment Using Pre-Experiment Data) позволяет сократить дисперсию в данных путем расчета разности целевой переменной и переменной ![X](https://habrastorage.org/getpro/habr/upload_files/83c/456/9b0/83c4569b0a8781d5ff7580b3b8af5596.svg), независимой от целевой. Чтобы переменная ![X](https://habrastorage.org/getpro/habr/upload_files/9cc/9f4/ecb/9cc9f4ecb986fe7336c408dfc3b7972c.svg)была истинно независимой от ![Y](https://habrastorage.org/getpro/habr/upload_files/624/c05/acb/624c05acb83d961562fdafeec06910fb.svg)обычно в качестве нее берут ту же метрику, что и ![Y](https://habrastorage.org/getpro/habr/upload_files/80a/db5/f21/80adb5f2150a5d44fdb84a9a4e495b5a.svg), но до эксперимента.

![Y_{cuped} = Y - \theta X + \theta E(X)](https://habrastorage.org/getpro/habr/upload_files/3c3/7dc/7f6/3c37dc7f6ee2106ffec82e61ce874705.svg)

Разность рассчитывается с учетом коэффициента ![\theta](https://habrastorage.org/getpro/habr/upload_files/a34/6c6/af6/a346c6af6c7ab49ff3482479eb47648a.svg):

![\theta = cov(Y,X) / var(X)](https://habrastorage.org/getpro/habr/upload_files/063/16b/f02/06316bf0224187fdeb3f467b3544cf81.svg)

Суть такого преобразования заключается в том, что мы убираем определенную составляющую вариативности ![Y](https://habrastorage.org/getpro/habr/upload_files/0d7/62b/b90/0d762bb90d2183ac5798131505116643.svg), которая обусловлена ковариатой ![X](https://habrastorage.org/getpro/habr/upload_files/f29/4f5/759/f294f5759f9c6650bf7223c396e45d10.svg).

CUPAC (Control Using Predictions as Covariate) аналогичен методу CUPED за тем отличием, что в качестве ковариат берутся не исторические данные, а прогноз обычно целевой переменной на интересующий период. Далее схема работы такая же как в CUPED: рассчитывается преобразованная метрика ![Y_{cuped}](https://habrastorage.org/getpro/habr/upload_files/cbf/3b5/b40/cbf3b5b408e0b01118dbf7ff18a8a580.svg), которая может обладать меньшей дисперсией.

### Подготовка групп

1. Разбиваем клиентов на группы
    

Если компания настроена на проведение A/B-тестирования, то слабо верится в то, что в один момент времени будет запускаться только один тест. Обычно это происходит следующим образом: одна команда тестирует цвет кнопки, другая — скидки, третья — рекомендательную систему и т.д.

Являются эксперименты зависимыми или нет определяют метрики и контекст. Например, вы тестируете две акции: скидка 20% при покупке от 2000 рублей и бесплатное такси до дома при покупке от 2000 рублей. Если при этом вы ожидаете, что средний чек вырастет, то при анализе результатов стоит задуматься о том, как эти акции влияют друг на друга.

Если тесты зависимые, то нужно проконтролировать, что одни и те же объекты не попадают в оба теста. Если тесты независимые — то желательно, чтобы влияние эксперимента на контрольную и тестовую группу было сбалансировано.

2. Проводим стратификацию
    

Стратификация позволяет получить более репрезентативную выборку на меньшем объеме данных. Этот метод я рекомендую применять всегда, когда есть возможность.

При стратификации происходит разделение выборки на сопоставимые группы по определенным параметрам. Для этого исходный датасет разбивается на подгруппы путем кластеризации или бакетирования.

![Кластеризация объектов. По 5% объектов из каждого кластера определяются в группы A и В.](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ea1/7d1/53c/ea17d153ca38907af52eeda8a8732fe6.png "Кластеризация объектов. По 5% объектов из каждого кластера определяются в группы A и В.")

Кластеризация объектов. По 5% объектов из каждого кластера определяются в группы A и В.

![Бакетирование. Применяется, когда значения метрики непрерывны. Из каждого бакета выбираются объекты в группы А и В.](https://habrastorage.org/r/w1560/getpro/habr/upload_files/4cc/0d0/56f/4cc0d056f9323b7c1345658d4d6b5b07.jpg "Бакетирование. Применяется, когда значения метрики непрерывны. Из каждого бакета выбираются объекты в группы А и В.")

Бакетирование. Применяется, когда значения метрики непрерывны. Из каждого бакета выбираются объекты в группы А и В.

Обычно стратификация применяется в задачах, где не запредельно много клиентов. Когда запускаются A/B-тесты в рамках сайтов, то к стратификации относятся менее щепетильно. Более того, в некоторых случаях ее сделать в принципе невозможно, т.к. данные накапливаются постепенно. В такой ситуации необходимо подумать о постстратификации — вариант стратификации, который делается уже по факту, в результате которого мы пытаемся уже из имеющихся данных выделить две сопоставимые группы.

3. Замораживаем клиентов, участвующих в кампании (контрольная и тестовая группы)
    

На клиентах, отобранных для тестовой и контрольной групп, нельзя запускать другие кампании. Поэтому такие клиенты замораживаются — до окончания текущего эксперимента их данные нельзя использовать для тестирования гипотез. 

### Запуск эксперимента

Этот этап эксперимента будет самый короткий по описанию и без пояснений не потому, что он не принципиален. Скорее наоборот. Это понятные и супер-важные этапы, которые вроде и не зависят от аналитика, но от них зависят результаты теста. И именно поэтому я призываю отметить их особенно:

1. проверьте статус факта воздействия;
    
2. проверьте, что объекты из контрольной группы были без воздействия;
    
3. проконтролируйте заморозку объектов;
    
4. уточните, как замораживается глобальная контрольная группа (если планируется ее учет в анализе).
    

Эти шаги не придуманы абстрактно, а основаны на моей практике и ошибках, с которыми приходилось сталкиваться в работе. Обычно организация взаимодействия с объектами лежит на плечах других команд. Например, вы составили списки клиентов, но коммуникацию организует другое подразделение. И здесь может что-то пойти не так: добавили клиентов, которые уже участвуют в других акциях, или перепутали контрольную и тестовую группу. Поэтому стратегически важно проверить выполнение тех условий, что были задуманы вами на этапе планирования эксперимента.

### Анализ результатов

1. Подготавливаем данные
    

На этапе обработки результатов эксперимента применяем все те же методы, которые применялись при имитации эксперимента на этапе подготовки, — функциональное преобразование данных, снижение дисперсии в данных, удаление выбросов.

2. Анализируем результаты эксперимента
    

На этом этапе нужно применить статистический критерий и получить p-value. У аналитиков, только встающих на путь A/B-тестирования, часто возникает ощущение, что p-value — нечто магическое, а его значение возникает из ниоткуда и не подлежит оспариванию.

На самом деле p-value отражает вероятность встретить такое же или еще более экстремальное значение, чем заданное. Рассчитывается как площадь под графиком от начального значения и в сторону хвоста. Например, p-value для значения 150 000 равно всего 6%.

![p-value отражает долю значений таких же или еще более экстремальных, чем заданное (15 000).](https://habrastorage.org/r/w1560/getpro/habr/upload_files/684/35b/c19/68435bc196276e9a11f81275d2c2e23c.jpg "p-value отражает долю значений таких же или еще более экстремальных, чем заданное (15 000).")

p-value отражает долю значений таких же или еще более экстремальных, чем заданное (15 000).

Логика за принятием решения на основе p-value следующая: если в результате эксперимента было получено такое значение метрики, которое в концепции базовой гипотезы H0 очень маловероятно, то базовая гипотеза отвергается в пользу альтернативной.

Другими словами, если p-value < alpha, то отличие сравниваемых групп считается статистически значимым, поэтому нулевая гипотеза отвергается в пользу альтернативной. Если нет — отвергнуть нулевую гипотезу не можем.

Можно долго рассуждать на тему, а стоит ли «подтюнивать» получившийся p-value. Например, alpha вы установили на уровне 0,05, а p-value оказался 0,051. В разных компаниях к этой ситуации могут относиться по-разному. Моя рекомендация — строго определять, с какой стороны относительно alpha находится значение p-value. Самое главное — у всех команд тестирования в компании должен быть единый способ работы с p-value.

Так же на этом этапе советую изучить тему подглядывания. У Анатолия Карпова есть очень подробный выпуск: [Тонкости A/B тестирования: проблема подглядывания](https://www.youtube.com/watch?v=jnFVmtaeSA0).

На этом все. Искренне надеюсь, что этот гайд поможет вам сориентироваться при подготовке A/B-теста.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/7c0/8e4/ebd/7c08e4ebdc2169715a5611528770c1e2.png)

Если вы хотите поглубже погрузиться в вопросы A/B-тестирования и более детально разобрать каждый из этапов, то приглашаю вас на курс от GlowByte, который стартует 28.11.2022. Более подробное описание каждого из дней курса по ссылке: [курс по А/B-тестированию.](https://clck.ru/32bZhu)

А так же будем рады всех видеть в нашем сообществе noML, где мы активно обсуждаем различные темы вокруг ML и продвинутой аналитики в реальных бизнес-задачах: