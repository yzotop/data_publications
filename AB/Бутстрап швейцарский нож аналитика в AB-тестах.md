---
tags:
  - data
link: https://habr.com/ru/articles/762648/
data_type:
  - AB tests
source: habr
author: Mosin
---
[[База - айсберг AB тестов]]
[[Линеаризация - зачем и как укрощать ratio-метрики в AB-тестах]]

Вам надоело каждый раз разбираться какую гипотезу, а главное с какими ограничениями к имеющимся данным проверяет бесчисленное множество статистических тестов?  
Тогда бутстрап — это ваш выбор. Он не требует никаких параметрических предположений о данных или какой-либо нетривиальной математики и, вместе с тем, может быть применен к широкому спектру статистических оценок.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9d7/8fb/b89/9d78fbb8993163ca07db61a270ffb415.png)

## Вступление

Бутстрап позволяет из выборок, полученных из базы данных или в результате A/B-теста, путем повторного отбора наблюдений строить **_эмпирическое_ распределение любой выборочной статистики** (метрики) без предварительных ограничений или требований к данным. С его помощью можно:

- Построить _доверительный интервал_, например, для 60-го перцентиля, суммы или даже дисперсии;
    
- Посчитать _результаты эксперимента_ для медианы;
    
- Найти p-value для приемочной _ratio-метрики_ с зависимыми наблюдениями, такой как CTR или средний чек;
    
- Провести _анализ мощности_ разных статкритериев в A/B-тесте;
    
- Постараться найти в какой части распределения _произошел эффек_т от экспериментального воздействия.
    

#### ❗️Основная идея❗️

Бутстрап старается _притворяться_ генеральной совокупностью. Идейно можно к этому относиться так: у вас есть возможность провести сколько угодно «экспериментов» для проверки одной гипотезы, где у вас есть доступ ко всей **«**генеральной совокупности**»**, которой является наша исходная выборка. Данная иллюзия поддерживается именно семплированием наблюдений с повторением.

Однако бутстрап не генерит новой информации и соответственно не повышает, репрезентативность исходных данных.  
Кроме того, бутстрапированные выборки _семплируются в объеме исходной._ Это нужно, чтобы получить достаточно точную оценку вариативности (дисперсии) интересующей статистики, которая как раз и зависит от размера исходной выборки, как _standard error_ для разницы средних в **t-тесте**.

Обобщенная реализация функции бутстрапа выглядит достаточно просто.

1. Взять исходную выборку;
    
2. Провести «эксперимент», отбирая в бут-выборку наблюдения с повторением;
    
3. На получившейся выборке посчитать интересующую статистику и положить ее в массив;
    
4. Повторить пункты 2 и 3 много-много раз и получить эмпирическое распределение статистики;
    
5. Получить из этого распределения нужную информацию;
    
6. Визуализировать для информативности.
    

```
import numpy as npimport pandas as pdfrom scipy import statsimport seaborn as snsimport matplotlib.pyplot as pltdef bootstrap(sample, n_trials=5_000, statistic=np.median):    rng = np.random.default_rng()    stat_distrib = []    # get booted samples and count stat    for _ in range(n_trials):        boot_sample = rng.choice(sample, size=len(sample), replace=True)        stat_distrib.append(statistic(boot_sample))    result = do_some_math(stat_distrib)    do_some_viz(result, stat_distrib)    return resultdef do_some_math(data):    passdef do_some_viz(data):    pass
```

## Практика

Разберем указанные возможности бутстрапа на примерах. За основу возьмем набор непрерывных значений из экспоненциального распределения, например, трат пользователей. Данное распределение может выглядеть примерно так.

![Распределение трат пользователей](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1dc/49f/c85/1dc49fc85665d0a6aabb11ba3671b46a.png "Распределение трат пользователей")

Распределение трат пользователей

### 1. Построение доверительных интервалов

Давайте для нашей выборки значение 60-го перцентиля зададим интервальной оценкой с уровнем доверия 95%.

```
CONF_LVL = 0.95def bootstrap_ci(sample, n_trials=5_000, statistic=np.median):    rng = np.random.default_rng()    stat_distrib = []    # get booted samples and count stat    for _ in range(n_trials):        boot_sample = rng.choice(sample, len(sample), replace=True)        stat_distrib.append(statistic(boot_sample))        result = do_some_math(stat_distrib)    do_some_viz(result, stat_distrib)    return resultdef do_some_math(data):    # confidence interval counting    left_q = (1 - CONF_LVL) / 2    right_q = 1 - left_q    ci = np.quantile(data, [left_q, right_q])    return ci    def do_some_viz(res, data):    hist = plt.hist(data, bins=32, color='lightsalmon')    ymax = hist[0][np.argmax(hist[0])]    plt.vlines(np.mean(data), ymin=0, ymax=ymax, colors='black',                 label=f'Statistic mean: {np.mean(data).round(3)}')    plt.vlines(res, ymin=0, ymax=ymax//2.5, linestyle='--', colors='black',                 label=f'CI: {res[0].round(3)} and {res[1].round(3)}')    plt.xlabel('statistic value', fontsize=14)    plt.ylabel('frequency', fontsize=14)    plt.legend(loc=0)    return Nonedef quant_60(data):    return np.quantile(data, 0.6)ci = bootstrap_ci(spendings, statistic=quant_60)
```

На выходе получится приблизительно вот такой график эмпирического распределения выбранной статистики. Среднее значение данного распределения будет очень близко к оценке 60-го перцентиля в нашей исходной выборке.

![Эмпирическое распределение 60-го перцентиля трат пользователей](https://habrastorage.org/r/w1560/getpro/habr/upload_files/2fc/742/8a8/2fc7428a8867591494834752a6245bf8.png "Эмпирическое распределение 60-го перцентиля трат пользователей")

Эмпирическое распределение 60-го перцентиля трат пользователей

На практике такое можно использовать для построения подневных графиков интересующих метрик с их границами ДИ или для презентации важной бизнесовой метрики, которая получилась в тестовой группе эксперимента, обычно это касается денег.

### 2. Результаты экспериментов по произвольной статистике

Иногда возникает продуктовая потребность оценить результаты эксперимента не для среднего значения, а для медианы. Реализовать это можно следующим образом.

```
CONF_LVL = 0.95def bootstrap_ab(s1, s2, n_trials=5_000, statistic=np.median):    rng = np.random.default_rng()    stat_distrib = []    for _ in range(n_trials):        boot_s1 = rng.choice(s1, len(s1))        boot_s2 = rng.choice(s2, len(s2))        stat_distrib.append(statistic(boot_s1) - statistic(boot_s2))        result = do_some_math(stat_distrib)    do_some_viz(result[1], stat_distrib)    return resultdef do_some_math(data):    # confidence interval counting    left_q = (1 - CONF_LVL) / 2    right_q = 1 - left_q    ci = np.quantile(data, [left_q, right_q])        # p_value    quant = stats.norm.cdf(x=0, loc=np.mean(data), scale=np.std(data, ddof=1))    p_value = quant * 2 if 0 < np.mean(data) else (1 - quant) * 2    return p_value, cip_value, ci = bootstrap_ab(spendings_t, spendings_c)
```

Тут уже необходимо делать бут-выборки из двух «генеральных совокупностей», теста и контроля. Получив эмпирическое распределение разнозностей статистик, к нему можно относиться как в реализации «ЦПТ».  
Чтобы найти _p-value_ для двухсторонней гипотезы, необходимо узнать долю случаев, когда разница была равна **0** и случаев еще более выраженных. Для этого просто находим, в каком квантиле нашего эмпирического распределения расположен **0,** и считаем хвосты.  
Также в качестве критерия можно использовать ДИ. Если **0** за пределами границ ДИ, то отвергаем нулевую гипотезу _H0_.

![Результаты эксперимента для медианы](https://habrastorage.org/r/w1560/getpro/habr/upload_files/2a8/737/503/2a873750351f7e4324700b0020801381.png "Результаты эксперимента для медианы")

Результаты эксперимента для медианы

Для проверки гипотезы о разницы средних значений существует разработанный статаппарат, а именно всеми любимый **t-тест**. В нем, согласно ЦПТ, разница средних имеет нормальное распределение, и для этого распределения известна мера шума (_standard error_) и оценки доверительных интервалов.

![Стандартная ошибка среднего и границы 95% доверительного интервала в t-тесте](https://habrastorage.org/r/w1560/getpro/habr/upload_files/075/bd5/375/075bd537505e4d078645b3cb337ce038.png "Стандартная ошибка среднего и границы 95% доверительного интервала в t-тесте")

Стандартная ошибка среднего и границы 95% доверительного интервала в t-тесте

Так вот, бутстрап будет давать приблизительно такие же результаты при подсчете средних значений в эксперименте что и **t-тест**. Точность этих результатов будет расти вместе с ростом объема исходных выборок и количества итераций. Можно сказать, что бутстрап на средних значениях является _вычислительно затратной аппроксимацией_ **t-теста.** Они также будут иметь приблизительно одинаковую _мощность_, но об этом ниже.

На примере со средними можно нагляднее продемонстрировать, почему бут-выборки формируются в объеме исходных данных. Если увеличить размер семплируемых бут-выборок в 25 раз, то эмпирическое распределение разниц среднего сузится, а _standard deviation_ станет примерно в 5 раз меньше (если размеры групп приблизительно одинаковые) посчитанного значения _standard error_ для **t-теста**.

![Расхождение оценок шума разницы средних значений при увеличении объема бут-выборок](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9da/41e/4b0/9da41e4b0d135cb07f401ddc1f9fa2fc.png "Расхождение оценок шума разницы средних значений при увеличении объема бут-выборок")

Расхождение оценок шума разницы средних значений при увеличении объема бут-выборок

### 3. Работа с ratio-метриками

Если мы для каждого пользователя поделим его траты на число заказов, то мы получим биномиальное распределение. Однако среднее значение по такому распределению будет _средний чек на пользователя_, т.е. среднее средних значений.  
Обычно же _средний чек_ в продукте определяется как сумма всех трат пользователей разделенная на сумму всех заказов. Такие показатели называются ratio-метриками, к ним еще относится _CTR_.  
На картинке внизу представлено расхождение в значениях среднего чека на пользователя и среднего чека.

![Распределение поюзерного среднего чека в группах](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b5c/9fc/874/b5c9fc8749bdda59036bc258d1fd901f.png "Распределение поюзерного среднего чека в группах")

Распределение поюзерного среднего чека в группах

Суть проблемы ratio-метрик заключается в их оценки статистическими критериями, которые обычно требуют **независимости** входных величин. То есть, если построить распределение, где одно наблюдение это стоимость чека, то уже в нем всегда будут _зависимые величины_, так как несколько заказов мог сделать один пользователь, отсюда и зависимость.  
Но и тут для бутстрапа нет никаких преград.

```
def bootstrap_ratio(s1_num, s1_denom, s2_num, s2_denom, n_trials=5_000):    rng = np.random.default_rng()    stat_distrib = []    for _ in range(n_trials):        users_idx1 = rng.choice(np.arange(0, len(s1_num)), size=len(s1_num))        boot1_num = s1_num[users_idx1]        boot1_denom = s1_denom[users_idx1]        ratio1 = boot1_num.sum() / boot1_denom.sum()                users_idx2 = rng.choice(np.arange(0, len(s2_num)), size=len(s2_num))        boot2_num = s2_num[users_idx2]        boot2_denom = s2_denom[users_idx2]        ratio2 = boot2_num.sum() / boot2_denom.sum()                stat_distrib.append(ratio1 - ratio2)        result = do_some_math(stat_distrib)    do_some_viz(result[1], stat_distrib)    return resultp_value, ci = bootstrap_ratio(spending_t, n_check_t, spending_c, n_check_c)
```

В данной реализации надо семплировать с повторением случайных пользователей и отбирать их соответствующие сигналы для числителя (_numerator_) и знаменателя (_denominator_), а затем считать значение метрики. Построить эмпирическое распределение и получить из него ответы – это уже этап усвоенный.  
Из картинки внизу видно, что среднее значение в распределении уже больше похоже на наблюдаемую разницу средних чеков.

![Результаты бустрапа на ratio-метрике](https://habrastorage.org/r/w1560/getpro/habr/upload_files/433/da7/802/433da78025f4e5213a61f8dedd50ecd9.png "Результаты бустрапа на ratio-метрике")

Результаты бустрапа на ratio-метрике

### 4. Анализ мощности

Под мощностью теста обычно подразумевается вероятность принятия альтернативной гипотезы _H1_, когда она действительно верна. Мощность обычно зависит от размера имеющихся данных, а также модели эффекта, получаемого от экспериментального воздействия, и возможности статтеста этот эффект детектировать.  
Поскольку у нас есть возможность провести сколько угодно много «экспериментов», можно взять и буквально посчитать долю событий, когда мы приняли _H1_ при заданном уровне _alpha_ на разных статтестах. Возьмем **t-test**, **mannwhitney** **test** и **bootstrap** **на средних**.

```
ALPHA = 0.05def power_compute(s1, s2, n_trials=200):    rng = np.random.default_rng()    # dict for stattests' p_values    test = {'t': [], 'mw': [], 'btsp': []}        for _ in range(n_trials):        boot_s1 = rng.choice(s1, len(s1))        boot_s2 = rng.choice(s2, len(s2))                test['t'].append(stats.ttest_ind(boot_s1, boot_s2)[1])        test['mw'].append(stats.mannwhitneyu(boot_s1, boot_s2)[1])        test['btsp'].append(bootstrap_ab(boot_s1, boot_s2,                                          n_trials=500, statistic=np.mean))        result = do_some_math(test)    do_some_viz(test)    return resultdef do_some_math(test_dict):    power_dict = {}    for test in test_dict:        np_arr = np.array(test_dict[test])        power = len(np_arr[np_arr<=ALPHA]) / len(np_arr)        power_dict[f'{test}_power'] = power    return power_dictdef do_some_viz(test_dict):    df = pd.DataFrame(test_dict)    df = df.melt(var_name='test', value_name='p_val')        sns.ecdfplot(data=df, x='p_val', hue='test')    plt.vlines(x=ALPHA, ymin=0, ymax=1, colors='black')    plt.xlabel('Alpha')    plt.ylabel('Power')    return Nonepower_dict = power_compute(spendings_c, spendings_t)
```

На выходе получится словарь со значениями мощностей для выбранных тестов. На картинке получится _эмпирический кумулятивный (накопительный) график распределения_ (Empirical Cumulative Distribution Function). К нему можно относиться как к обычной гистограмме, в которой бины складываем слева направо, друг на друга. Однако _ECDF_ более информативен, поскольку нам нужны не частоты, а суммарная доля случаев, когда _p-value_ был ниже _alpha._ Доля интересующих нас случаев находится на пересечении вертикальной линии с линией соответствующего теста.  
Из графиков видно, что мощность **t-теста** такая же как для **бутстрапа на средних** и находится на уровне 80%.

![ECDF в сравнении с обычной гистограммой](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9d8/a43/51b/9d8a4351b582889333b42ba53074b2a6.png "ECDF в сравнении с обычной гистограммой")

ECDF в сравнении с обычной гистограммой

Анализ мощности с помощью бутстрапа может быть полезен для подведения результатов эксперимента.  
Например, могут быть случаи, когда заранее остановили A/B-тест, потому что он прокрасился в положительную сторону, но после анализа мощности, выяснится, что корректно принять _H1_ можно на уровне 50%, что сравнимо c подбрасыванием монетки.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ec2/660/46d/ec266046ded6efeb6c61cf99e64dccd0.png)

Маленькая мощность при прокрасе метрики

### 5. Перцентиль за перцентилем

Иногда в результатах A/B-тестов можно получать удивительные результаты, которые расходятся с нашими ожиданиями. Предположим, что был проведен эксперимент, и целевая метрика на мобилках статзначимо выросла, а на десктопе результат получился отрицательный, но серый. В качестве критерия использовался **t-тест**. Однако очень трудно пройти мимо такого падения и для десктопа можно узнать что непараметрический тест красит результат с мощностью 90%.

![Результат эксперимента](https://habrastorage.org/r/w1560/getpro/habr/upload_files/50c/6ab/f42/50c6abf42cc5c49f5900c472b09251b7.png "Результат эксперимента")

Результат эксперимента

Поскольку тест Манна-Уитни работает с рангами, можно с помощью бутстрапа «пробежаться» по децилям тестовой и контрольной групп и найти, где произошло смещение рангов (позиций). В представленном ниже варианте это произошло в первых четырех децилях.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/dac/b4a/147/dacb4a1476178632d0f66197e019f326.png)

Результаты децильного анализа

## Итог

Понято, что бутстрап плохо масштабируется из-за своей вычислительной требовательности, особенно если в компании проведение A/B-тестов поставлено на поток, и за раз могут считаться десятки и сотни продуктовых метрик.

Однако для решения специфичных задач или при вычислении в экспериментах статзначимости самых неожиданных функций всегда можно попробовать «стукнуть» по своим данным грубой вычислительной палкой, чтобы они попробовали дать чуть больше информации. Если усвоить главную идею, которая стоит за реализацией бустрапа, все за этим следующее будет ограничиваться только фантазией применяющего его аналитика.