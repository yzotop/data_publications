---
tags:
  - data
author: Lunin
link: https://habr.com/ru/companies/avito/articles/571096/
source: habr
data_type:
  - AB tests
company: Avito
---
Это вторая часть статьи о том, как улучшить A/B-тесты. Советую сначала [прочитать первую](https://habr.com/ru/company/avito/blog/571094/), чтобы лучше понимать материал. В новой части я подробно остановлюсь на методах увеличения мощности в A/B-тестах: поговорим про CUPED, бутстрап-критерии, стратификацию и парную стратификацию.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/786/7cd/015/7867cd015af6aeb5f6ea5017e07e7d68.png)

## Терминология

Ещё раз напомню терминологию, которую буду использовать в статье:

Статистически значимый результат — результат, который статистически значимо лучше 0.

Прокрас теста — результат эксперимента статистически значимо отличается от 0, и у вас есть какой-то эффект.

Зелёный тест — метрика в A/B-тесте статистически значимо стала лучше.

Красный тест — метрика в A/B-тесте статистически значимо стала хуже.

Серый тест — результат A/B-теста не статистически значим.

Тритмент — фича или предложение, чьё воздействие на пользователей вы проверяете в A/B-тесте.

MDE — [минимальный детектируемый эффект](https://help.optimizely.com/Ideate_and_Hypothesize/Use_minimum_detectable_effect_(MDE)_when_designing_an_experiment#:~:text=Minimum%20detectable%20effect%20(MDE)%20is,Baseline%20conversion%20rate). Размер, который должен иметь истинный эффект от тритмента, чтобы эксперимент его обнаружил с заданной долей уверенности (мощностью). Чем меньше MDE, тем лучше.

Мощность критерия — вероятность критерия задетектировать эффект, если он действительно есть. Чем больше мощность критерия, тем он круче. Мощность также напрямую зависит от ширины доверительного интервала: чем она меньше, тем мощнее критерий.

Предпериод — период до начала эксперимента.

## Методы увеличения мощности в AB-тестах

Для начала давайте вспомним, из каких 3 основных этапов состоит AB–тест:

1. Разделение пользователей на тест и контроль.
    
2. Активная стадия теста. Пользователи совершают действия, которые мы потом будем анализировать.
    
3. Анализ результатов. Здесь применяются статистические критерии для подведения итогов теста.
    

Каждый из этих этапов можно улучшить.

### Увеличение времени продолжительности теста

Начнём с самого простого метода увеличить мощности A/B-теста: увеличить время продолжительности теста. В основном, чем дольше вы держите тест, тем вероятнее получите статистически значимые результаты, потому что в эксперименте поучаствует больше людей. Чем больше людей, тем меньше дисперсия у средних величин, а значит, меньше доверительный интервал. Это увеличивает вероятность задетектировать эффект.

Но чем больше вы держите тест, тем меньше гипотез протестируете за определённый промежуток времени. Например:

- Вы держите один тест два месяца и не можете запустить другой тест, который влияет на результаты текущего эксперимента.
    
- Вы держите один тест один месяц, а во второй месяц запускаете второй эксперимент.
    

В первом случае доверительный интервал при анализе первого теста будет поменьше, чем во втором. Зато во втором случае вы смогли протестировать сразу две гипотезы.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/8f4/5e9/68d/8f45e968d681f360bc1403613c05a039.png)

Но даже если вы захотите продержать тест два года, не факт, что мощность критерия будет сильно лучше, чем если бы вы держали его год. У нас часто бывает, что людей становится больше, но и метрика в этот момент становится шумнее. Из-за этого не происходит сокращения доверительного интервала. Рассмотрим пример: для одного из наших A/B-экспериментов я построил зависимость ширины доверительного интервала от номера недели эксперимента.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/49c/519/675/49c519675139fdf611ac7ae67c757215.png)

Здесь видно, что в последние шесть недель доверительный интервал особо не менялся, а значит, не менялась и мощность критерия. Поэтому не важно, в какую из последних недель я проводил бы анализ: в мощности A/B-теста я бы не выигрывал. Но если бы я подержал эксперимент только шесть недель, то во вторые шесть бы мог запустить другой эксперимент и не потерять в мощности для первого.

Кстати, построив такой график на предэкспериментальном периоде, вы можете определить оптимальный срок A/B-теста. Как это сделать:

1. Например, вы планируете запустить тест 1 июня. Вы берёте значение метрики для пользователя
    
    - С 1 по 8 марта.
        
    - С 1 по 15 марта.
        
    - ...
        
    - С 1 марта по 31 мая.
        
2. Делите случайно в каждом примере выше пользователей на тест и контроль.
    
3. Запускаете на них ваш критерий. Считаете ширину доверительного интервала.
    
4. Рисуете график как в примере выше.
    
5. Определяете срок A/B-теста.
    

Таким образом вы сможете определить оптимальный срок, чтобы не проводить тест слишком долго и не потерять в мощности критерия.

Замечание: эти рассуждения корректны, если вы не измеряете долгосрочные эффекты от тритмента. В противном случае стоит как можно дольше держать эксперимент.

**Итого:** увеличение времени проведения — часто рабочий метод улучшить мощность A/B-теста, но лишь до определённого срока. Кроме того, это ограничивает скорость тестирования гипотез.

Перейдём к более интересной и всегда рабочей схеме: методам сокращения дисперсии при постанализе A/B-теста. Самый простой, но и самый опасный способ, — убрать выбросы или топ пользователей. Но это мы уже обсудили [в предыдущей статье](https://habr.com/ru/company/avito/blog/571094/#outliers-in-data). Теперь я предлагаю посмотреть, как создать более мощные критерии, не изменяя выборку.

## Постанализ: CUPED

CUPED (Controlled-experiment Using Pre-Experiment Data) — очень популярный в последнее время метод уменьшения вариации. Основная идея метода такова: давайте вычтем что-то из теста и из контроля так, чтобы математическое ожидание разницы новых величин осталось таким же, как было, а дисперсия уменьшилась.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/157/093/bfc/157093bfcf98fbf75d6db6a14c10a97a.png)

A и B — некоторые случайные величины (ковариаты). Тогда утверждается, что если θ будет такой, как указано в формулах далее, то дисперсия будет минимально возможной для таких статистик:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/273/232/c99/273232c99f7d7171f77ca9c8855e53eb.png)

В случае выборок разного размера:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/ed4/7d9/26b/ed47d926b161a01fbc312da902f4d977.png)

Формула для дисперсии:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e0a/a81/8ed/e0aa818ed1258f7a63011b46b774c31b.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/62c/35b/e3b/62c35be3be98a9644cc294865af8b4e2.png)

То есть, чем больше корреляция по модулю, тем меньше будет дисперсия.

Также важно помнить: чтобы метод работал корректно, необходимо и достаточно, чтобы математические ожидания A и B совпадали.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e48/86c/9d6/e4886c9d6927e981521855d314a75c81.png)

Осталось понять, что брать в роли A и B. Чаще всего для них берут значения той же метрики на предэкспериментальном периоде. Например, вы смотрите метрику выручки, тогда в роли ковариаты A и B можно взять выручку от пользователя за месяц до начала эксперимента. Чем хорош такой способ:

1. Математическое ожидание метрики на предпериоде будет одним и тем же в тесте и в контроле — иначе у вас некорректно поставлен A/B-тест. А значит, и CUPED даст правильный результат.
    
2. В большинстве случаев метрика на предпериоде сильно коррелирует с экспериментальным периодом. Отсюда получается, что и дисперсия сильно уменьшится.
    

Кроме значения метрики на предпериоде можно использовать результаты ML-модели, обученной предсказывать истинные значения метрик без влияния тритмента. С хорошей моделью можно достичь большего уменьшения дисперсии.

Теперь, когда мы определились с новой метрикой, надо понять, какой критерий использовать. Можно точно также использовать T-test для CUPED-метрик. Вот результаты проверок на искусственных тестах: 

Проверка корректности метода на AB, AA тестах

```

```

> [](https://github.com/DimaLunin/AB_lifehacks/blob/main/CUPED.ipynb)

[](https://habr.com/ru/company/avito/blog/571094/)

Давайте ещё посмотрим, на сколько в искусственном примере уменьшилась ширина доверительного интервала по сравнению с обычным T-test:

```
# 2. Создание тестируемого критерия.def cuped_ttest(control, test, control_before, test_before):    theta = (np.cov(control, control_before)[0, 1] + np.cov(test, test_before)[0, 1]) /\                (np.var(control_before) + np.var(test_before))		control_cup = control - theta * control_before		test_cup = test - theta * test_before		return absolute_ttest(control_cup, test_cup)cuped_ci_lengths = []ttest_ci_lengths = []N = 30000for i in tqdm_notebook(range(N)):    # 4.a. Тестирую A/B-тест.    control_before = sps.expon(scale=1000).rvs(1000)    control = control_before + sps.norm(loc=0, scale=100).rvs(1000)    test_before = sps.expon(scale=1000).rvs(1000)    test = test_before + sps.norm(loc=0, scale=100).rvs(1000)    test *= 1.1    # 4.b. Запускаю критерий.    _, _, cuped_ci, _, _ = cuped_ttest(control, test, control_before, test_before)    _, _, ttest_ci, _, _ = absolute_ttest(control, test)    cuped_ci_lengths.append(cuped_ci)    ttest_ci_lengths.append(ttest_ci)    coeff = np.mean(cuped_ci_lengths) / np.mean(ttest_ci_lengths)print(f"Отношение ширины доверительных интервалов друг к другу: {round(coeff * 100, 3)}%")
```

Отношение ширины доверительных интервалов друг к другу: 11.015%.

Мы сократили доверительный интервал примерно в 10 раз! В этом примере мы очень сильно увеличили мощность критерия, перейдя от T-test к CUPED-критерию. А ещё, **CUPED состоит всего из четырёх строчек кода**!

Также, часто в некоторых статьях предлагают следующую метрику для CUPED:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/a78/538/d23/a78538d23e89d34bb7a1a106b94e6e2f.png)

Вместо ковариаты B, объявленной ранее, подставляется значение этой метрики на предпериоде, из которого вычтено среднее значение. Тогда математическое ожидание этой ковариаты будет нулевым, а математическое ожидание новых штрихованных метрик совпадает с математическим ожиданием начальных метрик:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/868/7ef/e90/8687efe900fbf230d9de1d09c130fca1.png)

Кроме того, в этот момент вы не теряете бизнес-смысл у вашей новой  CUPED-метрики, и можете посчитать оценки и доверительные интервалы для вашей метрики в тесте и в контроле.

Так вот, запомните: **никогда не используйте такую CUPED–метрику!** Покажу, к чему это может привести.

Пример

```

```

```

```

Получается, что метрика как портит CUPED-критерий, так и не даёт правильную оценку изначальной метрики.

> Доказательство и выводы из него

- [](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%BA%D0%BE%D0%BD_%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B8%D1%85_%D1%87%D0%B8%D1%81%D0%B5%D0%BB)
    

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/980/713/649/98071364921a4e35c0484f8da2171bdf.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/19c/1b7/7f9/19c1b77f9e1b055fafab7d7d4d8ea395.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/d56/a32/f64/d56a32f6411e31f41e62036c4ab5cdaa.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6e9/afb/428/6e9afb4288d33e493e91b6bf243ffd85.png)

### Относительный CUPED

Осталось показать, как настроить CUPED для относительной постановки A/B-тестов. И здесь всё будет не так гладко.

Предлагается посмотреть на следующую нетривиальную статистику:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/7d3/fbb/412/7d3fbb4125815f501c3f955381c45ee2.png)

Причём в числителе штрихованные CUPED — случайные величины без вычитания среднего у ковариаты, а в знаменателе — обычное среднее на контроле, без штрихов. Знаменатель такой, потому что CUPED-метрика не сохранит изначальное математическое ожидание. 

Утверждается, что при большом размере выборок эта статистика, как и относительный T-test критерий, будет верно оценивать и строить доверительный интервал для истинного прироста. Доказательство корректности  будет практически такое же, как и у T-test критерия из первой части. Дисперсия для такой функции также строится через дельта-метод, а формула практически полностью повторяет формулу для дисперсии в T-test.

Формула дисперсии:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/319/065/1c0/3190651c0946cca225a05d24fab8865d.png)

Формула дисперсии в случае выборок разного размера

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/9cc/a70/f4c/9cca70f4c02b911a254097c4a3776416.png)Код проверки корректности метода на A/B- и A/A-тестах

[](https://habr.com/ru/company/avito/blog/571094/)

```

```

Отлично! Мы смогли построить относительный критерий для CUPED, который корректно работает.

**Итого**: если вы ещё не используете CUPED для A/B-тестов, самое время это исправить. Пишется не сложнее, чем T-test, но при этом сильно улучшает мощность критериев.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/42b/818/7e7/42b8187e7f137a4aaff3879c9369d162.png)

Теперь предлагаю поговорить про бутстрап-аналог CUPED–метода.

## Постнормировка

Идея метода та же, что и в CUPED: использовать предэкспериментальный период. Ранее мы вычитали метрику, но ведь можно не только вычитать, но и делить:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/405/a40/213/405a40213720fa079a6a7cadd7490157.png)

Утверждается, что математическое ожидание этой случайной величины совпадает с мат. ожиданием изначальной разницы теста и контроля. В чём логический смысл такой статистики? Допустим, мы случайно поделили выборку на тест и контроль, но сделали это плохо. К примеру, среднее в тесте на предпериоде в 2 раза больше, чем среднее в контроле. Тогда очень вероятно, что и без всякого тритмента среднее в тесте и в контроле будут отличаться друг от друга примерно в 2 раза. Поэтому, давайте домножим контроль на 2 и сбалансируем значения в группах на экспериментальном периоде.

То есть логика метода такая: уменьшим влияние шума, возникшего при делении на тест и контроль.

Теоретическое обоснование корректности

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/62d/ba3/15c/62dba315c9f01cbb526273055c0a94a9.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e18/68b/0f5/e1868b0f5b21b71c07fb9eee0434bc64.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/3da/ad3/ecd/3daad3ecdd5ecef660a61cf69207ffe4.png)

В относительной постановке статистика будет такой — идея та же, что и в абсолютной постановке:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/361/581/1cd/3615811cddea2794b2e8b5247adbc356.png)

То есть мы смотрим, как раньше и сейчас тест относится к контролю. Если раньше тест был больше контроля в 2 раза, и сейчас мы получили такие же результаты, то наш тритмент никак не улучшил метрику.

Доказательство корректности

[](https://link.springer.com/article/10.1007/s00362-012-0429-2)

А теперь вопрос: как такое считать? Выписанная ранее формула дисперсии при делении двух случайных величин друг на друга уже внушает страх многим из нас, а тут у нас целых четыре отношения друг к другу! Здесь на помощь приходит один из лучших методов в статистике, который может помочь в любой непонятной ситуации, — **bootstrap**. 

Бутстрап — это статистический метод, который позволяет по одной выборке построить «приблизительно» доверительный интервал для любой [статистики](https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0_(%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F_%D0%B2%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B8)), зависящей от выборки целиком.

Чуть подробнее о методе

[](https://en.wikipedia.org/wiki/Bootstrapping_(statistics))

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/c7b/c8d/54a/c7bc8d54af0667a9ab59a822a2f7aced.png)

Благодаря тому, что бутстрап может построить доверительный интервал для любой статистики, статистический критерий практически не отличается в относительной и в абсолютных постановках. Единственное различие — это статистика, которую метод считает по выборке.

В случае абсолютной постановки A/B-теста:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1db/9fd/0d2/1db9fd0d2f28f33739872cf08abaefc9.png)

В относительной:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b01/c4d/c32/b01c4dc32c19f7cb8c9f706aba534833.png)

Если же реализовывать аналог T-test через бутстрап, то внутри критерия надо будет считать такие статистики:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/0ce/46f/273/0ce46f2739617c29fdfbac6fee246345.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/160/3ec/0c3/1603ec0c3873614dc00930ccab5298ac.png)

A/A- и A/B-проверка

```

```

> [](https://github.com/DimaLunin/AB_lifehacks/blob/main/bootstrap.ipynb)

```

```

Как я покажу далее, на реальных данных постнормировка работает не хуже, чем CUPED, но пишется проще: нет никаких страшных дисперсий и распределений.

**Итого:** главное, что надо запомнить о бустрап-критериях:

- Не хотите думать — используйте бутстрап! Вся теория зашита в самом методе, дисперсию выводить математически не надо. Если есть интересующая статистика, бутстрап сразу для неё построит доверительный интервал. От вас в коде критерия надо поменять одну формулу подсчёта статистики по выборке.
    
- Главный минус — такие критерии ну очень долгие. Конечно, есть хаки с распараллеливанием, [пуассоновским бутстрапом](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)) и т. п. Но они всё ещё не ускорят его настолько, чтобы он был быстрее T-test подобных критериев.
    

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/338/247/418/338247418ce4032941b28fd324ac4986.png)

## Улучшенное разделение пользователей на тест и контроль

Мы посмотрели, как можно увеличивать мощность A/B–тестов, улучшая мощность критерия. Но кроме этого можно подумать о том, как лучше поделить пользователей на тест и контроль, чтобы:

- тест и контроль были всё также сбалансированы;
    
- дисперсия разницы теста с контролем стала бы сама по себе меньше.
    

Поэтому поговорим о стратификации.

### Стратификация

Рассмотрим самый простой пример для визуализации: пусть у нас есть генеральная совокупность пользователей-покемонов:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/a8c/e97/da0/a8ce97da0f852529a26aa9ef6e67ea41.png)

Мы захотели провести на них A/B-тест. К примеру, раздать скидки на услуги Авито. При обычном A/B-тестировании мы случайно разбиваем всю выборку на тест и контроль, к примеру так:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/afa/4b9/1c9/afa4b91c9db6f1a5e3def6f4c5b8774b.png)

Дальше к этому мы применяем T-test, бутстрап, CUPED и т.д. и считаем результаты. Но вопрос: а что, если Пикачу (жёлтенькие) реагируют на тритмент не так, как Слоупоки (розовенькие)? Это вносит дополнительный шум в данные, так как в одной выборке три Пикачу, а в другой — один.

Поэтому давайте добавим вспомогательный шаг при делении выборки на тест и контроль. Сначала сгруппируем всех покемонов по виду, а потом будем сэмплировать из каждой группы (или страты) половину покемонов в тест, а другую — в контроль. Этот метод и называется стратификацией.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6d8/388/c1d/6d8388c1d2614d8dd9bd7fc001ba1f90.png)

[Утверждается](https://www.kdd.org/kdd2016/papers/files/adp0945-xieA.pdf), что дисперсия выборок при случайном делении и стратифицированном делении будет разной.

Формулы дисперсий

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/595/3d0/bda/5953d0bdadeecad86ee4a76848d349e8.png)

На практике же примеры признаков, по которым можно группировать пользователей на страты, — это:

- пол;
    
- возраст;
    
- страна/город проживания;
    
- компания или частное лицо;
    
- кластеризация с помощью машинного обучения;
    
- всё, что придет нам в голову.
    

Существует и некоторое усовершенствование такого метода: парная стратификация.

### Парная стратификация и переход к парному критерию

Для начала распишем по шагам предлагаемый метод:

1. Отсортируем всех пользователей на предэкспериментальном периоде.
    
2. Разобьём всех юзеров на группы — страты — из двух стоящих подряд человек.
    
3. Из каждой страты случайно одного пользователя отправим в контроль, а другого — в тест.
    

Иллюстрация метода:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b88/d08/1b0/b88d081b045ba32d9a85c866815163b9.png)

Как видно, идейно метод является продолжением идеи стратификации. Точно так же есть страты и точно так же половина группы уходит в контроль, а другая — в тест. Осталось лишь поменять критерий, держа в памяти, что дисперсия у стратифицированных выборок меньше, чем дисперсия при случайном разбиении. Но есть ещё беда: как я покажу далее, выборки теста и контроля станут зависимыми! Поэтому предлагается соединить две выборки T и C.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/8da/ebe/584/8daebe5842b0c4317cec591dbd15e89d.png)

Как их соединить? Давайте перейдём к новой случайной величине Z=T-C. Для неё мы будем считать среднее и строить доверительный интервал. Поэтому от обычных критериев перейдём к спаренным.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6a8/888/f07/6a8888f073d85820e9cf4d45bda25527.png)

Посмотрим на примерах, как в этом случае меняются критерии

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/10f/356/36e/10f35636e8ac89b15e29979b0f9d3a89.png)

[](https://habr.com/ru/company/avito/blog/571094/#t-test)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/b1e/be4/171/b1ebe41716ca4c03114dcb99ff63d9d4.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/4cd/3e7/177/4cd3e717742bac96fbdf1c7539a3a942.png)

> [](https://github.com/DimaLunin/AB_lifehacks/blob/main/paired_stratification%20.ipynb)

Теперь я предлагаю на примере посмотреть, как этот метод работает для T-test, а ещё на сравнение результатов спаренного и обычного критериев.

Сравнение спаренных и обычных критериев

```

```

В чём прелесть спаренных критериев: **они работают и в неспаренных случаях**, когда не была применена парная стратификация. Они просто дополнительно учитывают ковариацию между выборками, которой нет в случае обычных выборок. По идее, спаренные критерии могут добавить шума в доверительный интервал, но наши реальные и искусственные эксперименты показывают, что этого или не происходит, или шум незаметен в сравнении с шумом в самих выборках.

Поэтому, **используя парные критерии, вы** **не ухудшите результаты A/B-тестов**. Но в случае парной стратификации сможете улучшить их мощность.

Для тех, кто заинтересовался методом и не боится небольшого количества математики, предлагаю обсудить теорию, стоящую за ним.

Теория

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1df/d33/5a5/1dfd335a5f0378980748546db1085faa.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/db2/60d/0ea/db260d0eaad9dd521b4d618e1bc866cd.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/939/32a/267/93932a267a0733e7fb8a38a42689c1b8.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/f7f/b42/ff3/f7fb42ff3570fdc2db93dd36c0924110.png)

[](https://ru.wikipedia.org/wiki/%D0%9F%D0%BE%D1%80%D1%8F%D0%B4%D0%BA%D0%BE%D0%B2%D0%B0%D1%8F_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/c63/28a/264/c6328a2649aa6d25aa938ce9c9384e55.png)

[](https://en.wikipedia.org/wiki/Order_statistic)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/8c9/7f5/e00/8c97f5e00b2f1275f1b701553f4ecc07.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e58/4c4/320/e584c432077986f18175f754f3b76205.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/95b/a22/233/95ba222336a05c92fb88ae7035ced39e.png)

```

```

**Итого**: парная стратификация — достаточно интересный метод уменьшения вариации с помощью добавления зависимости между тестом и контролем. И на практике он часто бывает хорош.

## Сравнение всех методов

Время сравнить все рассмотренные ранее методы. До этого я доказывал корректность методов, но не показывал на практике, к чему приводят те или иные хаки. Пора это исправлять.

Для начала предлагаю определиться с метрикой, по которой стоит сравнивать критерии. Первая метрика, которая приходит в голову знакомым со статистикой, — это мощность. Так как я буду в A/B-симуляциях тестировать односторонние альтернативы, что среднее в тесте больше, чем в контроле, то и мощность нас интересует левосторонняя. То есть процент случаев, когда левая граница доверительного интервала больше 0. Но мощность не всегда показательна при различии двух методов. 

К примеру, если есть огромный эффект, то любой критерий отвергнет гипотезу о равенстве средних, но при этом один даст широкий доверительный интервал, а другой — узкий. В таком случае, конечно, лучше будет использовать критерий с узким доверительным интервалом. Кроме того, нам нужно удостовериться в корректности методов. Поэтому ещё нам нужен реальный уровень значимости. 

Итого, основные метрики, которые я буду использовать:

- Реальный уровень значимости или ошибка первого рода, которая должна быть 5%.
    
- Левосторонняя мощность.
    
- Ширина доверительного интервала.
    

Дополнительная метрика

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/1a4/5a5/8ba/1a45a58bac55ddf2ad8377a3526d6143.png)

Критерии, которые я буду сравнивать:

- T-test.
    
- Парный T-test.
    
- CUPED.
    
- Парный CUPED.
    
- Парный CUPED без юзеров, отвечавших за 5% выручки на предэкспериментальном периоде. Это интерпретация метода борьбы с выбросами из первой части статьи.
    
- Bootstrap.
    
- Парный bootstrap.
    
- Постнормировка.
    
- Парная постнормировка.
    

Все эти методы оценены на 1000 датасетов, собранных на наших реальных данных по методу, описанном в первой части. Метрика, которую я смотрел, — выручка. В итоге я провёл статистические тесты в относительной/абсолютной постановке, на A/A-, A/B-тестах, в случае парно стратифицированных и обычных выборок. Но ввиду бесполезности А/А-тестов (ведь есть A/B-тесты, а А/А нужны только для проверки корректности), продемонстрирую только A/B-тесты. 

Результаты получились такими:

**Относительная постановка.** Посмотрим на результаты на обычных, не стратифицированных выборках:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/009/fff/b9f/009fffb9f6b425298845721ba843bae8.png)

Цветовая легенда:

- Синий цвет в реальном уровне значимости — статистический критерий статистически значимо ошибается меньше, чем заявленные 5%.
    
- Зелёный цвет в реальном уровне значимости — процент ошибок у статистического критерия не статистически значимо отличается от 5%. А значит, критерий работает как заявлено.
    
- Жирный шрифт в метриках — наилучший результат.
    

Была применена парная стратификация к выборкам:

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/e65/509/ebb/e65509ebbe0ead91cb12f2fcd81f09f5.png)

Отсюда получились следующие результаты:

- В случае нестратифицированных выборок парные и непарные критерии работают одинаково. Так что вы всегда можете безболезненно перейти на спаренные критерии при выборках одинакового размера.
    
- CUPED по сравнению с T-test сокращает доверительный интервал **в полтора раза** (в случае нестратифицированных выборок) и увеличивает мощность на 13% (при небольшом эффекте). Если вы хотите начать получать больше статистически значимых результатов, то в первую очередь реализовывайте CUPED. Благо на SQL он также просто пишется. Не если вы по каким-то причинам не хотите его использовать, то можете реализовать постнормировку c примерно с такими же результатами.
    
- Парная стратификация позволяет сократить доверительный интервал для CUPED примерно **на 7%** и увеличить мощность на 5%. При этом критерии, которые не учитывают её, совершают меньше ошибок, чем 5%, заширяя доверительный интервал, что и следовало из теории.
    
- Если вы можете избавиться от топ-юзеров в A/B-тесте, не потеряв при этом репрезентативность, то качество для спаренного CUPED можно улучшить ещё **на 3.5%**.
    
- Если бы мы использовали обычный T-test, то ширина доверительного интервала была бы 0.14, а мощность всего 16.6%. Но после использования всех лайфхаков из статьи мы смогли сократить его **в 1.66 раза**, а мощность поднять **на 22%**. Хочется отметить, что метрика выручки у нас самая шумная, поэтому достичь для неё таких результатов — это успех.
    

**В абсолютной постановке** получились такие же результаты, поэтому их я не привожу.

## Итог

Я рассказал самое основное, что поможет сильно улучшить ваши текущие и будущие A/B-тесты. Перечислю ещё раз, что стоит запомнить из этой статьи:  

1. Бывает бесполезно держать эксперимент слишком долго. Вы просто зря теряете время. Кроме того, чем дольше вы держите один A/B-тест, тем меньше гипотез успеваете проверить за определённый срок.
    
2. Вы не используете CUPED? Пора это исправить.
    
3. Если у вас есть очень страшная статистика, математическое ожидание которой вы хотите оценить на A/B-тесте, то на помощь может прийти бутстрап.
    
4. Любой используемый статистический критерий можно улучшить, если вы заранее стратифицируете выборку. Или воспользуетесь алгоритмом парной стратификации, который дополнительно добавит зависимость между тестом и контролем.