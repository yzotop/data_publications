---
tags:
  - data
data_type:
  - AB tests
link: https://medium.com/statistics-experiments/%D0%B4%D0%B8%D1%81%D0%B1%D0%B0%D0%BB%D0%B0%D0%BD%D1%81-%D0%B2-a-b-%D1%82%D0%B5%D1%81%D1%82%D0%B0%D1%85-%D0%B5%D1%81%D1%82%D1%8C-%D0%BB%D0%B8-%D1%80%D0%B0%D0%B7%D0%BD%D0%B8%D1%86%D0%B0-%D0%BC%D0%B5%D0%B6%D0%B4%D1%83-99-1-%D0%B8-50-50-%D0%B2-%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%85-11c8f4fe7eb4
author: expf
source: medium
company: expf
---
Итак, по какой-то причине вы или ваша команда решили запустить A/B-тестирование с несбалансированными выборками (например, 65/35, 90/10 или 99/1). На первый взгляд, кажется что нет преград для запуска. Однако как и в любом эксперименте, приходится задаваться одними и теми же вопросами: когда останавливать эксперимент, когда можно верить результатам эксперимента, какой статистический критерий использовать? Могу ли я сравнивать тестовую ветку с контрольной при таком дизайне эксперимента? В этой статье мы рассмотрим нюансы, которые стоит учесть при планировании несбалансированных экспериментов

## Зачем запускать эксперименты с балансом 90/10, 95/5, 99/1… ?

Эксперименты с несбалансированными выборками полезны в первую меньшим риском для бизнеса, т.к. в случае провальной гипотезы потенциальная потеря денег будет, соответственно, меньше. Или в случае раннего этапа “обкатки” изменения, которое еще продолжительное время придется дебажить.

_Запустили тест на 1% трафика, конверсия упала на 15%, гипотеза не оправдала ожидания. Хотя локальная потеря — 15%, глобально же — просадка только 0,15%. Правда, реально ли мы наблюдаем просадку -15% или же это проявление случайности, необходимо еще доказать._

По большей части, у классических статистических критериев нет предположений, связанных с балансом выборок. К примеру, у t-Критерия Стьюдента [таких предположений нет](https://en.wikipedia.org/wiki/Student%27s_t-test), но есть требование к одинаковой дисперсии. Существует поправка Уэлша, которая позволяет сравнивать средние при разных дисперсиях, но и то в определенных случаях ([бóльшая дисперсия допускается только в бóльшей выборке](https://en.wikipedia.org/wiki/Welch%27s_t-test#Examples)). Отсюда следует, что сравнение несбалансированных выборок допустимо. Означает ли это, что мы можем применять стат. тесты на несбалансированных выборках и не переживать за точность?

## Причем здесь мощность?

Рано или поздно нам придется столкнуться с несбалансированными тестами, т.к. практика их применения достаточно распространена (в силу озвученных плюсов выше). Что нужно знать на этапе анализа? Прежде чем сказать, что различий нет, необходимо выяснить, способен ли статистический критерий их обнаружить. Если разница на самом деле есть, а критерий говорит об обратном, то положительные изменения для продукта так и не пойдут в продакшен. Такие случаи фиксирует ошибка II рода. Чем она выше, тем вероятней отсутствие разницы, когда по факту она есть. Обратная величина от ошибки II рода — мощность (вероятность увидеть разницу, когда она есть). И нам бы хотелось, чтобы условия для проведения эксперимента были наиболее предрасполагающие к высокой мощности.

К счастью, мы можем заранее подготовиться и посчитать мощность на несбалансированных выборках, применяя для этого симуляции _(см. ниже Проверка на данных)_. На всякий случай давайте вспомним что такое мощность (или true positive rate):

![](https://miro.medium.com/v2/resize:fit:590/1*95nGxw_5GjqqZ6uxoRvAkg.png)

чем выше мощность, тем вероятней отклонить нулевую гипотезу (например, о равенстве средних) при верной альтернативной (средние отличаются). Эти слова нам мало о чем говорят без примеров:

_Допустим мы провели эксперимент, где накопилось по 3500 пользователей на каждую ветку и теперь хотим сравнить кликабельность. CTR в контроле 10% и тесте 11%. При уровне значимости 95%, в относительном приросте 10% мы будем уверены только на 27,6% (если бы проводили такой эксперимент бесконечное количество раз). Т.е. в 72,4% таких же экспериментах эффект просто напросто не был бы увиден и мы зря выкинули бы результаты в мусорку._

_Для расчета мощности (R):_

p1 = 0.1  
p2 = 0.11  
n = 3500  
h = ES.h(p1,p2)  
pwr::pwr.2p2n.test(h = h, n1 = n, n2 = n, sig.level = 0.05)

Широкая практика придерживаться 80% мощности (или 1 из 5 ложноотрицательных случаев). Эмпирически же, каждая команда сама для себя определяет допустимый порог, который был бы приемлемым для продукта и бизнеса.

# Проверка на данных

## Метрика качества синтетических тестов

Теперь когда мы с вами знаем что такое мощность, давайте определим ее как метрику качества для изучения несбалансированных экспериментов.

_Представьте ситуацию: вы запустили эксперимент на 99/1, видите прирост на 1,2,3,4…X % в метрику и хотите катить в продакшен изменения (или видите падение метрики и остановить эксперимент). Внимательный читатель уже понял, что чтобы говорить об этих 1,2,3,4… % нужно быть уверенным в них. Хорошо бы иметь какое-нибудь мерило. Метрика качества подойдет для этой роли._

Для исследования будем использовать симуляции на базе синтетических тестов. Симуляции будут генерироваться на основе гиперпараметров (_см. ниже Параметры симуляций_). Далее в симуляциях будем считать метрику качества Power (TPR) по следующей формуле:

![](https://miro.medium.com/v2/resize:fit:205/1*_2yijbRjOR7sYw99Hbj2rw.png)

, где I — индикаторная функция, P — полученные p-value на каждой итерации симуляции, α — уровень альфа и N — все симуляции. В генераторе распределения мы явно указываем параметры среднего и дисперсии, где средние будут отличаться. Поэтому логично, что все отвергнутые нулевые гипотезы будут ознаменовать принятие истины о существовании разницы.

## Параметры симуляций

Для проверки несбалансированных экспериментов симулируем 4 кейса c весами 50/50, 75/25, 90/10, 99/1. За основу возьмем нормальное распределение со следующими параметрами:

- Размер выборки: 50,100,500,1000,2000,10000 _(важное замечание: баланс 99/1 для 50 и 100 корректировался под 95/5, т.к. у стат. оценщика есть требование к минимальному объему выборки)_
- Изменение % (или lift): 1,2,3,4,5,6,7,8,9,10,20,50,100 %
- Среднее (μ) = 1,2,5,10,20,50,100
- Стандартное отклонение (σ) = 1,2,5,10

На каждой комбинации генерировалось 1000 синтетических экспериментов. Мощность будем проверять при уровне значимости 95%. В качестве статистических оценщиков используются t-Критерий Стьюдента и u-Критерий Манна-Уитни. В общей сложности получилось 8 736 000 симуляций.

## Влияние баланса на мощность

На графике №1 каждый баланс отмечен своей цветной кривой. По горизонтали изменение в метрику (от 1 до 10), а по вертикали вероятность обнаружить это изменение.

![](https://miro.medium.com/v2/resize:fit:700/1*4vEoot61CpkXEmXmI7nasQ.png)

График 1: Зависимость мощности от изменчивости при разных балансовых весах. Для этого графика использовалась комбинация sd: 1, mu: 5, lift меньше либо равно 10 и N: 1000. Пунктиром отмечена отсечка в 80% мощности

Скорость у 99/1 существенно отличается от 50/50, а остальные кейсы демонстрируют прямую зависимость скорости роста мощности от баланса. Еще примечательно, что разница между 50/50 и 75/25 не такая большая. Не смотря на двукратный разрыв по объему выборки в тестовой группе (25% против 50%), просадка по мощности не кажется безнадежной. К тому же, по мере роста % изменения, разница в мощности между 50/50 и 75/25 становится все меньше и в конце концов метрика качества сравнивается. Отметим еще одну важную вещь: [чем больше % изменения, тем вероятней его обнаружение](https://files.eric.ed.gov/fulltext/ED493363.pdf).

Как таковой зависимости от параметров распределения нет — тренд сохраняется на всех градациях среднего и дисперсии. При большем объеме выборки мы получим бòльшую мощность, но это было понятно и без учета исследования поведения мощности при разном балансе. Мы это видим на графике №2 (в фасетах указан объем выборки):

![](https://miro.medium.com/v2/resize:fit:700/1*TE5_za6eb4NI8suwnODFVg.png)

График 2: каждый отдельный фасет представлен для разных объемов выборки (50,100,500…). Для этого графика использовалась комбинация sd: 1, mu: 5, lift меньше либо равно 10. Пунктиром отмечена отсечка в 80% мощности

Что интересно, на определенных эффектах (% изменения) рано или поздно, удастся получить минимально допустимую мощность. Следовательно, для сервисов с большой аудиторией нет как таковых проблем с балансом 99/1, если интересует предельно большой MDE (minimum detectable effect).

![](https://miro.medium.com/v2/resize:fit:700/1*yhZW66loWaC9OZhQ2qwFVg.png)

График 3: Мощность на 99/01. Для этого графика использовалась комбинация sd: 1, mu: 5, N:10000, lift меньше либо равно 20. Пунктиром отмечена отсечка в 80% мощности

Еще раз обратим внимание на важное наблюдение на графике 3: при достаточно большом объеме выборки (10000 наблюдений на обе ветки = 9000/1000), мощность для 6–20% изменения в метрику вполне приемлема, т.к. выше 80%.

## Дисбаланс и дисперсия

Нельзя не упомянуть поведение мощности при разных дисперсиях. Мы знаем, что чем сильнее зашумлена метрика, тем сложнее обнаружить ее изменение.

![](https://miro.medium.com/v2/resize:fit:700/1*EX3_PiKphE9n_t8mAahj6A.png)

График 4: Мощность на 99/01 при разных дисперсиях (ско). Для этого графика использовалась комбинация mu: 5, N: 10000, lift меньше либо равно 10. Пунктиром отмечена отсечка в 80% мощности

Хорошая ли затея использовать методики по сокращению дисперсии при балансе 99/01? С одной лишь оговоркой — выборки должны быть репрезентативны. Под репрезентативностью мы здесь имеем виду однородную (или гомогенную) аудиторию в обеих выборках: в контроле 50% мобильных пользователей — значит и в тесте их тоже должно быть 50%. Очевидно, что это важное условие для любого эксперимента. На 99/01 оно играет важную роль, если вдруг появится необходимость нивелировать дисперсию. Ведь какая польза от того, что мы сделаем метрику более чувствительной, если сравниваем теплое с мягким.

Кстати, если интересно почитать про сокращение дисперсии:

- [Ранговые трансформации](https://medium.com/statistics-experiments/%D1%83%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%B2%D0%B0%D0%B5%D0%BC-%D1%87%D1%83%D0%B2%D1%81%D1%82%D0%B2%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D1%8C-%D1%8D%D0%BA%D1%81%D0%BF%D0%B5%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D1%82%D0%BE%D0%B2-%D0%BF%D1%80%D0%B8-%D0%BF%D0%BE%D0%BC%D0%BE%D1%89%D0%B8-%D1%80%D0%B0%D0%BD%D0%B3%D0%BE%D0%B2%D0%BE%D0%B9-%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%84%D0%BE%D1%80%D0%BC%D0%B0%D1%86%D0%B8%D0%B8-32a4f72a86fc)
- [CUPED](https://medium.com/statistics-experiments/cuped-%D0%B8%D0%BB%D0%B8-%D1%83%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%87%D1%83%D0%B2%D1%81%D1%82%D0%B2%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D0%BE%D1%81%D1%82%D0%B8-%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%BA%D0%B8-de7183fc964c)

## Может есть более демократичный к дисбалансу критерий?

> Дисклеймер. У автора изначально не было цели сравнивать разные критерии в рамках этого исследования, т.к. появляется много дополнительных этапов проверки: разные критерии на разных распределениях с разными гиперпараметрами и т.п. и т.д. Поэтому мы останемся на тех же симуляциях, чтобы ответить на поставленный вопрос в подзаголовке.

Результаты на 10000 наблюдениях для Манна-Уитни на тех же данных показали примерно одинаковую мощность что и t-Критерий. Интересно, что на меньшем объеме выборки при больших эффектах мощность выше (см. график 5)

![](https://miro.medium.com/v2/resize:fit:700/1*6datd23P-HYATm7VAmoWRQ.png)

График 5: Сравнение критериев по мощности. В фасетах указан размер выборки (50,100…)

Означает ли это победу Манна-Уитни на 99/01? Однозначно об этом говорить можно было бы, изучив поведение критериев на разных типах распределения, а не только на нормальном. Тем не менее, по факту мы наблюдаем отрыв MW от t-теста в частных случаях.

# Выводы

Мощность критерия будет максимальной тогда, когда количество наблюдений в каждой из веток эксперимента наиболее близко друг к другу. Соответственно, это ведет к тому, что эксперименты стоит запускать с балансом 50/50 для наиболее вероятного обнаружения значимых изменений в эксперименте.

Тем не менее — реалии таковы, что статистика не учитывает стратегию запуска новых фич в сервисе, новых цен в тарифной сетке и любых других изменений, которые за собой могут повлечь экономические, брендинговые и другие риски. Подводя итог, **рекомендуется использовать такой баланс в эксперименте, который будет учитывать бизнес-интерес, согласно возможностям и емкости трафика, и, опираясь на ограничения в статистическом инструменте** (частично освещенные выше).

_Например, при DAU 100–500 пользователей можно забыть о балансе 99/01. При таком объеме даже изменчивость 10–25% разглядеть проблематично. С MAU 100–300 тыс. определенно имеет смысл задумываться о балансе 75/25 и ниже._

## Когда стоит придерживаться баланса 50/50?

- Когда риски не высоки и нет ограничений со стороны продукта / бизнеса
- Ожидаемый прирост или падение метрики достаточно маленькие (допустим, меньше 5%)

## Когда можно использовать несбалансированный тест?

- У вас достаточный объем трафика для обнаружения интересующих изменений в метрике (например, 20% и выше)
- За время эксперимента у вас есть возможность получить наиболее репрезентативные группы

Если все же вы не можете запустить 50/50 и ни одно из условий не получается придерживаться, то в качестве альтернативы выделяйте под эксперимент небольшую долю трафика (например, 5%) и внутри этой доли балансируйте ветки эксперимента на уровне 50/50 (получится 2,5% в каждую ветку). Придется подождать дольше обычного, но так вы получите наибольший уровень мощности