---
link: https://habr.com/ru/articles/653363/
tags:
  - data
data_type:
  - Analytics
source: habr
---
Приветствую тебя, дорогой друг! Эта публикация была создана для тебя, если ты хотел бы разобраться с этими непонятными словами из заголовка раз и навсегда. Как с идейной, так и с математической стороны. Признаюсь сразу, в свое время в универе частенько прогуливал семинары по высшей математике где-нибудь в приятном заведение со вкусной едой и хорошей музыкой или вообще дома, занимаясь чем-то "уникальным" и "сверхполезным". Но жизнь оказалась более ироничной, чем я думал. Сейчас я работаю продуктовым аналитиком в [@IDFinance](https://habr.com/users/idfinance) и познаю мат. статистику заново. И теперь уже с горящими глазами. Дается местами она не просто, а особенную трудность испытываю, когда хочу найти в интернете простые и понятные материалы по необходимой теме. Собственно, это меня и побудило написать данную статью, включающую в себя всю математику, почему она так работает и как это вообще запрограммировать.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/6c4/c3b/6a5/6c4c3b6a5758975e049ea46dadecd299.png)

### Начнем с примера

Заядлый рыбак Антон купил в магазине новую сверхтехнологичную наживку, так как друзья его убедили, что на данную снасть клюет более крупная рыба. Антон с нетерпением ожидал выходных, чтобы проверить его обновку в деле. И, естественно, в ближайшие даты он поехал на его любимый прудик, где клюет даже в самый нерыбный день. Всю дорогу наш рыбак вкушал как он будет вытаскивать трофейных сазанов и толстолобиков и с нетерпением ждал прибытия. По приезде Антон закинул две удочки. На первую он повесил старую, проверенную временем, наживку, а на вторую новую снасть. И теперь оставалось только ждать. Ждал Антон недолго, рыба клевала неприлично часто, только и успевай подсекать, взвешивать рыбу и отпускать обратно на волю. И вот, к концу выходных, сидя вечером около костра и поедая уху, Антон обратился к своему блокнотику, в который он записывал веса всех рыб. Там было отмечено около 300 взвешиваний по каждой из удочек. Но Антону до сих пор оставалось непонятно, какая же эффективнее. Он решил попросить помощи у своего друга математика. Предлагаю вам, вместе со мной, побыть на время этим самым другом математиком и помочь Антону ответить на его вопрос.

На обе удочки Антон поймал по 300 экземпляров рыб. В случае старой наживки средний вес рыбы был ![500 \pm 150](https://habrastorage.org/getpro/habr/upload_files/a63/e36/f8e/a63e36f8e8109c42d7a04aa40730cd88.svg)грамм, в случае новой наживки – ![530 \pm 150](https://habrastorage.org/getpro/habr/upload_files/521/21d/d7a/52121dd7ab9f680a6a8a33b26c1b7735.svg)грамм. Можно сказать, что мы получили нормальное распределение весов, с мат. ожиданием ![\mu = 500](https://habrastorage.org/getpro/habr/upload_files/46b/e1f/0a3/46be1f0a39b5c8353687fe36e14150e0.svg) и стандартным отклонением ![\sigma = 150.](https://habrastorage.org/getpro/habr/upload_files/9aa/3dd/b3c/9aa3ddb3cedd0c16364574e0c4e9edc6.svg)Мы можем говорить, что наше распределение является нормальным, так как распределения таких параметров как вес, рост, физическая сила, умственное развитие и т.д. являются нормальными.

Давайте попробуем сгенерировать теперь данные, которые нам передал Антон и посмотрим что получилось:

```
import numpy as npfish_rod_1 = np.random.normal(loc=500, scale=150, size=300)fish_rod_2 = np.random.normal(loc=530, scale=150, size=300)fish_rod_1[:10]
```

```
array([571.63344449, 496.64627972, 325.81534818, 474.13480467,       468.92529865, 471.77045815, 588.86876405, 493.60099443,       414.8360645 , 575.02554082])
```

Посмотрим какое распределение получится:

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/22a/d03/9b6/22ad039b6ac85906424bd11c1b4b3042.png)

Как мы видим, у нас действительно данные сосредоточены вокруг средних, и, на глаз, процентов 70 значений лежит в пределах![\pm 150](https://habrastorage.org/getpro/habr/upload_files/958/7a8/782/9587a878222e619aa2aef45e51a81b97.svg)граммов. Судя по всему новая наживка работает качественнее, чем старая, так как мы видим, что второй график смещен в правую сторону, относительно левого. Да и без графиков понятно, что среднее 530 больше, чем 500. Можем ли мы сделать вывод о том, что новая наживка лучше? Нет, нет и еще раз нет! Никто не отменял случайность. Возможно, нам так повезло, а в следующий раз будет наоборот. Так как же проверить правда это или нет, спросите вы? Давайте разбираться по порядку.

### Нормальное распределение

Нормальное распределение - это распределение, которое задается функцией Гаусса и является само по себе функцией плотности, оно симметрично и унимодально. А самое важное для нас, что отклонения значений от среднего мало того, что равновероятны, так еще и подчиняются известному вероятностному закону. Давайте посмотрим на это распределение и поймем наглядно что это все значит:

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/4d7/812/543/4d78125431b96b2ed0901ee9fbb5d008.png)

Разберемся с терминами:

- Распределение симметрично относительно своего центра ![(\mu).](https://habrastorage.org/getpro/habr/upload_files/1b1/cbb/84c/1b1cbb84cd24bb5be0e437579c7444bb.svg)
    
- Распределение унимодально. То есть имеет только одну моду (вершину). Собственно, вокруг этой вершины оно и симметрично.
    
- Распределение является функцией плотности. То есть вероятность попасть в интервал ![(a; b)](https://habrastorage.org/getpro/habr/upload_files/4d3/583/cc3/4d3583cc31561ce0d45bba00cc57638b.svg) равняется площади под кривой нормального распределения в интервале ![(a; b).](https://habrastorage.org/getpro/habr/upload_files/0aa/f4e/182/0aaf4e1821cd416ff8279231e019247d.svg) Важно, что вероятность попасть в интервал ![(-\infty; +\infty)](https://habrastorage.org/getpro/habr/upload_files/3cd/bc8/801/3cdbc8801e96e7a9a9641f4e430253ae.svg)равняется 100%, то есть площадь под кривой в данном интервале равняется единице.
    
- Распределение подчиняется вероятностному закону. Взглянув на распределение, мы можем сказать, что в промежутке![(-1\sigma; 1\sigma )](https://habrastorage.org/getpro/habr/upload_files/eff/852/74a/eff85274ae0a3eddd5d4890c8363dded.svg)находится приблизительно 34.1% + 34.1% = 68.2% наблюдений. Или, другими словами, вероятность случайным образом попасть в данный промежуток 68.2%. Или, с более формальной точки зрения, площадь под кривой нормального распределения в интервале![(-1\sigma; 1\sigma )](https://habrastorage.org/getpro/habr/upload_files/a02/e7e/5a4/a02e7e5a4e1bdf9ddc8fba15798ecd3e.svg) равняется 0.682.
    
- Распределение задается функцией Гаусса: ![f(x) = \frac{1}{\sigma \sqrt{2\pi}} exp(-\frac{(x-\mu)^2}{2\sigma^2})](https://habrastorage.org/getpro/habr/upload_files/eab/a32/e1a/eaba32e1a6bf64f9f9a31739a8f3824b.svg)
    

Давайте посмотрим на эту страшную функцию. Не пугайтесь, она нам больше никогда не понадобится. Мы тут видим два неизвестных для нас параметра: ![\mu](https://habrastorage.org/getpro/habr/upload_files/f3a/db6/de0/f3adb6de032820589b7aac3310a4d814.svg) и ![\sigma.](https://habrastorage.org/getpro/habr/upload_files/fb3/56e/65b/fb356e65b9b8b9dd609a17ca677dc6f6.svg)Эти параметры отвечают за сдвиг и масштаб нашей функции. Давайте прибегнем опять к графикам и поиграемся в них с данными значениями.

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/5b3/f6f/049/5b3f6f0499ad13a4473ebe4f6e456e81.png)

Все эти распределения являются нормальными. Различаются они лишь смещением центра относительно нуля и масштабом (некоторые из них шире, некоторые уже). Но, каждое из этих распределений, продолжает подчиняться вероятностному закону, о котором мы говорили выше. Так же, как мы расширили, сузили или сдвинули наше распределения от нормы![(\mu = 0](https://habrastorage.org/getpro/habr/upload_files/0d6/b43/c06/0d6b43c068ea17c4089826e67e2db2d5.svg) и ![\sigma = 1),](https://habrastorage.org/getpro/habr/upload_files/1dd/511/47d/1dd51147d876058c6a3eadf4eb2a2a93.svg)так и обратным образом мы можем привести любое нормальное распределение к стандартному виду благодаря z-оценке.

### Центральная предельная теорема

Центральная предельная теорема гласит, что сумма большого количества независимых случайных величин имеет распределение близкое к нормальному.

Давайте разбираться, у нас есть выборка размера ![n = 300](https://habrastorage.org/getpro/habr/upload_files/19f/166/080/19f1660807a097f02e3511facb6293df.svg) рыб, пойманных на первую удочку. Проведем эксперимент.

1. Будем многократно выбирать 300 рыб случайным образом. Так, чтобы одна и та же рыба могла попасть в новую выборку несколько раз.
    
2. После этого считаем средний вес рыбы (независимая случайная величина).
    
3. Повторяем пункт 1 и 2 много-много-много раз и записываем каждый раз значения средних.
    
4. Распределение средних должно стремиться к нормальному с увеличением количества повторений.
    

Давайте построим как это выглядит на практике:

```
sample = np.random.normal(loc=500, scale=150, size=300)print(sample.mean(), sample.std())fig, axes = plt.subplots(figsize = (7, 4))sns.histplot(data=sample, ax=axes)axes.set_title('Изначальная выборка (n = 300)', size=12)fig, axes = plt.subplots(nrows=2, ncols=2, figsize = (15, 8))avg = [[0, 0], [0, 0]]size = [[100, 1000], [10000, 100000]]for i in range(2):    for j in range(2):        avg[i][j] = [np.mean(random.choices(sample, k=300)) for i in range(size[i][j])]        sns.histplot(data=avg[i][j], ax=axes[i][j])        axes[i][j].set_title('Распределение {:d} выборочных средних'.format(size[i][j]), size=12)
```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/cba/337/7bf/cba3377bfbf6cacaf2bc39441060d5af.png)

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/414/796/435/41479643562aea17cd82fd858eab9852.png)

При 100 повторений график вообще не удался, по нему и не скажешь, что он куда-то стремится, тем более к нормальному распределению. А вот при 10.000 и 100.000 повторений графики очевидно похожи на то самое нормальное распределение.

Важно отметить, что чем больше ![n](https://habrastorage.org/getpro/habr/upload_files/741/3d2/082/7413d20827d254c06a4dcdb506926812.svg)(размер исходной выборки), тем ближе наше среднее к реальному среднему генеральной совокупности. То есть, чем больше рыб мы поймали, тем их средний вес ближе к реальному среднему весу всех рыб в данном пруду. Аналогично можно сказать и про стандартное отклонение. Поэтому, пока мы не знаем вес всех жителей пруда, мы не можем быть уверены, что в нашем улове среднее и стандартное отклонение совпадают с теми же значениями по всем рыбам пруда. Следовательно, нужно внести некую поправку, меру уверенности в наших данных. Эта мера уверенности есть. И она выглядит следующим образом.

![se=\frac{\sigma_x}{\sqrt{n}}](https://habrastorage.org/getpro/habr/upload_files/e60/321/676/e60321676bf72cbc337fd323a16d25a3.svg)

Среднеквадратичное отклонение равняется стандартному отклонению выборки, деленному на корень из числа элементов выборки.

#### Z-score

**Z-оценка** представляет собой преобразование данных в стандартную **Z-шкалу** со средним ![\mu_z = 0](https://habrastorage.org/getpro/habr/upload_files/9b3/2a0/d18/9b32a0d18d812a1b76ab827a8fe05837.svg) и ![\sigma_z = 1](https://habrastorage.org/getpro/habr/upload_files/a99/6ed/b14/a996edb14466f7c6d8a6439446ce57a8.svg) по следующей формуле:

![z_i =  \frac{x_i - \bar{x}}{\sigma_x}](https://habrastorage.org/getpro/habr/upload_files/804/d3d/ea2/804d3dea204fabb047341f41aa6cd6df.svg)

То есть, чтобы преобразовать наши данные в стандартную **Z-шкалу**, нам надо взять все веса рыб, отнять из них средний вес и поделить на cреднеквадратичное отклонение. Проделаем все это с данными по первой удочке:

```
mu_z = fish_rod_1.mean()se_z = fish_rod_1.std() / sqrt(n)z_fish_rod_1 = [(x - mu_z) / se_z for x in fish_rod_1]z_fish_rod_1[:5]
```

```
[0.07787472513608741, 1.003823047141974, 0.36522112368440396, 1.1425856197000772, -0.11237363891997496]
```

А так будут выглядеть график.

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/125/607/32b/12560732b64bad12f980f6156863885a.png)

Мы видим два абсолютно одинаковых графика с виду, но обратите внимание на ось абсцисс. Из-за того, что мы из ![x_i](https://habrastorage.org/getpro/habr/upload_files/0d0/a81/57a/0d0a8157acc8959dcbffeb02c0d75dd8.svg)вычли ![\bar{x},](https://habrastorage.org/getpro/habr/upload_files/16a/3b8/cc3/16a3b8cc3d08e8ab9ce04bf35ab31bd3.svg)правое распределение сместилось на ![\bar{x}](https://habrastorage.org/getpro/habr/upload_files/33c/16b/3c5/33c16b3c5bcd951cf0881f6a605b0430.svg)влево и среднее стало равняться нулю. А из-за того, что поделили на стандартное отклонение ![\sigma](https://habrastorage.org/getpro/habr/upload_files/30b/0cb/459/30b0cb459f5b06976366c206f98e88a8.svg), наше распределение сузилось. И теперь по оси абсцисс не единицы веса, а единицы стандартного отклонения. Таким образом любое нормальное распределение можно стандартизировать и привести к единому виду с ![\mu_z = 0](https://habrastorage.org/getpro/habr/upload_files/e9c/2be/7a7/e9c2be7a7b99aa054e7daf78c63d2105.svg) и ![\sigma_z = 1.](https://habrastorage.org/getpro/habr/upload_files/72d/fc0/ca0/72dfc0ca0cff80b4b124b08ee9c913aa.svg)И как следствие из этого, мы можем сравнивать средние двух признаков, если они нормально распределены, потому что их можно привести к единому виду благодаря **z-score**. Данные после преобразования будут исчисляться уже не в рыбках, котиках и морковках, а в стандартных отклонениях от среднего.

### Вернемся к нашим рыбам

Вспомним про наш вероятностный закон, которому подчиняется любое нормальное распределение. Мы можем сказать, что, к примеру, между ![(-1\sigma; 1\sigma )](https://habrastorage.org/getpro/habr/upload_files/41c/d6c/3a6/41cd6c3a62e912076126f0bd0d9cd630.svg) у нас находится 68.2% наблюдений. То есть рыб. То есть из 300 рыб, у нас скорее всего 205 с весом ![500 \pm 150](https://habrastorage.org/getpro/habr/upload_files/0bc/33a/c21/0bc33ac21b8ea360f729370f4a270adc.svg)грамм. А в диапазоне ![(-2\sigma; 2\sigma )](https://habrastorage.org/getpro/habr/upload_files/6ae/199/abd/6ae199abd09595d88372024ea3110c77.svg)у нас 95.4% всех рыб. То есть 95.4% всех рыб находится в весовом диапазоне ![500 \pm 300](https://habrastorage.org/getpro/habr/upload_files/9a0/f24/d64/9a0f24d64ba84b91bc3ac119cf89b668.svg)грамм.

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/c46/d88/201/c46d882019ee9abf3624393255d990bf.png)

### Генеральная совокупность и одна рыба.

Забудем пока про вторую удочку и представим, что Антон рыбачил только на одну. То есть мы можем для удобства сделать допущение, что параметры ![(\mu = 500](https://habrastorage.org/getpro/habr/upload_files/eb3/250/a07/eb3250a07fa3c1e7eaf35735cb597e3c.svg) и ![\sigma = 150)](https://habrastorage.org/getpro/habr/upload_files/5c7/e46/0ba/5c7e460ba4de2359807122e094359421.svg) являются описанием генеральной совокупности. Запомните это. Поэтому нам не требуется делить наше стандартное отклонение на ![\sqrt{n}.](https://habrastorage.org/getpro/habr/upload_files/1c4/243/813/1c4243813903d00245274381a981dbe9.svg) Теперь вопрос, с какой вероятностью Антон поймает рыбу, которая будет тяжелее, чем 530 грамм? Чтобы узнать ответ, опять воспользуемся формулой **z-score**.

![z = \frac{x - \mu}{\sigma}](https://habrastorage.org/getpro/habr/upload_files/a84/df5/ee1/a84df5ee197955029aefba411b6d4af0.svg)

Подставим в формулу наши значения: ![z = \frac{530 - 500}{150} = 0.2.](https://habrastorage.org/getpro/habr/upload_files/5a5/573/d44/5a5573d44b4b0b98c698fc62f6b7f860.svg)Что мы сейчас получили? Мы посчитали, что значение 530 грамм отклоняется от среднего значения генеральной совокупности (500 грамм) на 0,2 стандартных отклонения. Да, как я уже и писал, мы теперь меряем все не в рыбках и граммах, а в стандартных отклонениях.

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/4d6/3c9/004/4d63c900484bdc29400b242ce93cd884.png)

Зная отклонение от среднего генеральной совокупности (**z-score**), мы можем посчитать вероятность поймать рыбу тяжелее 530 грамм. Для этого воспользуемся подходящим инструментом в python, в который уже вшита функция плотности. Он за нас рассчитает площадь под кривой, правее ![0.2\sigma](https://habrastorage.org/getpro/habr/upload_files/5aa/6d7/697/5aa6d769767e14bec100ad0178881ea4.svg) (то, что закрашено синим на графике). Это и будет значением необходимой нам вероятности.

```
# Стандартизированное нормальное распределениеnorm_rv = stats.norm(loc=0, scale=1)print(1 - norm_rv.cdf(0.2))# Или обычное нормальное распределение, как в нашем случаеnorm_rv = stats.norm(loc=500, scale=150)print(1 - norm_rv.cdf(530))
```

Обе функции вернут одинаковый ответ: ![p = 0.42074.](https://habrastorage.org/getpro/habr/upload_files/a84/fb3/082/a84fb3082b061a274260217c3c538413.svg)Это и есть **p-value**, вероятность случайным образом вытащить одну рыбу с весом более 530 грамм. Разница в них только в том, что в первом случае нормальное распределение стандартизировано, а во втором мы работаем с параметрами генеральной совокупности.

### Генеральная совокупность и несколько рыб

С одной рыбой разобрались. А какова вероятность поймать 4, 100 и даже 300 рыб со средним весом 530 грамм? Воспользуемся формулой z-score, но немного ее модернизируем. Как раз сейчас нам и понадобится та самая поправка из центральной предельной теоремы.

![z = \frac{\bar{x}- \mu}{\frac{\sigma}{\sqrt{n}}}](https://habrastorage.org/getpro/habr/upload_files/de4/316/189/de431618973c4018bb3980a9d6549616.svg)

Где, ![\bar{x}](https://habrastorage.org/getpro/habr/upload_files/afd/589/b62/afd589b623a46ba2133b3b02b9c18738.svg) - среднее значение в выборке,![\mu](https://habrastorage.org/getpro/habr/upload_files/e8a/a36/c99/e8aa36c99ca3a2eba92eec3cad0a2272.svg)- среднее генеральной совокупности, ![\sigma](https://habrastorage.org/getpro/habr/upload_files/2d6/0da/f0c/2d60daf0cb2e15ad2ab74c1c007a405e.svg)- стандартное отклонение в генеральной совокупности, ![n](https://habrastorage.org/getpro/habr/upload_files/de9/d76/94c/de9d7694cb0136ee911ccf809b8c2345.svg)- кол-во элементов в выборке. Здесь мы вносим поправку в наше стандартное отклонение, так как работаем уже с несколькими элементами.

Практический смысл данной формулы говорит о том, что мы ввели две гипотезы, которые будут конкурировать между собой:

- ![H_0:](https://habrastorage.org/getpro/habr/upload_files/d93/bc4/e3f/d93bc4e3fe1cfde7bb890faa7c8fe8a2.svg)Нулевая гипотеза говорит о том, что выборка на самом деле принадлежит генеральной совокупности и средние значения выборки и генеральной совокупности равны ![(\bar{x} = \mu).](https://habrastorage.org/getpro/habr/upload_files/35c/aed/bab/35caedbab2ab66c48f66fd118bf7bdec.svg)
    
- ![H_1:](https://habrastorage.org/getpro/habr/upload_files/837/cfe/c59/837cfec59ffe823b7d7466b2f9013fbb.svg)Альтернативная гипотеза говорит об обратном. Выборка не является частным случаем текущей генеральной совокупности и средние, на самом деле, отличаются ![(\bar{x} \neq \mu).](https://habrastorage.org/getpro/habr/upload_files/69d/1c1/518/69d1c1518ccc24a28b05626721968585.svg)
    

Чтобы подтвердить или опровергнуть ![H_0](https://habrastorage.org/getpro/habr/upload_files/0de/937/638/0de93763864dbd5b470ade052a8e661c.svg) мы и считаем z-score и p-value. То есть мы считаем вероятность того, что ![\bar{x}](https://habrastorage.org/getpro/habr/upload_files/50d/8cd/110/50d8cd110192148414123fcb4362a511.svg) отличается от ![\mu](https://habrastorage.org/getpro/habr/upload_files/e9a/abb/61a/e9aabb61a7e16688215546747ee8c465.svg) на ![z](https://habrastorage.org/getpro/habr/upload_files/1c2/3b9/651/1c23b965186558538ca67f38af85e687.svg) стандартных отклонений. И если эта вероятность нас устраивает, то мы принимаем нулевую гипотезу, а если нет - отвергаем. Теперь давайте подставим в формулу значения:

![z = \frac{530 - 500}{\frac{150}{\sqrt{4}}} = \frac{30}{75} = 0.4](https://habrastorage.org/getpro/habr/upload_files/b58/79e/b57/b5879eb578858e37e62a6e649d23d34e.svg)

Теперь мы знаем, что среднее по выборке ![\bar{x}](https://habrastorage.org/getpro/habr/upload_files/2c6/c2f/1be/2c6c2f1be0c55bdd0062ba5937a7c8df.svg) отклоняется от среднего генеральной совокупности ![\mu](https://habrastorage.org/getpro/habr/upload_files/4ba/2aa/637/4ba2aa637cbb33a10e665b0d059b9de4.svg) на ![0.4\sigma.](https://habrastorage.org/getpro/habr/upload_files/0a0/483/2d5/0a04832d5ba584fd32ced503937e9c05.svg)Давайте теперь посчитаем вероятность такого отклонения.

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/be1/5c9/8e4/be15c98e407b27a3a8219c22a2dc57bf.png)

Вероятность поймать 4 рыбы со средним весом 530 грамм мы можем рассчитать все тем же способом, как и для единичного случая. **P-value** у нас получится равным 0.3446.

```
norm_rv = stats.norm(loc=0, scale=1)print(1 - norm_rv.cdf(0.4))
```

Как вы уже поняли, чем больше мы хотим поймать рыб со средним весом 530 грамм, тем больше у нас **z-score** и тем меньше **p-value**. Давайте посмотрим как это выглядит на практике:

Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/40e/11b/be3/40e11bbe304f92d513d9b23024047847.png)

То есть вероятность поймать 100 рыб со средним весом 530 грамм равняется 2.28%, а вероятность поймать 300 рыб равняется 0.03%, что ничтожно мало. И мы можем сделать вывод, что вторая удочка, с новой наживкой отработала лучше. Так как только в 0,03% случаев мы могли ошибиться.

Но помните, что мы сделали допущение, что данные с первой удочки - это генеральная совокупность. А по факту это выборка из генеральной совокупности. Будет ли теперь наш вывод статистически правильным? Нет, мы не учли этот момент. Давайте теперь все учтем и наконец-таки сделаем финальный вывод с точными цифрами!

### Две выборки со множеством рыб

Теперь у нас не генеральная совокупность и выборка, а две выборки из нескольких сотен рыб. То есть, если бы Антон продолжил бы ловить рыбу еще несколько дней, то средние значения и стандартные отклонения могли бы измениться.

Важно, что **z-критерий** требует знания стандартных отклонений. Поэтому давайте зафиксируемся на том, что мы поймали достаточно много рыб, чтобы утверждать, что ![\sigma_1](https://habrastorage.org/getpro/habr/upload_files/7f8/f8f/7bb/7f8f8f7bbb6c2de8fb5eb3b7cef0e835.svg) и ![\sigma_2](https://habrastorage.org/getpro/habr/upload_files/0c0/a40/d9e/0c0a40d9e997753b03757bf5455f5372.svg) являются такими же, как и в генеральной совокупности (во всем пруду). Иначе нам нужно будет воспользоваться t-критерием Стьюдента.

|   |   |   |   |
|---|---|---|---|
||![n](https://habrastorage.org/getpro/habr/upload_files/f9e/69f/107/f9e69f10708921a8ea26964516abd87d.svg)|![\mu](https://habrastorage.org/getpro/habr/upload_files/240/23a/a0b/24023aa0beff9877d2924ca841436391.svg)|![\sigma](https://habrastorage.org/getpro/habr/upload_files/bf6/a2f/ee1/bf6a2fee1854b2a62bfea913939099df.svg)|
|Старая наживка|300|500|150|
|Новая наживка|300|530|150|

Как мы помним из ЦПТ, нам нужно ввести поправку. И у нас теперь две выборки и поправку необходимо будет учесть два раза.

![z = \frac{\mu_2 - \mu_1}{\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}}](https://habrastorage.org/getpro/habr/upload_files/ea2/b2f/f44/ea2b2ff443d7d2d6b983d180b737dc6f.svg)

Практический смысл данной формулы все тот же. Мы принимаем нулевую гипотезу о равенстве средних ![H_0: \mu_1 = \mu_2](https://habrastorage.org/getpro/habr/upload_files/67f/bac/8b2/67fbac8b2f3aea70cf594e80ee17cc78.svg) при условие высокой вероятности (**p-value**) данного события, в ином случае отвергаем.

Давайте теперь подставим наши значения и рассчитаем **z-score**.

![z = \frac{530 - 500}{\sqrt{\frac{150^2}{300} + \frac{150^2}{300}}} = \frac{30}{\sqrt{150}} \approx 2.45](https://habrastorage.org/getpro/habr/upload_files/251/ea0/69e/251ea069ed4096fe23f353f73b3fb246.svg)Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/29e/edb/0af/29eedb0af44ae93cca0ed861ea396700.png)

Как мы видим, вероятность того, что средние равны - 0.72%. Следовательно, мы можем с уверенностью в 99.3% отвергнуть нулевую гипотезу и сделать вывод, что новая наживка все же лучше, чем старая.

### Когда можно использовать z-критерий?

Естественно, эти формулы можно использовать далеко не всегда. Иногда может потребоваться t-критерий Стьюдента, а иногда даже им не обойтись. Важно помнить, что для успешной реализации этого критерий необходимо соблюсти несколько условий:

1. Распределение должно быть нормальным.
2. Известна дисперсия генеральной совокупности для всех выборок.
3. Выборка имеет размерность более 30 элементов.
    
Если 2 и 3 условия не удовлетворяют требованиям, то лучше использовать t-критерием Стьюдента.

### P-value

Давайте дополнительно чуть подробнее разберемся как определять **p-value**. Мы рассмотрели только один вариант, когда мы заранее знаем, что ![\mu_2](https://habrastorage.org/getpro/habr/upload_files/edf/bc7/f60/edfbc7f6082da6b674ffa961379a1635.svg) точно больше, чем ![\mu_1.](https://habrastorage.org/getpro/habr/upload_files/f7e/5ce/f21/f7e5cef214956ddf5ac2991632cbc04c.svg) А если наоборот? Или вообще нет информации о том, как средние расположены относительно друг друга? Именно для таких случаев существует несколько видов гипотез.

- Левосторонняя гипотеза.
- Двусторонняя гипотеза.
- Правосторонняя гипотеза.
    
Код python

```

```

![](https://habrastorage.org/r/w1560/getpro/habr/upload_files/afe/e93/8d4/afee938d4f471d89172a9c44f9cc4c0d.png)

Отличия в них идеологические. Если мы заранее не знаем улучшится в тесте результат или ухудшится (не знаем знак **z-score**), то необходимо применять двустороннюю гипотезу и умножать полученный **p-value** на 2. А если мы тестируем улучшение или ухудшение, то тут достаточно односторонней гипотезы. Правда, уже после получения результатов теста, нельзя менять знак, который выбрали заранее.

Надеюсь, вам было все понятно, а читать было интересно. Буду безумно признателен, если поддержите мою первую публикацию лайком или комментарием.