---
tags:
  - data
data_type:
  - DS
---
## анализ

Чтобы понять и проверить эти расчёты, давайте разберём их шаг за шагом, рассмотрим сделанные допущения и выясним, как вы можете самостоятельно воспроизвести и проверить результаты.

**1. Количество активированных параметров в модели**

- **Предположение**: GPT-4o имеет 100 миллиардов активированных параметров.
- **Обоснование**: Это основано на слухах и сравнении с другими моделями, такими как LLama 3.1 7b и 70b, а также на данных о пропускной способности (throughput) в токенах в секунду.
- **Проверка**: Поскольку точное количество параметров в GPT-4o не является публично доступной информацией, это допущение может быть скорректировано. Вы можете изменить эту цифру в Colab-ноутбуке и посмотреть, как это повлияет на расчёты.

**2. Амортизированная стоимость сервера с 8 H100**

- **Предположение**: Стоимость такого сервера на AWS составляет $39.33 в час.
- **Обоснование**: Это верхняя оценка, так как реальные цены на рынке могут быть в несколько раз ниже.
- **Проверка**: Вы можете проверить актуальные цены на AWS или других облачных сервисах. Также можно учесть стоимость сервера при покупке и распределить её на срок эксплуатации для более точной амортизации.

**3. MFU (Model FLOPS Utilization)**

- **Предположение**: Эффективность использования вычислительных ресурсов составляет 30%.
- **Обоснование**: Это стандартное значение для таких моделей.
- **Проверка**: Вы можете исследовать технические документы или статьи, чтобы узнать типичные значения MFU для больших языковых моделей, и скорректировать этот параметр.

**Расчёт стоимости инференса на миллион токенов**

- **Шаг 1**: Рассчитывается общее количество операций с плавающей точкой (FLOPs), необходимых для генерации одного токена.
- **Шаг 2**: Учитывается MFU для определения реальной производительности.
- **Шаг 3**: На основе стоимости сервера и производительности вычисляется стоимость генерации одного миллиона токенов.

**Сравнение с ценами API**

- **Фактическая стоимость инференса**: По расчётам получается ~$0.23 за миллион токенов.
- **Официальные цены OpenAI**: $2.5 за миллион входных токенов и $10 за миллион выходных токенов.
- **Наценка**: API имеет наценку примерно в 50 раз по сравнению с оценочной себестоимостью инференса.

**Сравнение с человеческим трудом**

- **Зарплата**: Минимальная зарплата в Нью-Йорке – $16 в час.
- **Производительность**: Человек пишет примерно 100 токенов в минуту.
- **Стоимость**: Генерация миллиона токенов человеком обойдётся в ~$2666.67.
- **Вывод**: Даже при высоких ценах API, использование модели значительно дешевле человеческого труда.

**Как проверить эти расчёты**

1. **Используйте предоставленный Colab-ноутбук**:
   - Откройте ноутбук по ссылке.
   - Просмотрите код и формулы.
   - Измените входные параметры (количество параметров, стоимость сервера, MFU) и наблюдайте за изменением результатов.

2. **Проверьте формулы и расчёты вручную**:
   - Убедитесь, что понимаете каждую формулу.
   - Пересчитайте значения с вашими данными.
   - Проверьте единицы измерения на каждом этапе.

3. **Сопоставьте с другими источниками**:
   - Найдите статьи или исследования по стоимости инференса больших языковых моделей.
   - Сравните их данные с вашими расчётами.

4. **Учтите дополнительные факторы**:
   - Накладные расходы (электричество, охлаждение, обслуживание).
   - Оптимизации в архитектуре модели, которые могут влиять на эффективность.
   - Возможные скидки или специальные условия при масштабном использовании облачных сервисов.

**Заключение**

Понимая каждое допущение и шаг в расчётах, вы сможете самостоятельно проверить их точность и обоснованность. Используя Colab-ноутбук, вы можете экспериментировать с разными значениями и видеть непосредственное влияние на итоговую стоимость. Это поможет вам лучше понять экономические аспекты использования больших языковых моделей и их сравнение с человеческим трудом.

## про инференс

В данном контексте **инференс** (от английского *inference*) означает процесс использования уже обученной нейронной модели для генерации ответов или предсказаний на основе входных данных. Это противопоставляется этапу **обучения**, где модель учится на большом объёме данных.

Для больших языковых моделей, таких как GPT-4o, инференс включает:

- **Обработку входных данных**: Модель принимает текстовый запрос или последовательность токенов от пользователя.
- **Генерацию ответа**: На основе своего внутреннего состояния и обученных весов, модель прогнозирует следующий токен или последовательность токенов, формируя осмысленный ответ.
- **Вычислительные ресурсы**: Процесс инференса требует значительных вычислительных мощностей, особенно для моделей с большим количеством параметров.

В обсуждаемом материале инференс относится к:

- **Стоимость процесса**: Оценка затрат на вычислительные ресурсы, необходимые для генерации ответов модели.
- **Эффективность использования оборудования**: Анализ того, насколько эффективно используются графические процессоры (GPU) и другие аппаратные ресурсы во время инференса.
- **Сравнение с человеческим трудом**: Сопоставление стоимости инференса модели с затратами на выполнение аналогичной работы человеком.

Таким образом, инференс в этом контексте — это практическое применение модели для решения задач, включая все связанные с этим вычислительные и финансовые аспекты.


## пост

Почему-то многие думают, что провайдеры больших языковых моделей продают API чуть ли не себе в убыток. Я бы хотел поделиться прикидками о том, почему это совсем не так, и заодно помечтать о том, сколько параметров мы можем себе позволить тратить на модель, которая сможет заменить человека в работе.

Все расчёты можно воспроизвести в колабе (https://colab.research.google.com/drive/1db2pnSLO6UWAYdOtmtQfRpwi-jD5CCGE?usp=sharing), меняя цифры, как вам захочется. Выводы остаются неизменны.

Для расчётов нам нужно сделать несколько допущений:
1. Количество активированных параметров в модели. Для GPT 4 Turbo широко ходили слухи про 200 миллиардов параметров, так что 4o должна быть меньше. По данным Artificial Analysis (https://artificialanalysis.ai/models), пропускная способность GPT-4o – 95 tok/s, что находится между LLama 3.1 7b (182 tok/s) и 70b (80 tok/s). Для наших целей предположим, что в 4o 100 миллиардов активированных параметров, делая скидку на то, что в OpenAI инференсом занимаются крайне толковые люди. Кстати, Gemini Flash 1.5 с последним обновлением выдаёт (https://artificialanalysis.ai/models/gemini-1-5-flash) 330 tok/s.
2. Амортизированная стоимость сервера с 8 H100. Чтобы не сильно расстраиваться, возьмём оценку сверху как цену такого сервера на AWS (https://aws.amazon.com/ec2/capacityblocks/pricing/) – на сегодняшний день $39.33 в час. На рынке цены могут быть минимум в пять раз меньше.
3. MFU – какой процент вычислений используется эффективно. Стандартом является 30-50%, для наших прикидок возьмём 30%.

При таких допущениях (а с другими вы можете поиграть в колабе), стоимость инференса миллиона токенов получается $0.23. Сравним это с официальной ценой в $2.5 за input и $10 за output и получим наценку API в ~50 раз. И это – оценка сверху со всеми допущениями в сторону удорожания. С другой стороны, кому-то же надо скидываться Саме на Koenigsegg (https://qz.com/sam-altman-spotted-driving-multi-million-dollar-koenigs-1851592678). 😮‍💨

Заодно мы можем посчитать, насколько дешевле модели в сравнении с кожаными мешками. Взяв минимальную зарплату в Нью-Йорке ($16) и производительность в 100 токенов в минуту (среднее у людей примерно 50 слов (https://www.asaporg.com/efficiency-skills/average-words-per-minute-typing-how-fast-is-fast-enough) в минуту), получим стоимость миллиона токенов в $2666.67. Даже o1 со своими $60 / Mtok тут рядом не стоит. Есть, куда расти!