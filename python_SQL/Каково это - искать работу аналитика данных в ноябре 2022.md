---
tags:
  - data
link: https://vc.ru/u/1356291-dmitri-ilin/558613-kakovo-eto-iskat-rabotu-analitika-dannyh-v-noyabre-2022
source: VC
---
Так получилось, что в начале ноября 2022 мы с [SegmentStream](https://segmentstream.com/) решили прекратить наше сотрудничество. Нельзя сказать, что это было нечто неожиданное для меня или для работодателя. Наоборот, понимание того, что в наших отношениях наступил кризис, пришло еще летом. Однако с обеих сторон были предприняты определенные шаги (как оказалось, не очень успешные 😌) для исправления ситуации. Тем не менее, еще с начала осени я стал лениво следить за появлением новых вакансий на HH и с бОльшим интересом отвечать на сообщения рекрутеров в LinkedInn.

Вероятно, виной всему была боязнь провала с моей стороны и/или увеличившееся количество предложений на рынке в связи с известными осенними событиями в стране, но к плановой дате расторжения договора у меня не оказалось оффера на руках. Однако благодаря достигнутым договоренностям с работодателем я мог спокойной посвятить следующие два месяца поискам работы, исключив необходимость пристально следить за балансом своего банкового счета. SegmentStream 🙏

## 

Подготовка

**Первым делом** еще до официальной даты “ухода” я подготовил примеры кода и графиков, наглядным образом демонстрирующие, что именно и как я делал в SegmentStream. По сути, это был Jupyter notebook с расширенным описанием маркетингового эксперимента в Яндекс.Директ. Ноутбук содержал все шаги от описание дизайна эксперимента до подведения итогов с демонстрацией разницы распределения метрики в группах. Плюс, подготовил ответы на самые частые вопросы рекрутеров на русском и английском языках.

![](https://leonardo.osnova.io/2756246c-63ca-5722-9f03-1bffa733a993/-/preview/1100/-/format/webp/)

Пример кода

**Второе** - я составил список вакансий, на которые хотел откликнуться. При этом, список был в порядке убывания значимости для меня. Строго говоря, я наметил одну цель и решил готовиться к собеседованиям по ней, а остальные выбрал в качестве запасного варианта и дополнительной практики прохождения интервью.

**Третье** - исходя из требований по списку, упомянутого выше, я составил перечень областей, где мне однозначно требовалось освежить/получить знания (например, оконные функции в Clickhouse, уверенная трактовка статистических методов при проверке гипотез, использование dbt).

**Наконец**, после составления списка из п.3 я отобрал материалы, которые, на мой взгляд, помогли бы мне лучше подготовиться к техническим интервью.

Вот то, что я использовал для подготовки

**SQL**

[https://habr.com/ru/post/461567/](https://habr.com/ru/post/461567/)

[https://habr.com/ru/post/181033/](https://habr.com/ru/post/181033/)

[https://habr.com/ru/company/otus/blog/541882/](https://habr.com/ru/company/otus/blog/541882/)

По сути, достаточно корректно воспользоваться поиском (например, _site:habr.com sql задачи_) чтобы найти интересные (и не очень) задачи, которые используют интервьюеры. Кроме этого, имело смысл, как минимум, найти эквиваленты знакомых мне по BigQuery функций в Clickhouse, так как во многих описаниях к вакансиям были упоминания использования именно CH диалекта.

[https://clickhouse.com/docs/ru/sql-reference/window-functions/](https://clickhouse.com/docs/ru/sql-reference/window-functions/)

**Python**

[https://www.w3resource.com/python-exercises/python-basic-exercises.php](https://www.w3resource.com/python-exercises/python-basic-exercises.php)

Прямо обе части. Да, задач много, но они легко решаются. Тут, скорее, дело в вашей усидчивости и нацеленности на результат. Я решил заниматься до 3х часов в день с небольшими перерывами. Сразу напишу, что усилия надо было приложить к некоторым другим типам упражнений на Питоне. Об этом ниже. Однако эти задачи мне кажутся отличным выбором в качестве разминки.

Плюс, вот здесь хороший список задач - [https://realpython.com/quizzes/](https://realpython.com/quizzes/)

Ниже будут дополнительные ссылки на Python-задачи.

**Мат.стат и эксперименты**

Года два назад я прошел [замечательный курс по АБ-тестированию](https://expf.ru/ab_course) от ExpFest. У меня сохранились все материалы, включая pdf презентации, так что ничего искать не пришлось. Кстати, Искандер и Виталий с тех пор сделали курс еще лучше. Настоятельно рекомендую курс не только тем, кто “плавает” в базовых вещах по статистике и мат. анализу, но и тем, кто хочет прокачать уровень.

Здесь, на всякий случай, повторил все, что было в курсе: от трактовки и использования ЦПТ в ходе анализа результатов до способов решения проблемы ratio-метрик (смещение среднего) и уменьшение дисперсии.

**Отдельный пункт** - несколько видео на канале [Karpov Courses](https://www.youtube.com/@karpovcourses). Больше всего рекомендую вот это

Видео Karpov Courses - вопросы на собеседовании для аналитика

Очередная замечательная идея команды Анатолия Карпова! С удивлением, смешанным с разочарованием в собственных знаниях, обнаружил, что, ответив корректно на вопросы уровня Middle/Senior (2-ое интервью), я не смог грамотно сформулировать ответы на простые вопросы в 1-ом интервью.

Кстати, в комментариях к видео есть ссылки на материалы, по которым участники готовились к съемкам. Очень рекомендую просмотреть их в рамках подготовки к собеседованиям

> Обзор системы сплитования (на примере Авито): https://habr.com/p/454164/  
>   
> Краткий обзор по статистическим тестам:  
> https://vkteam.medium.com/practitioners-guide-to-statistical-tests-ed2d580ef04f  
>   
> Пуассоновский бутстрап:  
> https://youtu.be/Zki9VMzxcFU  
>   
> Подсчёт MDE:  
> https://medium.com/statistics-experiments/когда-останавливать-a-b-тест-часть-1-mde-7d39b668b488 (Часть 1)  
> https://medium.com/statistics-experiments/когда-останавливать-a-b-тест-часть-2-monte-carlo-a342ba5b552c (Часть 2)  
>   
> Стратификация:  
> https://habr.com/ru/company/X5Tech/blog/596279/  
>   
> Методы сокращения дисперсии и зачем это нужно: https://youtu.be/KvIJ8FCJzr4  
>   
> Увеличение чувствительности в A/B с помощью Cuped: https://youtu.be/pZpUM08mv-E  
>   
> Про FPR, TPR, Statistical power и p-value:  
>   
> https://youtu.be/XTcP4oo4JI4  
>   
> https://youtu.be/-zps6hm0nX8  
>   
> https://youtu.be/2nP_gcut7SU  
>   
> Канал для подготовки к интервью в сфере Data Science: https://www.youtube.com/c/DataInterviewPro  
> Лекция Нерсеса Багияна про A/B-тесты: https://youtu.be/cWmS-ws4z9I  
> Курс «Основы статистики»: https://stepik.org/course/76/syllabus  
> Курс «Основы статистики. Часть 2»: https://stepik.org/course/524/syllabus  
> Курс «Основы статистики. Часть 3»: https://stepik.org/course/2152/syllabus

## 

Собеседования и примеры заданий

Кроме тех вакансий, что я выбрал сам, после публикации своего резюме на HH я регулярно стал получать сообщения от рекрутеров.

![](https://leonardo.osnova.io/94202e3d-35f5-54b5-b782-2aaa4b0d360a/-/preview/600/-/format/webp/)

Скриншот hh

В итоге, я остановился на 4х вакансиях, которые показались мне наиболее интересными и хорошо подходящими моему опыту. Требования были везде +/- одинаковыми, но вот сами кампании сильно отличались друг от друга по сфере деятельности.

Не буду писать названия компаний, так как далее я буду приводить примеры задач и освещать детали переговоров с рекрутерами и интервьюерами в ходе собеседований. Безусловно, конфиденциальность здесь должна быть соблюдена.

Поэтому вместо имен кратко опишу каждую компанию.

**Компания А** - разработчик очень популярного веб- и мобильного приложение в музыкальной сфере с офисом на Кипре

**Компания B** - IT-гигант РФ уровня Mail RU, Yandex, Avito, Ozon и т.д. с удаленкой или офисом в Москве

**Компания C** - стартап в сфере переездов и релокейта с офисом в Португалии

**Компания D** - крупный маркетплейс услуг в РФ с удаленным офисом или офисом в Москве

При этом я сам подался только на вакансию в компании А, остальные “прилетели” от рекрутеров в telegram.

Далее постараюсь описать развитие событий по ходу общения с компаниям по каждой из вакансий.

## 

Screening-интервью с рекрутерами

Напишу сходу, что мои заготовленные ответы на частые вопросы рекрутеров очень здесь пригодились. Особенно тогда, когда собеседование проходило на английском языке. Это не только способствовало грамотной речи, но и помогало удержать разговор в нужном русле, а также сохранять нужный тайминг.

Вот список вопросов, на которые я заранее подготовил ответы:

-   почему решили сменить место работы
-   чем занимается ваша компания и какова ваша роль в ней
-   чем гордитесь и что сделали бы по-другому за период работы
-   что вы ищете на новом месте работы

Все интервью (кроме компании D) я проводил с рекрутерами. В компании D первое интервью было с ходу с людьми, которые являются потребителями аналитических отчетов (иными словами, те, на кого работают аналитики). Мне это очень понравилось, так как сразу дало возможность оценить, насколько комфортно будет работать с людьми, которые, по сути, оценивают твою работу.

## 

Технические интервью

Все скрининг-интервью я прошел успешно. Далее предстояли технические интервью и задания. Ситуация была следующей:

**Компания А** - одно тестовое задание без онлайн-кодинга.

**Компания B** - два технических и одно маркетинговое интервью (3 в общем)

**Компания C** - одно техническое интервью с руководителем аналитики

**Компания D** - одно технические интервью с руководителем аналитики

Меня заранее предупредили, что все технические интервью будут проходит с онлайн-кодингом. То есть, прямо в ходе интервью предстояло написать код для решения той или иной задачи.

Так уж сложилось, что с онлайн-кодингом у меня всегда были проблемы.😌 Мне сложно быстро писать корректный код, когда на меня в установившейся после краткого знакомства тишине наблюдают люди, которых я вижу впервые в жизни, и которые, при этом, оценивают каждую строку кода на предмет моей проф. пригодности.

С другой стороны, это был интересный вызов. Сломать, наконец, традицию заваливать такого рода интервью. Поэтому я с удвоенной силой взялся за подготовку.

**Первое техническое интервью**

Первое интервью мне предстояло с компанией D (крупный маркетплейс услуг в РФ). И, конечно, на интервью было целых **два человека**, которые наблюдали за моим кодингом. "Что же, тем интереснее будет" - подумал я.

Без лишнего текста сразу перейду к задачам.

_Статистика_

> Вопрос: был проведен экзамен вождения среди водителей категории В. По итогам оказалось, что 90% всех участников экзамена получили оценку выше средней. Возможно ли такое? Если нет, почему? Если да, почему?

Ниже - правильный ответ. Скрыл его, если хотите сначала подумать сами 🙃

Содержание скрыто

Показать

Чтобы корректно ответить на этот вопрос, достаточно представить, каким должно быть распределение метрики, о которой идет речь в вопросе, при заданных условиях. Ответ - да, возможно. При заданных условиях распределение метрики должно быть сильно скошено вправо. При этом дисперсия у бугра на графике должна быть не очень большая, а в выборке должны быть такие выбросы (оценка сильно ниже средней), которые позволяют утянуть среднюю оценку от бугра влево.

Содержание скрыто

Показать

![](https://leonardo.osnova.io/69ebd9cb-4e41-5f6b-afa3-6a1bd4df19ff/-/preview/700/-/format/webp/)

> Вопрос: монетку подбросили 1000 раз. Орел выпал 550 раз, решка - 450 раз. Справедливо ли утверждать, что монетка "сломана" и работает лучше в сторону орла? Возможно ли такое? Если нет, почему? Если да, почему?

Ответ:

Содержание скрыто

Показать

Очевидно, что это задача на проверку стат. значимости полученных результатов. Здесь достаточно будет применить критерий долей (или z-test) для оценки. Важно не забыть о выбранных уровнях альфа (значимости) и бета (мощности). Вот хорошее видео про эту задачу -

Содержание скрыто

Показать

_SQL_

Задания на SQL оказались легче, чем я ожидал.

ПЕРВАЯ ЗАДАЧА -- Есть две таблицы. -- Рекламные объявления -- ads: -- - ad_id (PK), -- - campaign_id (FK), -- - status. -- События -- events: -- - event_id (PK), -- - ad_id (FK), -- - source, -- - event_type, -- - event_date, -- - event_hour. -- Надо рассчитать: -- Кол-во событий в разрезе рекламных кампаний (campaign_id) и типов событий (event_type). ВТОРАЯ ЗАДАЧА -- События могут быть двух типов -- event_type: -- - 'impression' — показ, -- - 'click' — клик. -- Надо рассчитать: -- CTR (кол-во кликов / кол-во показов) в разрезе рекламных кампаний (campaign_id).

Решение:

Содержание скрыто

Показать

-- Есть две таблицы. -- Рекламные объявления -- ads: -- - ad_id (PK), -- - campaign_id (FK), -- - status. -- События -- events: -- - event_id (PK), -- - ad_id (FK), -- - source, -- - event_type, -- - event_date, -- - event_hour. -- Надо рассчитать: -- Кол-во событий в разрезе рекламных кампаний (campaign_id) и типов событий (event_type). SELECT campaign_id, event_type, COUNT(event_id) FROM( SELECT ad_id, campaign_id, event_id, event_type FROM ads a LEFT JOIN ( SELECT ad_id, event_id, event_type FROM events ) b ON a.ad_id = b.ad_id -- USING(ad_id) ) GROUP BY 1,2 -- campaign_id ORDER BY 3 DESC -- События могут быть двух типов -- event_type: -- - 'impression' — показ, -- - 'click' — клик. -- Надо рассчитать: -- CTR (кол-во кликов / кол-во показов) в разрезе рекламных кампаний (campaign_id). SELECT campaign_id, clicks / impressions AS CTR FROM( SELECT campaign_id, COUNT(IF(event_type = 'click', event_id, NULL)) clicks, COUNT(IF(event_type = 'impression', event_id, NULL)) impressions FROM( SELECT ad_id, campaign_id, event_id, event_type FROM ads a LEFT JOIN ( SELECT ad_id, event_id, event_type FROM events ) b ON a.ad_id = b.ad_id -- USING(ad_id) ) GROUP BY 1 )

Содержание скрыто

Показать

В первом примере можно, конечно, обойтись без подзапроса и сразу посчитать кол-во событий, но я привожу код так, как я написал его в ходе интервью. Это потом можно порефлексировать и написать лучше 😏

_Python_

Вот здесь меня ждал сюрприз. Задача была такой - _написать функцию, которая проверяет, является ли число простым._

С первого взгляда задача совсем не кажется сложной. Но она ввела меня в ступор. Не знаю, может быть мне так повезло, или я работал как-то не так, но мне ни разу не приходилось сталкиваться с такой задачей в работе.

Даже не буду приводить решение. Оно очень быстро гуглится.

После минуты попыток мое терпение закончилось, и я, недолго думая, быстро просто загуглил решение и вставил его в ноутбук, где проводился тест. Конечно, можно было "написать" решение, подглядывая в найденный документ. Но зачем?

Не то чтобы это был плевок в сторону интервьюеров, но это им явно не очень понравилось. Я объяснил свое решение тем, что если бы мне потребовалось выполнить эту задачу (в чем сильно сомневаюсь), я бы просто нашел в поиске корректное и наиболее оптимальное для текущих условий задачи решение.

_Позже в тот же день до меня, конечно, дошло, что смысл был не в проверке того, как хорошо я умею писать циклы, а в способности писать алгоритмы. Это понимание потом сильно пригодилось для других интервью. Об этом ниже_

Собственно, на этом собеседование было окончено.

**Второе техническое интервью**

Второе интервью было с компанией C (стартап в сфере переездов и релокейта)

Я заранее знал, что интервью может быть на английском, поэтому повторил нужные термины в словаре. Сразу к задачам.

_SQL_

По сути, интервью было не столько на кодинг, сколько на подходы к решению той или иной тех. задачи. Нужно было описать, какие функции SQL я бы использовал для

-   удаление дублей
-   поиска максимального чека по когорте
-   фильтрации результатов запроса с учетом особенностей таблицы
-   плюс, вопросы на автоматизацию регулярных запросов в GBQ

_Python_

Снова задача на алгоритмы. Но на этот раз я уже был подготовлен. 😁 Да и сама задача была не в написании алгоритма, а в оценке его сложности **O(n)** Снова хабр в помощь [https://habr.com/ru/post/104219/](https://habr.com/ru/post/104219/)

**Куда больший интерес у интервьюера вызвал мой подход к выбору метрик для проекта.**

Здесь очень помог доклад [Виталия Черемисинова](https://www.facebook.com/vit.cheremisinov) по метрикам для продукта, презентацию к которому я когда-то успел получить. Вот ссылка

[![](https://leonardo.osnova.io/3896faf1-0f8f-572f-bef4-d613ea2bd7b8/-/scale_crop/200x200/-/format/webp/)

Как искать и прорабатывать метрики для продукта…

Как искать и прорабатывать метрики для продукта (Experiment-Fest, Виталий Черемисинов)

sense23.com

](https://sense23.com/academy/video/kak-iskat-i-prorabatyvat-metriki-dlya-produkta-vitalij-cheremisinov/?ref=vc.ru)

![](https://leonardo.osnova.io/28e95d79-e0aa-5fe9-94b0-39f269623e82/-/preview/1100/-/format/webp/)

**Третье техническое интервью**

Наконец, в полной боевой готовности я подошел к самым сложным интервью с компанией B (IT-гигант РФ). Здесь нужно было пройти целых три секции - мат. стат, маркетинговые инструменты, код. Кратко опишу каждое интервью, иначе статья рискует стать очень длинной.

_Мат. стат и эксперименты_ - здесь снова очень пригодились знания, полученные на курсе ExpFest. Необходимо было не только выбрать правильные метрики, но и оценить их эффективность для проведения тестов, а также пользу и интерпретацию для бизнеса. Особенный упор был сделан на выбор стат. критериев для метрики.

_Маркетинг_ - необходимо было продемонстрировать знания того, как работают платформы онлайн-рекламы. А именно: какие есть стратегии, в чем разница между ними, как посчитать эффективность рекламы, как понять, что стратегия работает или не работает, какие метрики добавить в отчет

_Код_ - достаточно простые задачи на SQL (джойны и оконные функции) и ДА, снова алгоритмы на Питоне. 😌

И снова у меня были проблемы с алгоритмами. Чтобы не совершить мою ошибку, очень настоятельно рекомендую порешать вот эти задачи (самые простые).

https://leetcode.com/problems/merge-k-sorted-lists/

https://leetcode.com/problems/linked-list-cycle/

https://leetcode.com/problems/add-two-numbers/

https://leetcode.com/problems/reverse-linked-list/

Плюс, вот это видео (обе части!!!)

Так, интервью было три, а компаний - четыре. Где еще одна?

А компания A (куда я сам подавался), к моему большому облегчению, была против интервью с онлайн-кодингом. Вместо этого я получил вот такое тех. задание.

> 1. Есть таблица с транзакциями, содержит поля: datetime, transactionid, operationtype, platform, user_id, country.
> 
> Задача - дедублицировать данные.
> 
> 2. Есть 2 таблицы:
> 
> **User_profile**
> 
> User_id
> 
> Name
> 
> Age
> 
> Sex
> 
> Country
> 
> **User_events**
> 
> Datetime
> 
> User_id
> 
> event: ‘tab open’, ‘screen open’, ‘search’
> 
> Задание
> 
> Посчитать, в какой стране больше всего смотрят табы, а если наоборот, в какой стране меньше всего смотрят табы. Разбить действия пользователей на сессии и посчитать среднюю длительность сессий.
> 
> _Предпочтительно использовать диалект sql, используемый в Clickhouse._

Весьма простое задание, как мне показалось. "Что же, здесь есть где развернуться и показать свои навыки" - подумал я.

Обратите внимание, вам не даны примеры таблиц в csv, даны только поля.

Я создал целый ноутбук в колабе, который самым подробнейшим образом расписывает решения обеих задач. Плюс, сам нагенерил примеры таблиц, упомянутых во втором задании, чтобы сделать иллюстрации и графики.

Вот мое решение

**Настоятельно рекомендую попробовать сначала решить самостоятельно. Так же намного интереснее!**

[![](https://proxy.leonardo.osnova.io/ico/colab.research.google.com)

Google Colaboratory

Google Colaboratory

colab.research.google.com

](https://colab.research.google.com/drive/1n9nl_QqdvXiCGy6vKA6bU99xk4tea5yf?usp=sharing&ref=vc.ru)

## 

Итоги

По итогам прохождения вышеописанных интервью я получил следующие результаты

**Компания А**

Я был практически уверен, что здесь все будет хорошо. А как же могло быть по-другому? Я создал целый ноутбук, расписал всю логику решений, создал графики, демонстрирующие подход, наконец, сам нагенерил данные для демонстрации. В итоге я получил вот такой фидбек:

> Привет! Фидбек здесь, во первых, спасибо за ожидание и выполненное ТЗ, вот что имеем по твоему ТЗ:
> 
> 1. решение слишком перегруженное, сделано много того что вообще не надо было делать, в работе это не приветствуется, нужно делать под задачу, когда деталю не то что нужно - это трата времени команды.
> 
> 2 и 3 решены ок, но слишком много лишнего.
> 
> Пока есть кандидаты, которые решили задачу более оптимально, коллеги хотели бы пообщаться с ними в первую очередь.
> 
> Плюс, хотела бы поблагодарить за ожидание и выполненное ТЗ! А еще ты большой молодец, что подготовился к интервью по нашим продуктам, было здорово

Вот так! Получилось, лучшее - враг хорошего. Было, конечно, обидно. Но я подозреваю, что я слишком долго тянул с откликом на эту вакансию (пока готовил ответы на вопросы и свой ноутбук). Тем временем у команды появились другие кандидаты, которые решили задачи ничуть не хуже. Просто проще и быстрее.

**Компания B**

Несмотря на мои проблемы с алгоритмами, я получил приглашение на финальное интервью, а затем - оффер 🏆

**Компания С**

Приглашение на финальное интервью (на английском) и оффер.

**Компания D**

Отказ. Полагаю, весьма справедливо, так как я внаглую скопировал нагугленное решение прямо в ходе интервью, да еще и недвусмысленно поставил под сомнение целесообразность задачи 🙈

Итог - 2/4 - 50%. Так себе статистика, мягко скажем.

Спасибо огромное, если дочитали эту статью до конца. Я не планировал делать ее такой объемной, но аппетит, как известно, приходит во время еды.

Еще раз подчеркну следующее. Цель этого эссе - помочь кандидатам лучше подготовиться к собеседованиям на примере моих ошибок, а не раскрывать детали задач на тех. собеседованиях. Как видно из содержания статьи, ошибок я сделал немало! 😏

**Всем добра!**

P.S. Пока писал статью, от ещё одной компании прилетело предложение сделать тех. задание. Не буду подробно его расписывать, ограничусь кратким изложением каждого из пунктов.

1.  Дан csv файл, в нем перечислены маркетинговые кампании А,B,C,D. Для каждой кампании указан расход и кол-во лидов по воронке (stage 1, stage 2, stage 3). Вопрос - "_какие выводы вы можете сделать по работе рекламных кампаний_"
2.  На основе csv из пункта 1 создать дэшборд (хоть в google sheets) для демонстрации выводов.
3.  Написать возможные причины, по которым рекламные переходы в GA стали попадать в `direct / none`
4.  Простая SQL-задача на джойны и оконные функции